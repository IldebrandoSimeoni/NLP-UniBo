{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "    <h1> Natural Language Processing</h1>\n",
        "    <h2> Assignment 1 </h2>\n",
        "    <a href=\"mailto:ildebrando.simeoni@studio.unibo.it\">Ildebrando Simeoni</a>, <a href=\"mailto:diego.biagini2@studio.unibo.it\">Diego Biagini</a>, <a href=\"mailto:matteo.donati10@studio.unibo.it\">Matteo Donati</a>\n",
        "</center>\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "dzbv4ZVhdC7F"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OBJyXJaTZzd"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C7sW4HdzTURu"
      },
      "outputs": [],
      "source": [
        "# Importing os.\n",
        "import os\n",
        "\n",
        "# Importing urllib.request.\n",
        "import urllib.request\n",
        "\n",
        "# Importing zipfile.\n",
        "import zipfile\n",
        "\n",
        "# Importing pandas.\n",
        "import pandas as pd\n",
        "\n",
        "# Importing numpy.\n",
        "import numpy as np\n",
        "\n",
        "# Importing random.\n",
        "import random\n",
        "\n",
        "# Importing tensorflow.\n",
        "import tensorflow as tf\n",
        "\n",
        "# Importing pad_sequences.\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Importing Sequential.\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Importing Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation.\n",
        "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation, GRU\n",
        "\n",
        "# Importing L2.\n",
        "from keras.regularizers import l2\n",
        "\n",
        "# Importing Adam.\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Importing EarlyStopping and ReduceLROnPlateau.\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Importing classification_report.\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Importing pyplot.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sets reproducibility.\n",
        "def set_reproducibility(seed):\n",
        "\n",
        "  # Setting seeds.\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  tf.random.set_seed(seed)\n",
        "  os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "  os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
        "  os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
        "\n",
        "# Setting seed.\n",
        "set_reproducibility(seed = 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9thEzbNTfiz"
      },
      "source": [
        "## Dataset Analysis and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hOWsBikzhqq8"
      },
      "outputs": [],
      "source": [
        "# Function used to download .zips.\n",
        "def downloader(url, folder_name, filename):\n",
        "\n",
        "  # Defining data folder path.\n",
        "  data_path = os.path.join(os.getcwd(), folder_name)\n",
        "\n",
        "  # Creating data folder.\n",
        "  if not os.path.exists(data_path):\n",
        "      os.makedirs(data_path)\n",
        "\n",
        "  # Defining .zip file path.\n",
        "  zip_path = os.path.join(os.getcwd(), folder_name, filename)\n",
        "\n",
        "  # Requesting .zip file.\n",
        "  if not os.path.exists(zip_path):\n",
        "      urllib.request.urlretrieve(url, zip_path)\n",
        "\n",
        "  # Extracting data from .zip.\n",
        "  with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "      zip_ref.extractall(path = data_path)\n",
        "\n",
        "  # Returning data_path and zip_path.\n",
        "  return data_path, zip_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7f3f0k3KTcr3"
      },
      "outputs": [],
      "source": [
        "# Downloading dataset.\n",
        "data_path, _ = downloader(url = \"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\", folder_name = \"data\", filename = \"dependency_treebank.zip\")\n",
        "\n",
        "# Downloading glove.\n",
        "glove_path, _ = downloader(url = \"https://nlp.stanford.edu/data/glove.6B.zip\", folder_name = \"glove\", filename = \"glove.6B.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZDEgowtTqYf",
        "outputId": "b81235ba-eb17-4e78-c83a-b1ae7d6ae253"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pierre\tNNP\t2\n",
            "Vinken\tNNP\t8\n",
            ",\t,\t2\n",
            "61\tCD\t5\n",
            "years\tNNS\t6\n",
            "old\tJJ\t2\n",
            ",\t,\t2\n",
            "will\tMD\t0\n",
            "join\tVB\t8\n",
            "the\tDT\t11\n",
            "board\tNN\t9\n",
            "as\tIN\t9\n",
            "a\tDT\t15\n",
            "nonexecutive\tJJ\t15\n",
            "director\tNN\t12\n",
            "Nov.\tNNP\t9\n",
            "29\tCD\t16\n",
            ".\t.\t8\n",
            "\n",
            "Mr.\tNNP\t2\n",
            "Vinken\tNNP\t3\n",
            "is\tVBZ\t0\n",
            "chairman\tNN\t3\n",
            "of\tIN\t4\n",
            "Elsevier\tNNP\t7\n",
            "N.V.\tNNP\t12\n",
            ",\t,\t12\n",
            "the\tDT\t12\n",
            "Dutch\tNNP\t12\n",
            "publishing\tVBG\t12\n",
            "group\tNN\t5\n",
            ".\t.\t3\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Defining the dataset name.\n",
        "dataset_name = \"dependency_treebank\"\n",
        "\n",
        "# Defining path to first training sample.\n",
        "file_path = os.path.join(data_path, dataset_name, \"wsj_0001.dp\")\n",
        "\n",
        "# Reading first training sample.\n",
        "if os.path.isfile(file_path):\n",
        "\n",
        "  # Printing file.\n",
        "  with open(file_path, mode = \"r\") as text_file: print(text_file.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TkeSn0ePqsG2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe58bd27-ab11-4be7-ee5b-775b72dc03bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The embedding for 'the' is:\n",
            "[ 4.1800e-01  2.4968e-01 -4.1242e-01  1.2170e-01  3.4527e-01 -4.4457e-02\n",
            " -4.9688e-01 -1.7862e-01 -6.6023e-04 -6.5660e-01  2.7843e-01 -1.4767e-01\n",
            " -5.5677e-01  1.4658e-01 -9.5095e-03  1.1658e-02  1.0204e-01 -1.2792e-01\n",
            " -8.4430e-01 -1.2181e-01 -1.6801e-02 -3.3279e-01 -1.5520e-01 -2.3131e-01\n",
            " -1.9181e-01 -1.8823e+00 -7.6746e-01  9.9051e-02 -4.2125e-01 -1.9526e-01\n",
            "  4.0071e+00 -1.8594e-01 -5.2287e-01 -3.1681e-01  5.9213e-04  7.4449e-03\n",
            "  1.7778e-01 -1.5897e-01  1.2041e-02 -5.4223e-02 -2.9871e-01 -1.5749e-01\n",
            " -3.4758e-01 -4.5637e-02 -4.4251e-01  1.8785e-01  2.7849e-03 -1.8411e-01\n",
            " -1.1514e-01 -7.8581e-01].\n"
          ]
        }
      ],
      "source": [
        "# Defining embedding size.\n",
        "EMBEDDING_SIZE = 50\n",
        "\n",
        "# Defining specific glove's file path.\n",
        "glove_file = os.path.join(os.getcwd(), glove_path, f\"glove.6B.{str(EMBEDDING_SIZE)}d.txt\")\n",
        "\n",
        "# Reading lines of file.\n",
        "with open(glove_file, encoding = \"utf8\" ) as text_file: \n",
        "  lines = text_file.readlines()\n",
        "\n",
        "# Defining initial vocabulary.\n",
        "embedding_vocabulary = {}\n",
        "\n",
        "# Reading single lines.\n",
        "for line in lines:\n",
        "\n",
        "  # Splitting line.\n",
        "  splits = line.split()\n",
        "\n",
        "  # Storing line into vocabulary.\n",
        "  embedding_vocabulary[splits[0]] = np.array([float(val) for val in splits[1:]])\n",
        "\n",
        "# Printing one entry of the vocabulary.\n",
        "print(\"The embedding for 'the' is:\\n{}.\".format(embedding_vocabulary[\"the\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KACvAIENUlQ2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b2ecfc8a-eb16-450e-d6e2-4d8e7854953f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   file_id                                           sentence  \\\n",
              "0        1  [Pierre, Vinken, ,, 61, years, old, ,, will, j...   \n",
              "1        1  [Mr., Vinken, is, chairman, of, Elsevier, N.V....   \n",
              "2        2  [Rudolph, Agnew, ,, 55, years, old, and, forme...   \n",
              "3        3  [A, form, of, asbestos, once, used, to, make, ...   \n",
              "4        3  [The, asbestos, fiber, ,, crocidolite, ,, is, ...   \n",
              "\n",
              "                                                tags  \\\n",
              "0  [NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...   \n",
              "1  [NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...   \n",
              "2  [NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...   \n",
              "3  [DT, NN, IN, NN, RB, VBN, TO, VB, NNP, NN, NNS...   \n",
              "4  [DT, NN, NN, ,, NN, ,, VBZ, RB, JJ, IN, PRP, V...   \n",
              "\n",
              "                                            features  \n",
              "0  [[0.23568, 0.39638, -0.60135, -0.52681, 0.1587...  \n",
              "1  [[0.006008, 0.57028, -0.064426, -0.044687, 0.8...  \n",
              "2  [[0.86274, 0.056588, -0.081828, -0.35318, -0.0...  \n",
              "3  [[0.21705, 0.46515, -0.46757, 0.10082, 1.0135,...  \n",
              "4  [[0.418, 0.24968, -0.41242, 0.1217, 0.34527, -...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fda96a0f-99d8-41e3-a982-182fdf3e59fb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>tags</th>\n",
              "      <th>features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[Pierre, Vinken, ,, 61, years, old, ,, will, j...</td>\n",
              "      <td>[NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...</td>\n",
              "      <td>[[0.23568, 0.39638, -0.60135, -0.52681, 0.1587...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[Mr., Vinken, is, chairman, of, Elsevier, N.V....</td>\n",
              "      <td>[NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...</td>\n",
              "      <td>[[0.006008, 0.57028, -0.064426, -0.044687, 0.8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[Rudolph, Agnew, ,, 55, years, old, and, forme...</td>\n",
              "      <td>[NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...</td>\n",
              "      <td>[[0.86274, 0.056588, -0.081828, -0.35318, -0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[A, form, of, asbestos, once, used, to, make, ...</td>\n",
              "      <td>[DT, NN, IN, NN, RB, VBN, TO, VB, NNP, NN, NNS...</td>\n",
              "      <td>[[0.21705, 0.46515, -0.46757, 0.10082, 1.0135,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>[The, asbestos, fiber, ,, crocidolite, ,, is, ...</td>\n",
              "      <td>[DT, NN, NN, ,, NN, ,, VBZ, RB, JJ, IN, PRP, V...</td>\n",
              "      <td>[[0.418, 0.24968, -0.41242, 0.1217, 0.34527, -...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fda96a0f-99d8-41e3-a982-182fdf3e59fb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fda96a0f-99d8-41e3-a982-182fdf3e59fb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fda96a0f-99d8-41e3-a982-182fdf3e59fb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Function used to get a list of embeddings.\n",
        "def get_embeddings(sentence, vocabulary, embedding_size):\n",
        "\n",
        "  # List of embeddings for the input sentence.\n",
        "  embeddings = []\n",
        "\n",
        "  # Retrieving embedding vector for each word.\n",
        "  for word in sentence:\n",
        "\n",
        "    # Computing the embedding.\n",
        "    embedding = vocabulary.get(word.lower())\n",
        "\n",
        "    # Checking the embedding.\n",
        "    if embedding is not None:\n",
        "      \n",
        "      # Populating the list of embeddings.\n",
        "      embeddings.append(embedding)\n",
        "    \n",
        "    else:\n",
        "\n",
        "      # Storing vector of zeros for OOV terms.\n",
        "      embeddings.append(list(np.zeros(embedding_size)))\n",
        "\n",
        "  # Returning list of embeddings.\n",
        "  return embeddings\n",
        "\n",
        "# List containing dataframe rows.\n",
        "dataframe_rows = []\n",
        "\n",
        "# List containing words of a single sentence.\n",
        "row_words = []\n",
        "\n",
        "# List containing tags of a single sentence.\n",
        "row_tags = []\n",
        "\n",
        "# Defining data folder path.\n",
        "folder = os.path.join(data_path, dataset_name)\n",
        "\n",
        "# Storing rows.\n",
        "for filename in sorted(os.listdir(folder)):\n",
        "\n",
        "  # Computing path to file.\n",
        "  file_path = os.path.join(folder, filename)\n",
        "\n",
        "  # Checking existance of file.\n",
        "  if os.path.isfile(file_path):\n",
        "\n",
        "    # Opening the file.\n",
        "    with open(file_path, mode = \"r\") as text_file:\n",
        "\n",
        "      # Reading lines.\n",
        "      while True:\n",
        "\n",
        "        # Reading next line.\n",
        "        line = text_file.readline()\n",
        "\n",
        "        # Checking that line is different from \"\\n\" (empty line) and from last line (EOF).\n",
        "        if line and line != \"\\n\":\n",
        "\n",
        "          # Storing the word.\n",
        "          row_words.append(line.split()[0])\n",
        "\n",
        "          # Storing the POS tag.\n",
        "          row_tags.append(line.split()[1])\n",
        "\n",
        "        # Creating new dataframe row.\n",
        "        else:\n",
        "\n",
        "          # Creating a row.\n",
        "          dataframe_row = {\"file_id\": int(filename.split(\".\")[0].split(\"_\")[1]), \n",
        "                           \"sentence\": row_words, \n",
        "                           \"tags\": row_tags, \n",
        "                           \"features\": get_embeddings(row_words, embedding_vocabulary, EMBEDDING_SIZE)}\n",
        "\n",
        "          # Appending row.\n",
        "          dataframe_rows.append(dataframe_row)\n",
        "\n",
        "          # Resetting row_words list so to store a new sentence.\n",
        "          row_words = []\n",
        "\n",
        "          # Resetting row_tags list so to store a new sentence.\n",
        "          row_tags = []\n",
        "\n",
        "          # If, in particular, EOF is reached, then break the inner loop.\n",
        "          if not line: break\n",
        "\n",
        "# Creating pandas dataframe.\n",
        "dataframe = pd.DataFrame(dataframe_rows)\n",
        "\n",
        "# Printing dataframe head.\n",
        "dataframe.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "51jxVKeVa0C3"
      },
      "outputs": [],
      "source": [
        "# Defining training split.\n",
        "TRAINING_SPLIT = range(1, 101)\n",
        "\n",
        "# Defining validation split.\n",
        "VALIDATION_SPLIT = range(101, 151)\n",
        "\n",
        "# Defining test split.\n",
        "TEST_SPLIT = range(151, 200)\n",
        "\n",
        "# Computing train dataframe.\n",
        "train = dataframe.loc[dataframe[\"file_id\"].isin(TRAINING_SPLIT)]\n",
        "\n",
        "# Computing validation dataframe.\n",
        "validation = dataframe.loc[dataframe[\"file_id\"].isin(VALIDATION_SPLIT)]\n",
        "\n",
        "# Computing test dataframe.\n",
        "test = dataframe.loc[dataframe[\"file_id\"].isin(TEST_SPLIT)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jC61XX7MAJoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f7f3105-e2b2-414c-b0d1-a6bcd6ca3b98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataframe consists of 3914 sentences:\n",
            " - 1963 of these sentences define the training set.\n",
            " - 1299 of these sentences define the validation set.\n",
            " - 652 of these sentences define the test set.\n"
          ]
        }
      ],
      "source": [
        "# Printing total number of sentences.\n",
        "print(f\"The dataframe consists of {len(dataframe)} sentences:\")\n",
        "\n",
        "# Printing number of training sentences.\n",
        "print(f\" - {len(train)} of these sentences define the training set.\")\n",
        "\n",
        "# Printing number of validation sentences.\n",
        "print(f\" - {len(validation)} of these sentences define the validation set.\")\n",
        "\n",
        "# Printing number of test sentences.\n",
        "print(f\" - {len(test)} of these sentences define the test set.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jTgbsNPNoI9g"
      },
      "outputs": [],
      "source": [
        "# Computing length of longest train sentence.\n",
        "MAX_LENGTH = len(max(train[\"sentence\"].tolist(), key = len))\n",
        "\n",
        "# Padding train features.\n",
        "train_features = pad_sequences(train[\"features\"].tolist(), maxlen = MAX_LENGTH, padding = \"post\", dtype = \"float32\")\n",
        "\n",
        "# Padding validation features.\n",
        "validation_features = pad_sequences(validation[\"features\"].tolist(), maxlen = MAX_LENGTH, padding = \"post\", dtype = \"float32\")\n",
        "\n",
        "# Padding test features.\n",
        "test_features = pad_sequences(test[\"features\"].tolist(), maxlen = MAX_LENGTH, padding = \"post\", dtype = \"float32\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing all training tags. The training set already contains all of them.\n",
        "train_tags = [item for sublist in train[\"tags\"].tolist() for item in sublist]\n",
        "\n",
        "# Storing all validation tags.\n",
        "validation_tags = [item for sublist in validation[\"tags\"].tolist() for item in sublist]\n",
        "\n",
        "# Storing all test tags.\n",
        "test_tags = [item for sublist in test[\"tags\"].tolist() for item in sublist]\n",
        "\n",
        "# Removing duplicates from train_tags. By using a dict instead of a set I can get reproducible results (sets are not ordered).\n",
        "tags = list(dict.fromkeys(train_tags))"
      ],
      "metadata": {
        "id": "I3fKMnEEOKg7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gzIGFLjNibLW"
      },
      "outputs": [],
      "source": [
        "# Defining figures folder path.\n",
        "figures_path = os.path.join(os.getcwd(), \"figures\")\n",
        "\n",
        "# Creating data folder.\n",
        "if not os.path.exists(figures_path): os.makedirs(figures_path)\n",
        "\n",
        "# Function used to plot classes distribution.\n",
        "def plot_classes_distribution(classes, counts, filename, figures_path = figures_path):\n",
        "\n",
        "  # Defining figure.\n",
        "  fig, ax = plt.subplots(1, 1, figsize = (9, 4))\n",
        "\n",
        "  # Plotting counts.\n",
        "  ax.bar(np.arange(0, len(classes), 1), counts)\n",
        "\n",
        "  # Setting x label.\n",
        "  ax.set_xlabel(\"Class\")\n",
        "\n",
        "  # Setting y label.\n",
        "  ax.set_ylabel(\"Count\")\n",
        "\n",
        "  # Setting y scale.\n",
        "  ax.set_yscale(\"log\")\n",
        "\n",
        "  # Setting xticks.\n",
        "  ax.set_xticks(np.arange(0, len(classes), 1))\n",
        "\n",
        "  # Setting xticklabels.\n",
        "  ax.set_xticklabels(classes, rotation = 90)\n",
        "\n",
        "  # Saving figure.\n",
        "  fig.savefig(f\"{figures_path}/{filename}_classes_distribution.pdf\", bbox_inches = \"tight\")\n",
        "\n",
        "  # Showing the plot.\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting distribution.\n",
        "plot_classes_distribution(tags, [train_tags.count(tag) for tag in tags], \"training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "ZTo2sTuKQC62",
        "outputId": "288e4ee7-b441-4cfa-c0ba-c041218e39dc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting distribution.\n",
        "plot_classes_distribution(tags, [validation_tags.count(tag) for tag in tags], \"validation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "A1FsN3QSQFj6",
        "outputId": "7d88343c-e378-45d0-c913-b36ac0005ad1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting distribution.\n",
        "plot_classes_distribution(tags, [test_tags.count(tag) for tag in tags], \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "w-tjEtOlQHxO",
        "outputId": "84febbdf-557d-49b2-bd8d-9725c131d959"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocabulary for tags.\n",
        "tag_to_index = {}\n",
        "\n",
        "# PAD is mapped onto 0.\n",
        "tag_to_index[\"PAD\"] = 0\n",
        "\n",
        "# All other tags are mapped onto other indexes, starting from 1 up to |tags|.\n",
        "for i, tag in enumerate(list(tags)): tag_to_index[tag] = i + 1\n",
        "\n",
        "# Function used to transform list of tags into vectors of integers using a tag-to-index vocabulary.\n",
        "def convert_tags(input_tags, vocabulary):\n",
        "\n",
        "  # Output tags.\n",
        "  output_tags = []\n",
        "\n",
        "  # Converting input tags.\n",
        "  for tags_list in input_tags:\n",
        "\n",
        "    # Computing index.\n",
        "    output_tags.append([vocabulary[tag] for tag in tags_list])\n",
        "\n",
        "  # Returning output_tags.\n",
        "  return output_tags\n",
        "\n",
        "# Computing train tags.\n",
        "train_tags = convert_tags(input_tags = train[\"tags\"].tolist(), vocabulary = tag_to_index)\n",
        "\n",
        "# Computing validation tags.\n",
        "validation_tags = convert_tags(input_tags = validation[\"tags\"].tolist(), vocabulary = tag_to_index)\n",
        "\n",
        "# Computing test tags.\n",
        "test_tags = convert_tags(input_tags = test[\"tags\"].tolist(), vocabulary = tag_to_index)\n",
        "\n",
        "# Padding train tags.\n",
        "train_tags = pad_sequences(train_tags, maxlen = MAX_LENGTH, padding = \"post\")\n",
        "\n",
        "# Padding validation tags.\n",
        "validation_tags = pad_sequences(validation_tags, maxlen = MAX_LENGTH, padding = \"post\")\n",
        "\n",
        "# Padding test tags.\n",
        "test_tags = pad_sequences(test_tags, maxlen = MAX_LENGTH, padding = \"post\")"
      ],
      "metadata": {
        "id": "MPrVCjEzCr7E"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eefy9o5A6e6x"
      },
      "source": [
        "## Models Definition and Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HFHMaanl2IRf"
      },
      "outputs": [],
      "source": [
        "# List of models' names.\n",
        "models_name = [\"m_0\", \"m_1\", \"m_2\", \"m_3\"]\n",
        "\n",
        "# Dictionary of models' description.\n",
        "descriptions_dict = {models_name[0]: (f\"Baseline model ({models_name[0]}): \\n\"\n",
        "                                      \" - Bi-directional LSTM layer. \\n\"\n",
        "                                      \" - Time-distributed dense layer. \\n\"\n",
        "                                      \" - Softmax activation function.\"),\n",
        "                     models_name[1]: (f\"GRU model ({models_name[1]}): \\n\"\n",
        "                                      \" - GRU layer. \\n\"\n",
        "                                      \" - Time-distributed dense layer. \\n\"\n",
        "                                      \" - Softmax activation function.\"),\n",
        "                     models_name[2]: (f\"Double bi-directional LSTM model ({models_name[2]}): \\n\"\n",
        "                                      \" - Bi-directional LSTM layer. \\n\"\n",
        "                                      \" - Bi-directional LSTM layer. \\n\"\n",
        "                                      \" - Time-distributed dense layer. \\n\"\n",
        "                                      \" - Softmax activation function.\"),\n",
        "                     models_name[3]: (f\"Double dense layer model ({models_name[3]}): \\n\"\n",
        "                                      \" - Bi-directional LSTM layer. \\n\"\n",
        "                                      \" - Time-distributed dense layer. \\n\"\n",
        "                                      \" - ReLU activation function. \\n\"\n",
        "                                      \" - Time-distributed dense layer. \\n\"\n",
        "                                      \" - Softmax activation function.\")}\n",
        "\n",
        "# Dictionary of models.\n",
        "models = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5zt4AACHGSNA"
      },
      "outputs": [],
      "source": [
        "# Batch size.\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# Epochs.\n",
        "EPOCHS = 100\n",
        "\n",
        "# Initial learning rate.\n",
        "LR = 0.01\n",
        "\n",
        "# Weight decay parameter.\n",
        "REG = 0.01\n",
        "\n",
        "# Early stopping callback.\n",
        "early_stopping = EarlyStopping(monitor = \"val_loss\", patience = 5, restore_best_weights = True)\n",
        "\n",
        "# Reduce learning rate on plateau callback.\n",
        "reduce_lr = ReduceLROnPlateau(monitor = \"val_loss\", patience = 3, factor = 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UzNmDy4dLmjL"
      },
      "outputs": [],
      "source": [
        "# Function that creates the model.\n",
        "def get_model(name, layers, input_shape):\n",
        "\n",
        "  # Sequential model.\n",
        "  model = Sequential()\n",
        "\n",
        "  # Adding input layer.\n",
        "  model.add(InputLayer(input_shape = input_shape))\n",
        "\n",
        "  # Adding layers.\n",
        "  for layer in layers:\n",
        "\n",
        "    # Adding layers.\n",
        "    model.add(layer)\n",
        "  \n",
        "  # Output dense layer.\n",
        "  model.add(TimeDistributed(Dense(len(tag_to_index))))\n",
        "\n",
        "  # Softmax.\n",
        "  model.add(Activation(\"softmax\"))\n",
        "\n",
        "  # Adding a name to the model.\n",
        "  model._name = name\n",
        "\n",
        "  # Returning the model.\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_ziwP6lcHh6q"
      },
      "outputs": [],
      "source": [
        "# Function used to grid-search.\n",
        "def grid_search(model_name, units, best_baseline_LSTM_units = None):\n",
        "\n",
        "  # List of models obtained during grid-search.\n",
        "  models = []\n",
        "\n",
        "  # List of histories.\n",
        "  histories = []\n",
        "\n",
        "  # Printing description of the model.\n",
        "  print(f\"Grid-search, {model_name} model.\")\n",
        "\n",
        "  # Grid-search over possible number of units so to find the best model.\n",
        "  for n in units:\n",
        "\n",
        "    # Checking model name.\n",
        "    if model_name == \"m_0\":\n",
        "\n",
        "      # List of layers.\n",
        "      layers = [Bidirectional(LSTM(n, return_sequences = True, recurrent_regularizer = l2(REG)))]\n",
        "    \n",
        "    elif model_name == \"m_1\":\n",
        "\n",
        "      # List of layers.\n",
        "      layers = [GRU(n, return_sequences = True, recurrent_regularizer = l2(REG))]\n",
        "\n",
        "    elif model_name == \"m_2\" and best_baseline_LSTM_units != None:\n",
        "\n",
        "      # List of layers.\n",
        "      layers = [Bidirectional(LSTM(best_baseline_LSTM_units, return_sequences = True, recurrent_regularizer = l2(REG))),\n",
        "                Bidirectional(LSTM(n, return_sequences = True, recurrent_regularizer = l2(REG)))]\n",
        "\n",
        "    elif model_name == \"m_3\" and best_baseline_LSTM_units != None:\n",
        "\n",
        "      # List of layers.\n",
        "      layers = [Bidirectional(LSTM(best_baseline_LSTM_units, return_sequences = True, recurrent_regularizer = l2(REG))),\n",
        "                TimeDistributed(Dense(n)),\n",
        "                Activation(\"relu\")]\n",
        "\n",
        "    # Creating the double lstm model.\n",
        "    model = get_model(name = model_name, layers = layers, input_shape = (MAX_LENGTH, EMBEDDING_SIZE))\n",
        "\n",
        "    # Compiling.\n",
        "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = Adam(LR), metrics = [\"accuracy\"])\n",
        "\n",
        "    # Storing model.\n",
        "    models.append(model)\n",
        "\n",
        "    # Printing info.\n",
        "    print(f\"\\nNumber of units: {n}.\\n\")\n",
        "\n",
        "    # Printing summary.\n",
        "    models[-1].summary()\n",
        "\n",
        "    # Fitting the model.\n",
        "    history = models[-1].fit(train_features, train_tags, batch_size = BATCH_SIZE, epochs = EPOCHS, validation_data = (validation_features, validation_tags), callbacks = [early_stopping, reduce_lr])\n",
        "\n",
        "    # Storing history.\n",
        "    histories.append(history)\n",
        "\n",
        "  # Returning models and histories.\n",
        "  return models, histories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "i1oYG_Kj40Km"
      },
      "outputs": [],
      "source": [
        "# Punctuation tag list.\n",
        "punctuation_tag_list = [\"PAD\", \",\", \".\", \"``\", \"''\", \":\", \"$\", \"#\"]\n",
        "\n",
        "# Function used to compute macro F1-score.\n",
        "def compute_F1_score(model, X, y, tag_to_index_vocabulary):\n",
        "\n",
        "  # Computing predictions.\n",
        "  pred = model.predict(X)\n",
        "\n",
        "  # Computing classification report.\n",
        "  report = classification_report(y.flatten(), \n",
        "                                 np.argmax(pred, axis = 2).flatten(), \n",
        "                                 labels = np.arange(0, len(tag_to_index_vocabulary), 1),\n",
        "                                 target_names = list(tag_to_index_vocabulary.keys()),\n",
        "                                 zero_division = 0,\n",
        "                                 output_dict = True)\n",
        "\n",
        "  # Macro F1-score without punctuation classes.\n",
        "  macro_f1 = 0\n",
        "\n",
        "  # Iterating over classes.\n",
        "  for tag in list(tag_to_index_vocabulary.keys()):\n",
        "\n",
        "    # Updating the macro F1-score.\n",
        "    if tag not in punctuation_tag_list: macro_f1 = macro_f1 + report[tag][\"f1-score\"]\n",
        "\n",
        "  # Dividing macro F1-score with the number of non-punctuation classes.\n",
        "  macro_f1 = macro_f1 / (len(list(tag_to_index_vocabulary.keys())) - len(punctuation_tag_list))\n",
        "\n",
        "  # Returning macro F1-score and predictions.\n",
        "  return macro_f1, pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "O1R8c9swIzIA"
      },
      "outputs": [],
      "source": [
        "# Function used to get the best model among a set of models.\n",
        "def get_best_model(models, units):\n",
        "\n",
        "  # Computing F1-scores.\n",
        "  f1_scores = [compute_F1_score(model, validation_features, validation_tags, tag_to_index)[0] for model in models]\n",
        "\n",
        "  # Computing best number of units .\n",
        "  best = units[np.argmax(f1_scores)]\n",
        "\n",
        "  # Printing best number of units.\n",
        "  print(f\"The best number of units is: {best}.\")\n",
        "\n",
        "  # Returning the best model.\n",
        "  return best, f1_scores, models[np.argmax(f1_scores)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Ti49IGGKJPpG"
      },
      "outputs": [],
      "source": [
        "# Function used to plot training losses.\n",
        "def plot_training_loss(model_name, units, histories, figures_path = figures_path):\n",
        "\n",
        "  # Computing best epoch for each model.\n",
        "  best_epochs = [np.argmin(history.history[\"val_loss\"]) + 1 for history in histories]\n",
        "\n",
        "  # Creating the figure and axes.\n",
        "  fig, ax = plt.subplots(1, 1, figsize = (4, 4))\n",
        "\n",
        "  # Plotting every history.\n",
        "  for i in range(len(units)):\n",
        "\n",
        "    # Computing the x axis array.\n",
        "    x = np.arange(1, len(histories[i].history[\"val_loss\"]) + 1, 1)\n",
        "\n",
        "    # Plotting validation loss.\n",
        "    ax.plot(x, histories[i].history[\"val_loss\"], label = r\"${}^{}$\".format(model_name, i + 1))\n",
        "\n",
        "  # Setting labels.\n",
        "  ax.set_ylabel(\"Loss\")\n",
        "\n",
        "  # Setting labels.\n",
        "  ax.set_xlabel(\"Epoch\")\n",
        "\n",
        "  # Displying legend.\n",
        "  ax.legend()\n",
        "\n",
        "  # Saving the figure.\n",
        "  fig.savefig(f\"{figures_path}/val_loss_{model_name}.pdf\", bbox_inches = \"tight\")\n",
        "\n",
        "  # Showing the plot.\n",
        "  plt.show\n",
        "\n",
        "# Function used to plot f1_scores.\n",
        "def plot_f1_scores(model_name, units, f1_scores, figures_path = figures_path):\n",
        "  \n",
        "  # Creating the figure and axes.\n",
        "  fig, ax = plt.subplots(1, 1, figsize = (4, 4))\n",
        "\n",
        "  # Plotting.\n",
        "  ax.plot(np.arange(0, len(f1_scores), 1), f1_scores, marker = \"o\")\n",
        "\n",
        "  # Setting labels.\n",
        "  ax.set_ylabel(r\"$F_1$-score\")\n",
        "\n",
        "  # Setting labels.\n",
        "  ax.set_xlabel(\"Model\")\n",
        "\n",
        "  # Setting x ticks.\n",
        "  ax.set_xticks(np.arange(0, len(f1_scores), 1))\n",
        "\n",
        "  # Setting x ticks labels.\n",
        "  ax.set_xticklabels([r\"${}^{}$\".format(model_name, i + 1) for i in range(len(units))])\n",
        "\n",
        "  # Saving the figure.\n",
        "  fig.savefig(f\"{figures_path}/f1_scores_{model_name}.pdf\", bbox_inches = \"tight\")\n",
        "\n",
        "  # Showing the plot.\n",
        "  plt.show"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4YdLEyuxPuH"
      },
      "source": [
        "### Baseline Model ($m_0$)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "momN-VqKCtlx",
        "outputId": "7a994b51-ee8a-4947-a713-f93b822ad765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid-search, m_0 model.\n",
            "\n",
            "Number of units: 32.\n",
            "\n",
            "Model: \"m_0\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  (None, 249, 64)          21248     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 249, 46)          2990      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " activation (Activation)     (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,238\n",
            "Trainable params: 24,238\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 10s 99ms/step - loss: 1.8719 - accuracy: 0.8906 - val_loss: 0.5530 - val_accuracy: 0.9305 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.4803 - accuracy: 0.9394 - val_loss: 0.3939 - val_accuracy: 0.9465 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.3333 - accuracy: 0.9502 - val_loss: 0.2716 - val_accuracy: 0.9550 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.2343 - accuracy: 0.9577 - val_loss: 0.2005 - val_accuracy: 0.9603 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.1766 - accuracy: 0.9643 - val_loss: 0.1596 - val_accuracy: 0.9660 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.1433 - accuracy: 0.9693 - val_loss: 0.1351 - val_accuracy: 0.9697 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 0.1225 - accuracy: 0.9725 - val_loss: 0.1192 - val_accuracy: 0.9720 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 0.1083 - accuracy: 0.9745 - val_loss: 0.1078 - val_accuracy: 0.9737 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 0.0977 - accuracy: 0.9764 - val_loss: 0.0988 - val_accuracy: 0.9754 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0892 - accuracy: 0.9780 - val_loss: 0.0917 - val_accuracy: 0.9768 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0824 - accuracy: 0.9794 - val_loss: 0.0857 - val_accuracy: 0.9778 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0765 - accuracy: 0.9805 - val_loss: 0.0807 - val_accuracy: 0.9790 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0715 - accuracy: 0.9815 - val_loss: 0.0766 - val_accuracy: 0.9798 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0672 - accuracy: 0.9827 - val_loss: 0.0730 - val_accuracy: 0.9808 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0635 - accuracy: 0.9835 - val_loss: 0.0699 - val_accuracy: 0.9816 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0602 - accuracy: 0.9843 - val_loss: 0.0672 - val_accuracy: 0.9823 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0572 - accuracy: 0.9852 - val_loss: 0.0648 - val_accuracy: 0.9829 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0546 - accuracy: 0.9858 - val_loss: 0.0627 - val_accuracy: 0.9834 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0523 - accuracy: 0.9863 - val_loss: 0.0609 - val_accuracy: 0.9838 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0502 - accuracy: 0.9868 - val_loss: 0.0594 - val_accuracy: 0.9840 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0483 - accuracy: 0.9872 - val_loss: 0.0579 - val_accuracy: 0.9843 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0466 - accuracy: 0.9876 - val_loss: 0.0566 - val_accuracy: 0.9846 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0450 - accuracy: 0.9880 - val_loss: 0.0555 - val_accuracy: 0.9850 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0436 - accuracy: 0.9883 - val_loss: 0.0546 - val_accuracy: 0.9850 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0422 - accuracy: 0.9886 - val_loss: 0.0535 - val_accuracy: 0.9853 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.0409 - accuracy: 0.9889 - val_loss: 0.0529 - val_accuracy: 0.9855 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0397 - accuracy: 0.9892 - val_loss: 0.0522 - val_accuracy: 0.9856 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0386 - accuracy: 0.9895 - val_loss: 0.0513 - val_accuracy: 0.9857 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0377 - accuracy: 0.9897 - val_loss: 0.0509 - val_accuracy: 0.9858 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0367 - accuracy: 0.9900 - val_loss: 0.0504 - val_accuracy: 0.9859 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0358 - accuracy: 0.9903 - val_loss: 0.0498 - val_accuracy: 0.9862 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0349 - accuracy: 0.9905 - val_loss: 0.0493 - val_accuracy: 0.9863 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0340 - accuracy: 0.9907 - val_loss: 0.0489 - val_accuracy: 0.9863 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0332 - accuracy: 0.9909 - val_loss: 0.0485 - val_accuracy: 0.9865 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0325 - accuracy: 0.9911 - val_loss: 0.0482 - val_accuracy: 0.9865 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0318 - accuracy: 0.9913 - val_loss: 0.0478 - val_accuracy: 0.9866 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0311 - accuracy: 0.9915 - val_loss: 0.0476 - val_accuracy: 0.9867 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0304 - accuracy: 0.9917 - val_loss: 0.0472 - val_accuracy: 0.9867 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0297 - accuracy: 0.9919 - val_loss: 0.0470 - val_accuracy: 0.9867 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0291 - accuracy: 0.9920 - val_loss: 0.0468 - val_accuracy: 0.9867 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0285 - accuracy: 0.9921 - val_loss: 0.0465 - val_accuracy: 0.9870 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0280 - accuracy: 0.9923 - val_loss: 0.0463 - val_accuracy: 0.9870 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0274 - accuracy: 0.9925 - val_loss: 0.0462 - val_accuracy: 0.9870 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0268 - accuracy: 0.9926 - val_loss: 0.0461 - val_accuracy: 0.9870 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0264 - accuracy: 0.9928 - val_loss: 0.0459 - val_accuracy: 0.9871 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0259 - accuracy: 0.9929 - val_loss: 0.0458 - val_accuracy: 0.9872 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0254 - accuracy: 0.9930 - val_loss: 0.0457 - val_accuracy: 0.9872 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0249 - accuracy: 0.9932 - val_loss: 0.0456 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 0.0454 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0241 - accuracy: 0.9934 - val_loss: 0.0454 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0237 - accuracy: 0.9936 - val_loss: 0.0453 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0232 - accuracy: 0.9937 - val_loss: 0.0453 - val_accuracy: 0.9874 - lr: 0.0100\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0230 - accuracy: 0.9938 - val_loss: 0.0453 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0225 - accuracy: 0.9938 - val_loss: 0.0450 - val_accuracy: 0.9874 - lr: 0.0100\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 1s 33ms/step - loss: 0.0222 - accuracy: 0.9940 - val_loss: 0.0452 - val_accuracy: 0.9874 - lr: 0.0100\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0219 - accuracy: 0.9940 - val_loss: 0.0451 - val_accuracy: 0.9874 - lr: 0.0100\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0215 - accuracy: 0.9942 - val_loss: 0.0453 - val_accuracy: 0.9875 - lr: 0.0100\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0209 - accuracy: 0.9945 - val_loss: 0.0450 - val_accuracy: 0.9875 - lr: 1.0000e-03\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0207 - accuracy: 0.9945 - val_loss: 0.0449 - val_accuracy: 0.9876 - lr: 1.0000e-03\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0207 - accuracy: 0.9945 - val_loss: 0.0449 - val_accuracy: 0.9875 - lr: 1.0000e-03\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 0.0449 - val_accuracy: 0.9875 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 0.0449 - val_accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 1s 34ms/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 0.0449 - val_accuracy: 0.9875 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 0.0449 - val_accuracy: 0.9875 - lr: 1.0000e-05\n",
            "\n",
            "Number of units: 64.\n",
            "\n",
            "Model: \"m_0\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_1 (Bidirectio  (None, 249, 128)         58880     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 249, 46)          5934      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64,814\n",
            "Trainable params: 64,814\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 5s 119ms/step - loss: 1.6377 - accuracy: 0.9001 - val_loss: 0.6213 - val_accuracy: 0.9400 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.4928 - accuracy: 0.9457 - val_loss: 0.3520 - val_accuracy: 0.9524 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.2754 - accuracy: 0.9582 - val_loss: 0.2077 - val_accuracy: 0.9632 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.1713 - accuracy: 0.9678 - val_loss: 0.1438 - val_accuracy: 0.9696 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.1254 - accuracy: 0.9722 - val_loss: 0.1150 - val_accuracy: 0.9727 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.1026 - accuracy: 0.9755 - val_loss: 0.0984 - val_accuracy: 0.9762 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0881 - accuracy: 0.9785 - val_loss: 0.0871 - val_accuracy: 0.9779 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.0775 - accuracy: 0.9806 - val_loss: 0.0789 - val_accuracy: 0.9792 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.0695 - accuracy: 0.9822 - val_loss: 0.0724 - val_accuracy: 0.9806 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.0628 - accuracy: 0.9838 - val_loss: 0.0671 - val_accuracy: 0.9822 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.0575 - accuracy: 0.9851 - val_loss: 0.0629 - val_accuracy: 0.9831 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.0531 - accuracy: 0.9861 - val_loss: 0.0593 - val_accuracy: 0.9837 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 0.0492 - accuracy: 0.9870 - val_loss: 0.0563 - val_accuracy: 0.9845 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.0459 - accuracy: 0.9879 - val_loss: 0.0540 - val_accuracy: 0.9852 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0430 - accuracy: 0.9884 - val_loss: 0.0517 - val_accuracy: 0.9858 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.0404 - accuracy: 0.9892 - val_loss: 0.0500 - val_accuracy: 0.9862 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 0.0382 - accuracy: 0.9897 - val_loss: 0.0485 - val_accuracy: 0.9864 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0362 - accuracy: 0.9903 - val_loss: 0.0471 - val_accuracy: 0.9868 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 0.0344 - accuracy: 0.9907 - val_loss: 0.0461 - val_accuracy: 0.9869 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0328 - accuracy: 0.9911 - val_loss: 0.0450 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.0312 - accuracy: 0.9916 - val_loss: 0.0443 - val_accuracy: 0.9876 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0299 - accuracy: 0.9920 - val_loss: 0.0434 - val_accuracy: 0.9877 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0286 - accuracy: 0.9923 - val_loss: 0.0427 - val_accuracy: 0.9880 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0274 - accuracy: 0.9927 - val_loss: 0.0423 - val_accuracy: 0.9881 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.0263 - accuracy: 0.9931 - val_loss: 0.0418 - val_accuracy: 0.9881 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0253 - accuracy: 0.9933 - val_loss: 0.0413 - val_accuracy: 0.9883 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.0243 - accuracy: 0.9935 - val_loss: 0.0412 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.0234 - accuracy: 0.9938 - val_loss: 0.0404 - val_accuracy: 0.9885 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 0.0226 - accuracy: 0.9940 - val_loss: 0.0405 - val_accuracy: 0.9885 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0217 - accuracy: 0.9942 - val_loss: 0.0401 - val_accuracy: 0.9886 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.0209 - accuracy: 0.9945 - val_loss: 0.0398 - val_accuracy: 0.9887 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0202 - accuracy: 0.9947 - val_loss: 0.0399 - val_accuracy: 0.9888 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0195 - accuracy: 0.9949 - val_loss: 0.0396 - val_accuracy: 0.9888 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.0188 - accuracy: 0.9952 - val_loss: 0.0393 - val_accuracy: 0.9889 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0182 - accuracy: 0.9953 - val_loss: 0.0395 - val_accuracy: 0.9890 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0177 - accuracy: 0.9955 - val_loss: 0.0394 - val_accuracy: 0.9889 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0170 - accuracy: 0.9957 - val_loss: 0.0392 - val_accuracy: 0.9891 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.0164 - accuracy: 0.9959 - val_loss: 0.0394 - val_accuracy: 0.9889 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.0159 - accuracy: 0.9960 - val_loss: 0.0393 - val_accuracy: 0.9890 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0154 - accuracy: 0.9961 - val_loss: 0.0393 - val_accuracy: 0.9890 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0145 - accuracy: 0.9964 - val_loss: 0.0392 - val_accuracy: 0.9891 - lr: 1.0000e-03\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0143 - accuracy: 0.9965 - val_loss: 0.0390 - val_accuracy: 0.9891 - lr: 1.0000e-03\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0143 - accuracy: 0.9965 - val_loss: 0.0390 - val_accuracy: 0.9891 - lr: 1.0000e-03\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0142 - accuracy: 0.9965 - val_loss: 0.0390 - val_accuracy: 0.9891 - lr: 1.0000e-03\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.0141 - accuracy: 0.9966 - val_loss: 0.0390 - val_accuracy: 0.9891 - lr: 1.0000e-03\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0141 - accuracy: 0.9966 - val_loss: 0.0390 - val_accuracy: 0.9891 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 0.0390 - val_accuracy: 0.9891 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 0.0390 - val_accuracy: 0.9891 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 0.0390 - val_accuracy: 0.9891 - lr: 1.0000e-05\n",
            "\n",
            "Number of units: 128.\n",
            "\n",
            "Model: \"m_0\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_2 (Bidirectio  (None, 249, 256)         183296    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDis  (None, 249, 46)          11822     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 195,118\n",
            "Trainable params: 195,118\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 5s 114ms/step - loss: 1.7563 - accuracy: 0.9058 - val_loss: 0.7155 - val_accuracy: 0.9500 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.5331 - accuracy: 0.9574 - val_loss: 0.3544 - val_accuracy: 0.9637 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.2664 - accuracy: 0.9697 - val_loss: 0.1914 - val_accuracy: 0.9716 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.1500 - accuracy: 0.9752 - val_loss: 0.1204 - val_accuracy: 0.9760 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0993 - accuracy: 0.9788 - val_loss: 0.0899 - val_accuracy: 0.9790 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0762 - accuracy: 0.9818 - val_loss: 0.0745 - val_accuracy: 0.9811 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.0632 - accuracy: 0.9842 - val_loss: 0.0655 - val_accuracy: 0.9829 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0544 - accuracy: 0.9860 - val_loss: 0.0593 - val_accuracy: 0.9839 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.0481 - accuracy: 0.9873 - val_loss: 0.0545 - val_accuracy: 0.9849 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.0427 - accuracy: 0.9886 - val_loss: 0.0504 - val_accuracy: 0.9858 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0387 - accuracy: 0.9895 - val_loss: 0.0479 - val_accuracy: 0.9863 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0353 - accuracy: 0.9904 - val_loss: 0.0455 - val_accuracy: 0.9870 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0326 - accuracy: 0.9912 - val_loss: 0.0438 - val_accuracy: 0.9874 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.0300 - accuracy: 0.9920 - val_loss: 0.0424 - val_accuracy: 0.9878 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0278 - accuracy: 0.9926 - val_loss: 0.0409 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0260 - accuracy: 0.9931 - val_loss: 0.0404 - val_accuracy: 0.9883 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0242 - accuracy: 0.9937 - val_loss: 0.0393 - val_accuracy: 0.9888 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0226 - accuracy: 0.9941 - val_loss: 0.0390 - val_accuracy: 0.9888 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.0213 - accuracy: 0.9945 - val_loss: 0.0384 - val_accuracy: 0.9891 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.0200 - accuracy: 0.9949 - val_loss: 0.0384 - val_accuracy: 0.9890 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0189 - accuracy: 0.9952 - val_loss: 0.0376 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0177 - accuracy: 0.9956 - val_loss: 0.0382 - val_accuracy: 0.9892 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0167 - accuracy: 0.9959 - val_loss: 0.0376 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 1s 63ms/step - loss: 0.0157 - accuracy: 0.9961 - val_loss: 0.0374 - val_accuracy: 0.9894 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0147 - accuracy: 0.9965 - val_loss: 0.0371 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 69ms/step - loss: 0.0139 - accuracy: 0.9967 - val_loss: 0.0370 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.0132 - accuracy: 0.9968 - val_loss: 0.0370 - val_accuracy: 0.9896 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0124 - accuracy: 0.9971 - val_loss: 0.0370 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 0.0373 - val_accuracy: 0.9896 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0106 - accuracy: 0.9977 - val_loss: 0.0364 - val_accuracy: 0.9897 - lr: 1.0000e-03\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.0101 - accuracy: 0.9978 - val_loss: 0.0362 - val_accuracy: 0.9898 - lr: 1.0000e-03\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0100 - accuracy: 0.9978 - val_loss: 0.0362 - val_accuracy: 0.9898 - lr: 1.0000e-03\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.0099 - accuracy: 0.9978 - val_loss: 0.0363 - val_accuracy: 0.9897 - lr: 1.0000e-03\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.0363 - val_accuracy: 0.9897 - lr: 1.0000e-03\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.0363 - val_accuracy: 0.9897 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.0363 - val_accuracy: 0.9897 - lr: 1.0000e-04\n",
            "\n",
            "Number of units: 256.\n",
            "\n",
            "Model: \"m_0\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_3 (Bidirectio  (None, 249, 512)         628736    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDis  (None, 249, 46)          23598     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 652,334\n",
            "Trainable params: 652,334\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 6s 173ms/step - loss: 2.0510 - accuracy: 0.9057 - val_loss: 0.7254 - val_accuracy: 0.9529 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.4362 - accuracy: 0.9615 - val_loss: 0.2385 - val_accuracy: 0.9672 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.1671 - accuracy: 0.9725 - val_loss: 0.1188 - val_accuracy: 0.9741 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0943 - accuracy: 0.9782 - val_loss: 0.0824 - val_accuracy: 0.9787 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0691 - accuracy: 0.9822 - val_loss: 0.0675 - val_accuracy: 0.9818 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0567 - accuracy: 0.9849 - val_loss: 0.0590 - val_accuracy: 0.9836 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0491 - accuracy: 0.9867 - val_loss: 0.0537 - val_accuracy: 0.9849 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0431 - accuracy: 0.9883 - val_loss: 0.0496 - val_accuracy: 0.9859 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0384 - accuracy: 0.9895 - val_loss: 0.0467 - val_accuracy: 0.9869 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0345 - accuracy: 0.9906 - val_loss: 0.0437 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0317 - accuracy: 0.9914 - val_loss: 0.0425 - val_accuracy: 0.9877 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0289 - accuracy: 0.9922 - val_loss: 0.0397 - val_accuracy: 0.9885 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0268 - accuracy: 0.9929 - val_loss: 0.0394 - val_accuracy: 0.9886 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0245 - accuracy: 0.9936 - val_loss: 0.0380 - val_accuracy: 0.9890 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0223 - accuracy: 0.9942 - val_loss: 0.0368 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0205 - accuracy: 0.9948 - val_loss: 0.0356 - val_accuracy: 0.9898 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0191 - accuracy: 0.9952 - val_loss: 0.0352 - val_accuracy: 0.9898 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0177 - accuracy: 0.9957 - val_loss: 0.0344 - val_accuracy: 0.9901 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0163 - accuracy: 0.9961 - val_loss: 0.0350 - val_accuracy: 0.9900 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0150 - accuracy: 0.9965 - val_loss: 0.0343 - val_accuracy: 0.9902 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0138 - accuracy: 0.9969 - val_loss: 0.0340 - val_accuracy: 0.9904 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0128 - accuracy: 0.9971 - val_loss: 0.0335 - val_accuracy: 0.9905 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0120 - accuracy: 0.9973 - val_loss: 0.0341 - val_accuracy: 0.9905 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0111 - accuracy: 0.9977 - val_loss: 0.0333 - val_accuracy: 0.9907 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0103 - accuracy: 0.9979 - val_loss: 0.0345 - val_accuracy: 0.9906 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0098 - accuracy: 0.9980 - val_loss: 0.0336 - val_accuracy: 0.9907 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0092 - accuracy: 0.9982 - val_loss: 0.0339 - val_accuracy: 0.9905 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0076 - accuracy: 0.9986 - val_loss: 0.0325 - val_accuracy: 0.9908 - lr: 1.0000e-03\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 1s 94ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.0324 - val_accuracy: 0.9908 - lr: 1.0000e-03\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0069 - accuracy: 0.9987 - val_loss: 0.0325 - val_accuracy: 0.9909 - lr: 1.0000e-03\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.0324 - val_accuracy: 0.9909 - lr: 1.0000e-03\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.0324 - val_accuracy: 0.9909 - lr: 1.0000e-03\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.0325 - val_accuracy: 0.9909 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.0325 - val_accuracy: 0.9909 - lr: 1.0000e-04\n"
          ]
        }
      ],
      "source": [
        "# Possible units.\n",
        "baseline_units = [32, 64, 128, 256]\n",
        "\n",
        "# Computing models and histories.\n",
        "baseline_models, baseline_model_histories = grid_search(models_name[0], baseline_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i68Sx5VvShFD",
        "outputId": "f8cda8a3-5618-4759-b479-e04b1ccc6fa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 1s 11ms/step\n",
            "41/41 [==============================] - 1s 9ms/step\n",
            "41/41 [==============================] - 1s 11ms/step\n",
            "41/41 [==============================] - 1s 12ms/step\n",
            "The best number of units is: 256.\n"
          ]
        }
      ],
      "source": [
        "# Storing best model.\n",
        "baseline_best_units, baseline_f1_scores, models[models_name[0]] = get_best_model(baseline_models, baseline_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "vexOylzGJJE-",
        "outputId": "f485877c-2bd4-433d-b135-908b6d5c8bf1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plotting losses and saving figure as .pdf file.\n",
        "plot_training_loss(models_name[0], baseline_units, baseline_model_histories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "emXLTTjTgy8_",
        "outputId": "35fba59a-8a37-4d71-d9d5-90465778a80d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plotting scores and saving figure as .pdf file.\n",
        "plot_f1_scores(models_name[0], baseline_units, baseline_f1_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPtlS40Jx9gR"
      },
      "source": [
        "### GRU Model ($m_1$)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3gJ7IKwOgHk",
        "outputId": "344d2ab4-8607-4429-9534-2b812d8af6b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid-search, m_1 model.\n",
            "\n",
            "Number of units: 32.\n",
            "\n",
            "Model: \"m_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru (GRU)                   (None, 249, 32)           8064      \n",
            "                                                                 \n",
            " time_distributed_4 (TimeDis  (None, 249, 46)          1518      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,582\n",
            "Trainable params: 9,582\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 3s 62ms/step - loss: 2.0736 - accuracy: 0.9044 - val_loss: 0.4863 - val_accuracy: 0.9193 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.4664 - accuracy: 0.9268 - val_loss: 0.4211 - val_accuracy: 0.9397 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.3698 - accuracy: 0.9434 - val_loss: 0.3080 - val_accuracy: 0.9519 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.2681 - accuracy: 0.9545 - val_loss: 0.2273 - val_accuracy: 0.9588 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.2017 - accuracy: 0.9620 - val_loss: 0.1795 - val_accuracy: 0.9634 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.1637 - accuracy: 0.9667 - val_loss: 0.1531 - val_accuracy: 0.9672 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.1421 - accuracy: 0.9696 - val_loss: 0.1368 - val_accuracy: 0.9696 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.1277 - accuracy: 0.9718 - val_loss: 0.1254 - val_accuracy: 0.9716 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.1169 - accuracy: 0.9735 - val_loss: 0.1164 - val_accuracy: 0.9732 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.1083 - accuracy: 0.9748 - val_loss: 0.1095 - val_accuracy: 0.9739 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.1014 - accuracy: 0.9759 - val_loss: 0.1036 - val_accuracy: 0.9746 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0956 - accuracy: 0.9768 - val_loss: 0.0990 - val_accuracy: 0.9753 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0907 - accuracy: 0.9775 - val_loss: 0.0948 - val_accuracy: 0.9760 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0864 - accuracy: 0.9782 - val_loss: 0.0913 - val_accuracy: 0.9763 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0827 - accuracy: 0.9789 - val_loss: 0.0882 - val_accuracy: 0.9771 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0794 - accuracy: 0.9796 - val_loss: 0.0855 - val_accuracy: 0.9776 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0765 - accuracy: 0.9803 - val_loss: 0.0831 - val_accuracy: 0.9781 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0739 - accuracy: 0.9806 - val_loss: 0.0810 - val_accuracy: 0.9783 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0717 - accuracy: 0.9810 - val_loss: 0.0791 - val_accuracy: 0.9787 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0696 - accuracy: 0.9814 - val_loss: 0.0775 - val_accuracy: 0.9791 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0677 - accuracy: 0.9819 - val_loss: 0.0760 - val_accuracy: 0.9796 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0661 - accuracy: 0.9822 - val_loss: 0.0748 - val_accuracy: 0.9798 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0646 - accuracy: 0.9825 - val_loss: 0.0735 - val_accuracy: 0.9799 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0632 - accuracy: 0.9828 - val_loss: 0.0725 - val_accuracy: 0.9802 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0619 - accuracy: 0.9831 - val_loss: 0.0715 - val_accuracy: 0.9805 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0608 - accuracy: 0.9834 - val_loss: 0.0707 - val_accuracy: 0.9807 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0597 - accuracy: 0.9836 - val_loss: 0.0699 - val_accuracy: 0.9809 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0587 - accuracy: 0.9839 - val_loss: 0.0690 - val_accuracy: 0.9811 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0577 - accuracy: 0.9840 - val_loss: 0.0685 - val_accuracy: 0.9812 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0568 - accuracy: 0.9842 - val_loss: 0.0679 - val_accuracy: 0.9813 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0560 - accuracy: 0.9844 - val_loss: 0.0672 - val_accuracy: 0.9814 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0553 - accuracy: 0.9845 - val_loss: 0.0667 - val_accuracy: 0.9814 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0546 - accuracy: 0.9847 - val_loss: 0.0662 - val_accuracy: 0.9814 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0538 - accuracy: 0.9848 - val_loss: 0.0658 - val_accuracy: 0.9815 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0532 - accuracy: 0.9850 - val_loss: 0.0653 - val_accuracy: 0.9816 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0526 - accuracy: 0.9852 - val_loss: 0.0649 - val_accuracy: 0.9817 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0521 - accuracy: 0.9852 - val_loss: 0.0647 - val_accuracy: 0.9819 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0516 - accuracy: 0.9853 - val_loss: 0.0642 - val_accuracy: 0.9820 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0511 - accuracy: 0.9855 - val_loss: 0.0639 - val_accuracy: 0.9820 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0506 - accuracy: 0.9856 - val_loss: 0.0636 - val_accuracy: 0.9821 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0502 - accuracy: 0.9857 - val_loss: 0.0632 - val_accuracy: 0.9823 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0498 - accuracy: 0.9859 - val_loss: 0.0630 - val_accuracy: 0.9823 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0493 - accuracy: 0.9859 - val_loss: 0.0628 - val_accuracy: 0.9824 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 29ms/step - loss: 0.0489 - accuracy: 0.9860 - val_loss: 0.0626 - val_accuracy: 0.9825 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 29ms/step - loss: 0.0485 - accuracy: 0.9861 - val_loss: 0.0623 - val_accuracy: 0.9824 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 29ms/step - loss: 0.0482 - accuracy: 0.9863 - val_loss: 0.0620 - val_accuracy: 0.9825 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 28ms/step - loss: 0.0479 - accuracy: 0.9863 - val_loss: 0.0619 - val_accuracy: 0.9826 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0474 - accuracy: 0.9865 - val_loss: 0.0616 - val_accuracy: 0.9827 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.0471 - accuracy: 0.9865 - val_loss: 0.0615 - val_accuracy: 0.9826 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0468 - accuracy: 0.9866 - val_loss: 0.0612 - val_accuracy: 0.9828 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0465 - accuracy: 0.9867 - val_loss: 0.0613 - val_accuracy: 0.9827 - lr: 0.0100\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0462 - accuracy: 0.9867 - val_loss: 0.0610 - val_accuracy: 0.9826 - lr: 0.0100\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0459 - accuracy: 0.9868 - val_loss: 0.0608 - val_accuracy: 0.9828 - lr: 0.0100\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0456 - accuracy: 0.9868 - val_loss: 0.0607 - val_accuracy: 0.9828 - lr: 0.0100\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0454 - accuracy: 0.9870 - val_loss: 0.0607 - val_accuracy: 0.9829 - lr: 0.0100\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0452 - accuracy: 0.9870 - val_loss: 0.0603 - val_accuracy: 0.9829 - lr: 0.0100\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0449 - accuracy: 0.9871 - val_loss: 0.0604 - val_accuracy: 0.9830 - lr: 0.0100\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0446 - accuracy: 0.9872 - val_loss: 0.0602 - val_accuracy: 0.9830 - lr: 0.0100\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0444 - accuracy: 0.9872 - val_loss: 0.0601 - val_accuracy: 0.9831 - lr: 0.0100\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0442 - accuracy: 0.9873 - val_loss: 0.0600 - val_accuracy: 0.9831 - lr: 0.0100\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0440 - accuracy: 0.9873 - val_loss: 0.0599 - val_accuracy: 0.9832 - lr: 0.0100\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0437 - accuracy: 0.9874 - val_loss: 0.0598 - val_accuracy: 0.9832 - lr: 0.0100\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0435 - accuracy: 0.9875 - val_loss: 0.0599 - val_accuracy: 0.9832 - lr: 0.0100\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0433 - accuracy: 0.9875 - val_loss: 0.0597 - val_accuracy: 0.9834 - lr: 0.0100\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0431 - accuracy: 0.9875 - val_loss: 0.0597 - val_accuracy: 0.9833 - lr: 0.0100\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0430 - accuracy: 0.9876 - val_loss: 0.0595 - val_accuracy: 0.9834 - lr: 0.0100\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0427 - accuracy: 0.9876 - val_loss: 0.0594 - val_accuracy: 0.9835 - lr: 0.0100\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0426 - accuracy: 0.9878 - val_loss: 0.0594 - val_accuracy: 0.9836 - lr: 0.0100\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0423 - accuracy: 0.9878 - val_loss: 0.0595 - val_accuracy: 0.9834 - lr: 0.0100\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0422 - accuracy: 0.9877 - val_loss: 0.0593 - val_accuracy: 0.9836 - lr: 0.0100\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0420 - accuracy: 0.9879 - val_loss: 0.0591 - val_accuracy: 0.9836 - lr: 0.0100\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0418 - accuracy: 0.9879 - val_loss: 0.0591 - val_accuracy: 0.9837 - lr: 0.0100\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0417 - accuracy: 0.9880 - val_loss: 0.0590 - val_accuracy: 0.9837 - lr: 0.0100\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0415 - accuracy: 0.9880 - val_loss: 0.0589 - val_accuracy: 0.9838 - lr: 0.0100\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0413 - accuracy: 0.9880 - val_loss: 0.0590 - val_accuracy: 0.9838 - lr: 0.0100\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0412 - accuracy: 0.9880 - val_loss: 0.0589 - val_accuracy: 0.9838 - lr: 0.0100\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0406 - accuracy: 0.9883 - val_loss: 0.0587 - val_accuracy: 0.9838 - lr: 1.0000e-03\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0405 - accuracy: 0.9883 - val_loss: 0.0587 - val_accuracy: 0.9839 - lr: 1.0000e-03\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0405 - accuracy: 0.9883 - val_loss: 0.0586 - val_accuracy: 0.9839 - lr: 1.0000e-03\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0404 - accuracy: 0.9883 - val_loss: 0.0586 - val_accuracy: 0.9839 - lr: 1.0000e-03\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0404 - accuracy: 0.9883 - val_loss: 0.0586 - val_accuracy: 0.9839 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0404 - accuracy: 0.9883 - val_loss: 0.0586 - val_accuracy: 0.9839 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0404 - accuracy: 0.9883 - val_loss: 0.0586 - val_accuracy: 0.9839 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.0403 - accuracy: 0.9883 - val_loss: 0.0586 - val_accuracy: 0.9839 - lr: 1.0000e-05\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0403 - accuracy: 0.9883 - val_loss: 0.0586 - val_accuracy: 0.9839 - lr: 1.0000e-05\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0403 - accuracy: 0.9883 - val_loss: 0.0586 - val_accuracy: 0.9839 - lr: 1.0000e-05\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0403 - accuracy: 0.9883 - val_loss: 0.0586 - val_accuracy: 0.9839 - lr: 1.0000e-06\n",
            "Epoch 88/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0403 - accuracy: 0.9883 - val_loss: 0.0586 - val_accuracy: 0.9839 - lr: 1.0000e-06\n",
            "Epoch 89/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0403 - accuracy: 0.9883 - val_loss: 0.0586 - val_accuracy: 0.9839 - lr: 1.0000e-06\n",
            "Epoch 90/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0403 - accuracy: 0.9883 - val_loss: 0.0586 - val_accuracy: 0.9839 - lr: 1.0000e-07\n",
            "Epoch 91/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0403 - accuracy: 0.9883 - val_loss: 0.0586 - val_accuracy: 0.9839 - lr: 1.0000e-07\n",
            "Epoch 92/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0403 - accuracy: 0.9883 - val_loss: 0.0586 - val_accuracy: 0.9839 - lr: 1.0000e-07\n",
            "Epoch 93/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0403 - accuracy: 0.9883 - val_loss: 0.0586 - val_accuracy: 0.9839 - lr: 1.0000e-08\n",
            "\n",
            "Number of units: 64.\n",
            "\n",
            "Model: \"m_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_1 (GRU)                 (None, 249, 64)           22272     \n",
            "                                                                 \n",
            " time_distributed_5 (TimeDis  (None, 249, 46)          2990      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,262\n",
            "Trainable params: 25,262\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 3s 66ms/step - loss: 1.6647 - accuracy: 0.9079 - val_loss: 0.5457 - val_accuracy: 0.9350 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.4820 - accuracy: 0.9411 - val_loss: 0.3813 - val_accuracy: 0.9468 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.3122 - accuracy: 0.9530 - val_loss: 0.2421 - val_accuracy: 0.9590 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.2033 - accuracy: 0.9632 - val_loss: 0.1713 - val_accuracy: 0.9654 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.1530 - accuracy: 0.9675 - val_loss: 0.1413 - val_accuracy: 0.9680 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.1298 - accuracy: 0.9703 - val_loss: 0.1250 - val_accuracy: 0.9702 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.1156 - accuracy: 0.9726 - val_loss: 0.1135 - val_accuracy: 0.9728 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.1050 - accuracy: 0.9747 - val_loss: 0.1048 - val_accuracy: 0.9741 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0966 - accuracy: 0.9761 - val_loss: 0.0977 - val_accuracy: 0.9751 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0896 - accuracy: 0.9773 - val_loss: 0.0918 - val_accuracy: 0.9760 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0836 - accuracy: 0.9784 - val_loss: 0.0867 - val_accuracy: 0.9768 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0784 - accuracy: 0.9794 - val_loss: 0.0823 - val_accuracy: 0.9779 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0739 - accuracy: 0.9804 - val_loss: 0.0786 - val_accuracy: 0.9787 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0700 - accuracy: 0.9814 - val_loss: 0.0754 - val_accuracy: 0.9794 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.0667 - accuracy: 0.9822 - val_loss: 0.0727 - val_accuracy: 0.9802 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0638 - accuracy: 0.9828 - val_loss: 0.0705 - val_accuracy: 0.9808 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0612 - accuracy: 0.9835 - val_loss: 0.0684 - val_accuracy: 0.9812 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0589 - accuracy: 0.9840 - val_loss: 0.0666 - val_accuracy: 0.9816 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0569 - accuracy: 0.9846 - val_loss: 0.0652 - val_accuracy: 0.9822 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0550 - accuracy: 0.9851 - val_loss: 0.0639 - val_accuracy: 0.9826 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0533 - accuracy: 0.9855 - val_loss: 0.0626 - val_accuracy: 0.9828 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0518 - accuracy: 0.9857 - val_loss: 0.0615 - val_accuracy: 0.9830 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0503 - accuracy: 0.9861 - val_loss: 0.0605 - val_accuracy: 0.9832 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0490 - accuracy: 0.9865 - val_loss: 0.0597 - val_accuracy: 0.9834 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0478 - accuracy: 0.9867 - val_loss: 0.0588 - val_accuracy: 0.9835 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0467 - accuracy: 0.9870 - val_loss: 0.0583 - val_accuracy: 0.9836 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0456 - accuracy: 0.9873 - val_loss: 0.0575 - val_accuracy: 0.9838 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0446 - accuracy: 0.9876 - val_loss: 0.0567 - val_accuracy: 0.9841 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0437 - accuracy: 0.9878 - val_loss: 0.0564 - val_accuracy: 0.9842 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0428 - accuracy: 0.9879 - val_loss: 0.0562 - val_accuracy: 0.9842 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0421 - accuracy: 0.9882 - val_loss: 0.0555 - val_accuracy: 0.9844 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0412 - accuracy: 0.9884 - val_loss: 0.0549 - val_accuracy: 0.9845 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 27ms/step - loss: 0.0404 - accuracy: 0.9887 - val_loss: 0.0546 - val_accuracy: 0.9847 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0397 - accuracy: 0.9888 - val_loss: 0.0543 - val_accuracy: 0.9848 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0391 - accuracy: 0.9890 - val_loss: 0.0541 - val_accuracy: 0.9849 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0385 - accuracy: 0.9891 - val_loss: 0.0537 - val_accuracy: 0.9850 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0379 - accuracy: 0.9893 - val_loss: 0.0535 - val_accuracy: 0.9851 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0372 - accuracy: 0.9894 - val_loss: 0.0533 - val_accuracy: 0.9849 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.0367 - accuracy: 0.9896 - val_loss: 0.0530 - val_accuracy: 0.9851 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0362 - accuracy: 0.9897 - val_loss: 0.0528 - val_accuracy: 0.9852 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0356 - accuracy: 0.9898 - val_loss: 0.0527 - val_accuracy: 0.9852 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0352 - accuracy: 0.9899 - val_loss: 0.0524 - val_accuracy: 0.9853 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0348 - accuracy: 0.9901 - val_loss: 0.0522 - val_accuracy: 0.9854 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0342 - accuracy: 0.9902 - val_loss: 0.0524 - val_accuracy: 0.9854 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0338 - accuracy: 0.9903 - val_loss: 0.0522 - val_accuracy: 0.9855 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0334 - accuracy: 0.9903 - val_loss: 0.0520 - val_accuracy: 0.9855 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0330 - accuracy: 0.9906 - val_loss: 0.0520 - val_accuracy: 0.9856 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0326 - accuracy: 0.9906 - val_loss: 0.0518 - val_accuracy: 0.9857 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0322 - accuracy: 0.9908 - val_loss: 0.0518 - val_accuracy: 0.9857 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0319 - accuracy: 0.9907 - val_loss: 0.0519 - val_accuracy: 0.9857 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0316 - accuracy: 0.9909 - val_loss: 0.0516 - val_accuracy: 0.9856 - lr: 0.0100\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0312 - accuracy: 0.9910 - val_loss: 0.0515 - val_accuracy: 0.9858 - lr: 0.0100\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0309 - accuracy: 0.9911 - val_loss: 0.0516 - val_accuracy: 0.9857 - lr: 0.0100\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0306 - accuracy: 0.9911 - val_loss: 0.0515 - val_accuracy: 0.9858 - lr: 0.0100\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0298 - accuracy: 0.9914 - val_loss: 0.0511 - val_accuracy: 0.9859 - lr: 1.0000e-03\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0296 - accuracy: 0.9914 - val_loss: 0.0510 - val_accuracy: 0.9859 - lr: 1.0000e-03\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0295 - accuracy: 0.9914 - val_loss: 0.0510 - val_accuracy: 0.9859 - lr: 1.0000e-03\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.0294 - accuracy: 0.9915 - val_loss: 0.0510 - val_accuracy: 0.9859 - lr: 1.0000e-03\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0294 - accuracy: 0.9915 - val_loss: 0.0510 - val_accuracy: 0.9859 - lr: 1.0000e-03\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 26ms/step - loss: 0.0293 - accuracy: 0.9915 - val_loss: 0.0510 - val_accuracy: 0.9859 - lr: 1.0000e-04\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.0293 - accuracy: 0.9915 - val_loss: 0.0510 - val_accuracy: 0.9859 - lr: 1.0000e-04\n",
            "\n",
            "Number of units: 128.\n",
            "\n",
            "Model: \"m_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_2 (GRU)                 (None, 249, 128)          69120     \n",
            "                                                                 \n",
            " time_distributed_6 (TimeDis  (None, 249, 46)          5934      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 75,054\n",
            "Trainable params: 75,054\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 3s 69ms/step - loss: 2.4105 - accuracy: 0.8579 - val_loss: 0.8333 - val_accuracy: 0.9128 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.8133 - accuracy: 0.9286 - val_loss: 0.7499 - val_accuracy: 0.9397 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.6613 - accuracy: 0.9456 - val_loss: 0.5425 - val_accuracy: 0.9514 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.4563 - accuracy: 0.9555 - val_loss: 0.3665 - val_accuracy: 0.9591 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.3102 - accuracy: 0.9622 - val_loss: 0.2575 - val_accuracy: 0.9633 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.2230 - accuracy: 0.9661 - val_loss: 0.1948 - val_accuracy: 0.9668 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.1730 - accuracy: 0.9690 - val_loss: 0.1587 - val_accuracy: 0.9693 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 0s 29ms/step - loss: 0.1433 - accuracy: 0.9716 - val_loss: 0.1368 - val_accuracy: 0.9711 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.1247 - accuracy: 0.9734 - val_loss: 0.1225 - val_accuracy: 0.9726 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.1119 - accuracy: 0.9751 - val_loss: 0.1125 - val_accuracy: 0.9738 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.1025 - accuracy: 0.9766 - val_loss: 0.1044 - val_accuracy: 0.9751 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0949 - accuracy: 0.9778 - val_loss: 0.0982 - val_accuracy: 0.9760 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 0s 29ms/step - loss: 0.0886 - accuracy: 0.9789 - val_loss: 0.0929 - val_accuracy: 0.9771 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0833 - accuracy: 0.9798 - val_loss: 0.0884 - val_accuracy: 0.9778 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0787 - accuracy: 0.9805 - val_loss: 0.0845 - val_accuracy: 0.9786 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0746 - accuracy: 0.9814 - val_loss: 0.0810 - val_accuracy: 0.9790 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0710 - accuracy: 0.9820 - val_loss: 0.0779 - val_accuracy: 0.9798 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0677 - accuracy: 0.9828 - val_loss: 0.0752 - val_accuracy: 0.9804 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0648 - accuracy: 0.9833 - val_loss: 0.0728 - val_accuracy: 0.9807 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0622 - accuracy: 0.9839 - val_loss: 0.0708 - val_accuracy: 0.9812 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0597 - accuracy: 0.9846 - val_loss: 0.0688 - val_accuracy: 0.9817 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0575 - accuracy: 0.9850 - val_loss: 0.0669 - val_accuracy: 0.9820 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0555 - accuracy: 0.9855 - val_loss: 0.0654 - val_accuracy: 0.9824 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0537 - accuracy: 0.9860 - val_loss: 0.0639 - val_accuracy: 0.9829 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 0s 29ms/step - loss: 0.0519 - accuracy: 0.9864 - val_loss: 0.0625 - val_accuracy: 0.9831 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0503 - accuracy: 0.9869 - val_loss: 0.0614 - val_accuracy: 0.9835 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0489 - accuracy: 0.9872 - val_loss: 0.0602 - val_accuracy: 0.9838 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0475 - accuracy: 0.9875 - val_loss: 0.0590 - val_accuracy: 0.9840 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0462 - accuracy: 0.9878 - val_loss: 0.0582 - val_accuracy: 0.9842 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0449 - accuracy: 0.9881 - val_loss: 0.0573 - val_accuracy: 0.9844 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0438 - accuracy: 0.9884 - val_loss: 0.0564 - val_accuracy: 0.9846 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0426 - accuracy: 0.9887 - val_loss: 0.0557 - val_accuracy: 0.9847 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0416 - accuracy: 0.9890 - val_loss: 0.0549 - val_accuracy: 0.9851 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.0406 - accuracy: 0.9892 - val_loss: 0.0542 - val_accuracy: 0.9852 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0397 - accuracy: 0.9895 - val_loss: 0.0538 - val_accuracy: 0.9854 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0388 - accuracy: 0.9896 - val_loss: 0.0532 - val_accuracy: 0.9855 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.0380 - accuracy: 0.9898 - val_loss: 0.0527 - val_accuracy: 0.9856 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0371 - accuracy: 0.9901 - val_loss: 0.0521 - val_accuracy: 0.9856 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0364 - accuracy: 0.9903 - val_loss: 0.0517 - val_accuracy: 0.9857 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0356 - accuracy: 0.9904 - val_loss: 0.0513 - val_accuracy: 0.9858 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.0349 - accuracy: 0.9906 - val_loss: 0.0508 - val_accuracy: 0.9860 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.0342 - accuracy: 0.9908 - val_loss: 0.0506 - val_accuracy: 0.9861 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0336 - accuracy: 0.9910 - val_loss: 0.0501 - val_accuracy: 0.9862 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0328 - accuracy: 0.9911 - val_loss: 0.0502 - val_accuracy: 0.9861 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0322 - accuracy: 0.9913 - val_loss: 0.0497 - val_accuracy: 0.9863 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0317 - accuracy: 0.9914 - val_loss: 0.0496 - val_accuracy: 0.9864 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0311 - accuracy: 0.9916 - val_loss: 0.0493 - val_accuracy: 0.9865 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.0305 - accuracy: 0.9917 - val_loss: 0.0492 - val_accuracy: 0.9865 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0300 - accuracy: 0.9918 - val_loss: 0.0489 - val_accuracy: 0.9866 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0295 - accuracy: 0.9919 - val_loss: 0.0488 - val_accuracy: 0.9866 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0290 - accuracy: 0.9921 - val_loss: 0.0485 - val_accuracy: 0.9866 - lr: 0.0100\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0285 - accuracy: 0.9922 - val_loss: 0.0485 - val_accuracy: 0.9866 - lr: 0.0100\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0280 - accuracy: 0.9924 - val_loss: 0.0483 - val_accuracy: 0.9867 - lr: 0.0100\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0276 - accuracy: 0.9924 - val_loss: 0.0483 - val_accuracy: 0.9866 - lr: 0.0100\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0272 - accuracy: 0.9926 - val_loss: 0.0482 - val_accuracy: 0.9866 - lr: 0.0100\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0267 - accuracy: 0.9927 - val_loss: 0.0481 - val_accuracy: 0.9867 - lr: 0.0100\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0262 - accuracy: 0.9928 - val_loss: 0.0483 - val_accuracy: 0.9868 - lr: 0.0100\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0258 - accuracy: 0.9930 - val_loss: 0.0480 - val_accuracy: 0.9868 - lr: 0.0100\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0254 - accuracy: 0.9930 - val_loss: 0.0481 - val_accuracy: 0.9867 - lr: 0.0100\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 0.0474 - val_accuracy: 0.9870 - lr: 1.0000e-03\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0242 - accuracy: 0.9934 - val_loss: 0.0473 - val_accuracy: 0.9870 - lr: 1.0000e-03\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0241 - accuracy: 0.9934 - val_loss: 0.0473 - val_accuracy: 0.9870 - lr: 1.0000e-03\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 0s 31ms/step - loss: 0.0240 - accuracy: 0.9934 - val_loss: 0.0473 - val_accuracy: 0.9870 - lr: 1.0000e-03\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0239 - accuracy: 0.9934 - val_loss: 0.0473 - val_accuracy: 0.9870 - lr: 1.0000e-04\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0239 - accuracy: 0.9934 - val_loss: 0.0473 - val_accuracy: 0.9870 - lr: 1.0000e-04\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0239 - accuracy: 0.9934 - val_loss: 0.0473 - val_accuracy: 0.9870 - lr: 1.0000e-04\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0239 - accuracy: 0.9934 - val_loss: 0.0473 - val_accuracy: 0.9870 - lr: 1.0000e-05\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0239 - accuracy: 0.9934 - val_loss: 0.0473 - val_accuracy: 0.9870 - lr: 1.0000e-05\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0239 - accuracy: 0.9934 - val_loss: 0.0473 - val_accuracy: 0.9870 - lr: 1.0000e-05\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 0s 30ms/step - loss: 0.0239 - accuracy: 0.9934 - val_loss: 0.0473 - val_accuracy: 0.9870 - lr: 1.0000e-06\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 1s 32ms/step - loss: 0.0239 - accuracy: 0.9934 - val_loss: 0.0473 - val_accuracy: 0.9870 - lr: 1.0000e-06\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " gru_3 (GRU)                 (None, 249, 256)          236544    \n",
            "                                                                 \n",
            " time_distributed_7 (TimeDis  (None, 249, 46)          11822     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 248,366\n",
            "Trainable params: 248,366\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 3s 82ms/step - loss: 3.1907 - accuracy: 0.8588 - val_loss: 2.1170 - val_accuracy: 0.9066 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 2.0364 - accuracy: 0.9172 - val_loss: 1.7533 - val_accuracy: 0.9339 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 1.4766 - accuracy: 0.9378 - val_loss: 1.1701 - val_accuracy: 0.9446 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.9899 - accuracy: 0.9475 - val_loss: 0.8040 - val_accuracy: 0.9520 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.6948 - accuracy: 0.9552 - val_loss: 0.5821 - val_accuracy: 0.9590 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.5114 - accuracy: 0.9611 - val_loss: 0.4387 - val_accuracy: 0.9626 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.3899 - accuracy: 0.9649 - val_loss: 0.3419 - val_accuracy: 0.9655 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.3073 - accuracy: 0.9675 - val_loss: 0.2755 - val_accuracy: 0.9676 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.2501 - accuracy: 0.9694 - val_loss: 0.2288 - val_accuracy: 0.9692 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.2095 - accuracy: 0.9710 - val_loss: 0.1960 - val_accuracy: 0.9707 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.1805 - accuracy: 0.9722 - val_loss: 0.1716 - val_accuracy: 0.9719 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.1589 - accuracy: 0.9735 - val_loss: 0.1538 - val_accuracy: 0.9726 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.1427 - accuracy: 0.9742 - val_loss: 0.1402 - val_accuracy: 0.9732 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.1301 - accuracy: 0.9753 - val_loss: 0.1292 - val_accuracy: 0.9742 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.1200 - accuracy: 0.9760 - val_loss: 0.1205 - val_accuracy: 0.9749 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.1120 - accuracy: 0.9767 - val_loss: 0.1134 - val_accuracy: 0.9752 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.1053 - accuracy: 0.9774 - val_loss: 0.1075 - val_accuracy: 0.9760 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0995 - accuracy: 0.9781 - val_loss: 0.1025 - val_accuracy: 0.9766 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0945 - accuracy: 0.9786 - val_loss: 0.0987 - val_accuracy: 0.9769 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0902 - accuracy: 0.9792 - val_loss: 0.0948 - val_accuracy: 0.9776 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0866 - accuracy: 0.9796 - val_loss: 0.0913 - val_accuracy: 0.9778 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0835 - accuracy: 0.9800 - val_loss: 0.0885 - val_accuracy: 0.9782 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0804 - accuracy: 0.9804 - val_loss: 0.0859 - val_accuracy: 0.9785 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0777 - accuracy: 0.9809 - val_loss: 0.0836 - val_accuracy: 0.9785 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0754 - accuracy: 0.9813 - val_loss: 0.0814 - val_accuracy: 0.9790 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0732 - accuracy: 0.9817 - val_loss: 0.0796 - val_accuracy: 0.9793 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0712 - accuracy: 0.9819 - val_loss: 0.0782 - val_accuracy: 0.9796 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0694 - accuracy: 0.9823 - val_loss: 0.0764 - val_accuracy: 0.9799 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0678 - accuracy: 0.9825 - val_loss: 0.0751 - val_accuracy: 0.9802 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0661 - accuracy: 0.9828 - val_loss: 0.0735 - val_accuracy: 0.9806 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0647 - accuracy: 0.9831 - val_loss: 0.0725 - val_accuracy: 0.9808 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0632 - accuracy: 0.9835 - val_loss: 0.0710 - val_accuracy: 0.9809 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0620 - accuracy: 0.9837 - val_loss: 0.0699 - val_accuracy: 0.9812 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0607 - accuracy: 0.9839 - val_loss: 0.0689 - val_accuracy: 0.9814 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0595 - accuracy: 0.9842 - val_loss: 0.0680 - val_accuracy: 0.9815 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0584 - accuracy: 0.9845 - val_loss: 0.0671 - val_accuracy: 0.9818 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0573 - accuracy: 0.9848 - val_loss: 0.0664 - val_accuracy: 0.9817 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0565 - accuracy: 0.9849 - val_loss: 0.0657 - val_accuracy: 0.9818 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0555 - accuracy: 0.9850 - val_loss: 0.0646 - val_accuracy: 0.9822 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0544 - accuracy: 0.9853 - val_loss: 0.0638 - val_accuracy: 0.9824 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0537 - accuracy: 0.9855 - val_loss: 0.0636 - val_accuracy: 0.9824 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0530 - accuracy: 0.9856 - val_loss: 0.0630 - val_accuracy: 0.9826 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0520 - accuracy: 0.9859 - val_loss: 0.0626 - val_accuracy: 0.9827 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0514 - accuracy: 0.9860 - val_loss: 0.0618 - val_accuracy: 0.9829 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0507 - accuracy: 0.9862 - val_loss: 0.0611 - val_accuracy: 0.9831 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0497 - accuracy: 0.9864 - val_loss: 0.0609 - val_accuracy: 0.9832 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0491 - accuracy: 0.9866 - val_loss: 0.0602 - val_accuracy: 0.9833 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0485 - accuracy: 0.9867 - val_loss: 0.0592 - val_accuracy: 0.9836 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0478 - accuracy: 0.9869 - val_loss: 0.0592 - val_accuracy: 0.9835 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0474 - accuracy: 0.9869 - val_loss: 0.0592 - val_accuracy: 0.9834 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0468 - accuracy: 0.9871 - val_loss: 0.0582 - val_accuracy: 0.9837 - lr: 0.0100\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0462 - accuracy: 0.9872 - val_loss: 0.0580 - val_accuracy: 0.9840 - lr: 0.0100\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0458 - accuracy: 0.9874 - val_loss: 0.0583 - val_accuracy: 0.9836 - lr: 0.0100\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0452 - accuracy: 0.9876 - val_loss: 0.0577 - val_accuracy: 0.9841 - lr: 0.0100\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0446 - accuracy: 0.9876 - val_loss: 0.0573 - val_accuracy: 0.9841 - lr: 0.0100\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0439 - accuracy: 0.9878 - val_loss: 0.0566 - val_accuracy: 0.9844 - lr: 0.0100\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 1s 48ms/step - loss: 0.0433 - accuracy: 0.9880 - val_loss: 0.0565 - val_accuracy: 0.9843 - lr: 0.0100\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.0429 - accuracy: 0.9881 - val_loss: 0.0559 - val_accuracy: 0.9843 - lr: 0.0100\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0423 - accuracy: 0.9882 - val_loss: 0.0558 - val_accuracy: 0.9843 - lr: 0.0100\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.0418 - accuracy: 0.9883 - val_loss: 0.0552 - val_accuracy: 0.9848 - lr: 0.0100\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0414 - accuracy: 0.9885 - val_loss: 0.0557 - val_accuracy: 0.9846 - lr: 0.0100\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0410 - accuracy: 0.9886 - val_loss: 0.0551 - val_accuracy: 0.9846 - lr: 0.0100\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0405 - accuracy: 0.9888 - val_loss: 0.0545 - val_accuracy: 0.9849 - lr: 0.0100\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0402 - accuracy: 0.9888 - val_loss: 0.0541 - val_accuracy: 0.9849 - lr: 0.0100\n",
            "Epoch 65/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0397 - accuracy: 0.9889 - val_loss: 0.0542 - val_accuracy: 0.9850 - lr: 0.0100\n",
            "Epoch 66/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0393 - accuracy: 0.9890 - val_loss: 0.0535 - val_accuracy: 0.9851 - lr: 0.0100\n",
            "Epoch 67/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0388 - accuracy: 0.9892 - val_loss: 0.0535 - val_accuracy: 0.9851 - lr: 0.0100\n",
            "Epoch 68/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0388 - accuracy: 0.9891 - val_loss: 0.0534 - val_accuracy: 0.9850 - lr: 0.0100\n",
            "Epoch 69/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0382 - accuracy: 0.9894 - val_loss: 0.0535 - val_accuracy: 0.9852 - lr: 0.0100\n",
            "Epoch 70/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0378 - accuracy: 0.9894 - val_loss: 0.0527 - val_accuracy: 0.9852 - lr: 0.0100\n",
            "Epoch 71/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0373 - accuracy: 0.9895 - val_loss: 0.0527 - val_accuracy: 0.9852 - lr: 0.0100\n",
            "Epoch 72/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0369 - accuracy: 0.9896 - val_loss: 0.0528 - val_accuracy: 0.9852 - lr: 0.0100\n",
            "Epoch 73/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0371 - accuracy: 0.9896 - val_loss: 0.0528 - val_accuracy: 0.9852 - lr: 0.0100\n",
            "Epoch 74/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0354 - accuracy: 0.9900 - val_loss: 0.0511 - val_accuracy: 0.9856 - lr: 1.0000e-03\n",
            "Epoch 75/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0347 - accuracy: 0.9902 - val_loss: 0.0509 - val_accuracy: 0.9856 - lr: 1.0000e-03\n",
            "Epoch 76/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0345 - accuracy: 0.9902 - val_loss: 0.0509 - val_accuracy: 0.9856 - lr: 1.0000e-03\n",
            "Epoch 77/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0345 - accuracy: 0.9902 - val_loss: 0.0508 - val_accuracy: 0.9856 - lr: 1.0000e-03\n",
            "Epoch 78/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0345 - accuracy: 0.9902 - val_loss: 0.0508 - val_accuracy: 0.9856 - lr: 1.0000e-03\n",
            "Epoch 79/100\n",
            "16/16 [==============================] - 1s 47ms/step - loss: 0.0344 - accuracy: 0.9903 - val_loss: 0.0507 - val_accuracy: 0.9856 - lr: 1.0000e-03\n",
            "Epoch 80/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0344 - accuracy: 0.9902 - val_loss: 0.0508 - val_accuracy: 0.9857 - lr: 1.0000e-03\n",
            "Epoch 81/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0343 - accuracy: 0.9903 - val_loss: 0.0507 - val_accuracy: 0.9856 - lr: 1.0000e-04\n",
            "Epoch 82/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0342 - accuracy: 0.9903 - val_loss: 0.0506 - val_accuracy: 0.9856 - lr: 1.0000e-04\n",
            "Epoch 83/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0342 - accuracy: 0.9903 - val_loss: 0.0507 - val_accuracy: 0.9856 - lr: 1.0000e-04\n",
            "Epoch 84/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0342 - accuracy: 0.9903 - val_loss: 0.0507 - val_accuracy: 0.9856 - lr: 1.0000e-04\n",
            "Epoch 85/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0342 - accuracy: 0.9903 - val_loss: 0.0507 - val_accuracy: 0.9856 - lr: 1.0000e-04\n",
            "Epoch 86/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0342 - accuracy: 0.9903 - val_loss: 0.0507 - val_accuracy: 0.9856 - lr: 1.0000e-05\n",
            "Epoch 87/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0342 - accuracy: 0.9903 - val_loss: 0.0507 - val_accuracy: 0.9856 - lr: 1.0000e-05\n"
          ]
        }
      ],
      "source": [
        "# Possible units.\n",
        "gru_units = [32, 64, 128, 256]\n",
        "\n",
        "# Computing models and histories.\n",
        "gru_models, gru_model_histories = grid_search(models_name[1], gru_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ul1WbFDkOnYF",
        "outputId": "a7b70d68-cd3b-4902-afb3-020915ad717a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 1s 7ms/step\n",
            "41/41 [==============================] - 1s 6ms/step\n",
            "41/41 [==============================] - 1s 7ms/step\n",
            "41/41 [==============================] - 1s 7ms/step\n",
            "The best number of units is: 256.\n"
          ]
        }
      ],
      "source": [
        "# Storing best model.\n",
        "_, gru_f1_scores, models[models_name[1]] = get_best_model(gru_models, gru_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "LWsBxGmyc9PZ",
        "outputId": "ac195bd8-c366-441e-9d92-d7acd1dbf644"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plotting losses and saving figure as .pdf file.\n",
        "plot_training_loss(models_name[1], gru_units, gru_model_histories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "10CECwq1lZHp",
        "outputId": "b18bb8f6-c640-4f92-aee5-c4503ec3b5ef"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plotting scores and saving figure as .pdf file.\n",
        "plot_f1_scores(models_name[1], gru_units, gru_f1_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVqtTIGn9qUo"
      },
      "source": [
        "### Double BiLSTM Model ($m_2$)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsv40lpYOzy2",
        "outputId": "725d6e8b-5d15-41d7-bf09-0f3f6eb857ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid-search, m_2 model.\n",
            "\n",
            "Number of units: 32.\n",
            "\n",
            "Model: \"m_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_4 (Bidirectio  (None, 249, 512)         628736    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirectio  (None, 249, 64)          139520    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_8 (TimeDis  (None, 249, 46)          2990      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 771,246\n",
            "Trainable params: 771,246\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 9s 214ms/step - loss: 2.4332 - accuracy: 0.8810 - val_loss: 0.7458 - val_accuracy: 0.9170 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 2s 118ms/step - loss: 0.5144 - accuracy: 0.9224 - val_loss: 0.3566 - val_accuracy: 0.9307 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.3004 - accuracy: 0.9335 - val_loss: 0.2498 - val_accuracy: 0.9370 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.2223 - accuracy: 0.9444 - val_loss: 0.1984 - val_accuracy: 0.9495 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1780 - accuracy: 0.9545 - val_loss: 0.1624 - val_accuracy: 0.9587 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.1456 - accuracy: 0.9627 - val_loss: 0.1348 - val_accuracy: 0.9650 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.1211 - accuracy: 0.9693 - val_loss: 0.1144 - val_accuracy: 0.9705 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 2s 127ms/step - loss: 0.1023 - accuracy: 0.9742 - val_loss: 0.0992 - val_accuracy: 0.9743 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0879 - accuracy: 0.9776 - val_loss: 0.0874 - val_accuracy: 0.9772 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0763 - accuracy: 0.9807 - val_loss: 0.0786 - val_accuracy: 0.9796 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0673 - accuracy: 0.9831 - val_loss: 0.0708 - val_accuracy: 0.9820 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0596 - accuracy: 0.9850 - val_loss: 0.0653 - val_accuracy: 0.9831 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.0537 - accuracy: 0.9865 - val_loss: 0.0614 - val_accuracy: 0.9839 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0484 - accuracy: 0.9879 - val_loss: 0.0572 - val_accuracy: 0.9848 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0434 - accuracy: 0.9893 - val_loss: 0.0532 - val_accuracy: 0.9860 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.0389 - accuracy: 0.9906 - val_loss: 0.0501 - val_accuracy: 0.9868 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0355 - accuracy: 0.9915 - val_loss: 0.0479 - val_accuracy: 0.9874 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0323 - accuracy: 0.9924 - val_loss: 0.0463 - val_accuracy: 0.9878 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0295 - accuracy: 0.9932 - val_loss: 0.0445 - val_accuracy: 0.9883 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0265 - accuracy: 0.9940 - val_loss: 0.0432 - val_accuracy: 0.9887 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.0245 - accuracy: 0.9945 - val_loss: 0.0433 - val_accuracy: 0.9887 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0228 - accuracy: 0.9950 - val_loss: 0.0416 - val_accuracy: 0.9891 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.0208 - accuracy: 0.9955 - val_loss: 0.0407 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.0188 - accuracy: 0.9961 - val_loss: 0.0399 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0178 - accuracy: 0.9963 - val_loss: 0.0406 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0165 - accuracy: 0.9966 - val_loss: 0.0386 - val_accuracy: 0.9899 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0147 - accuracy: 0.9971 - val_loss: 0.0394 - val_accuracy: 0.9897 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0136 - accuracy: 0.9974 - val_loss: 0.0382 - val_accuracy: 0.9900 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0123 - accuracy: 0.9978 - val_loss: 0.0383 - val_accuracy: 0.9900 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0117 - accuracy: 0.9979 - val_loss: 0.0379 - val_accuracy: 0.9903 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0106 - accuracy: 0.9981 - val_loss: 0.0382 - val_accuracy: 0.9901 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0100 - accuracy: 0.9982 - val_loss: 0.0379 - val_accuracy: 0.9902 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0090 - accuracy: 0.9984 - val_loss: 0.0381 - val_accuracy: 0.9903 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0076 - accuracy: 0.9987 - val_loss: 0.0370 - val_accuracy: 0.9904 - lr: 1.0000e-03\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0072 - accuracy: 0.9987 - val_loss: 0.0370 - val_accuracy: 0.9903 - lr: 1.0000e-03\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.0369 - val_accuracy: 0.9904 - lr: 1.0000e-03\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.0370 - val_accuracy: 0.9903 - lr: 1.0000e-03\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.0370 - val_accuracy: 0.9904 - lr: 1.0000e-03\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 2s 119ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.0370 - val_accuracy: 0.9903 - lr: 1.0000e-03\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.0370 - val_accuracy: 0.9903 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 2s 120ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.0370 - val_accuracy: 0.9904 - lr: 1.0000e-04\n",
            "\n",
            "Number of units: 64.\n",
            "\n",
            "Model: \"m_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_6 (Bidirectio  (None, 249, 512)         628736    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirectio  (None, 249, 128)         295424    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_9 (TimeDis  (None, 249, 46)          5934      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 930,094\n",
            "Trainable params: 930,094\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 9s 227ms/step - loss: 2.5758 - accuracy: 0.8887 - val_loss: 1.0177 - val_accuracy: 0.9285 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 2s 132ms/step - loss: 0.6590 - accuracy: 0.9340 - val_loss: 0.3895 - val_accuracy: 0.9451 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 2s 133ms/step - loss: 0.2845 - accuracy: 0.9507 - val_loss: 0.2007 - val_accuracy: 0.9570 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 2s 133ms/step - loss: 0.1632 - accuracy: 0.9632 - val_loss: 0.1356 - val_accuracy: 0.9672 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 2s 133ms/step - loss: 0.1150 - accuracy: 0.9707 - val_loss: 0.1031 - val_accuracy: 0.9727 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 2s 132ms/step - loss: 0.0896 - accuracy: 0.9758 - val_loss: 0.0844 - val_accuracy: 0.9769 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 2s 133ms/step - loss: 0.0737 - accuracy: 0.9796 - val_loss: 0.0734 - val_accuracy: 0.9799 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.0624 - accuracy: 0.9831 - val_loss: 0.0639 - val_accuracy: 0.9826 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.0539 - accuracy: 0.9853 - val_loss: 0.0568 - val_accuracy: 0.9843 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.0473 - accuracy: 0.9872 - val_loss: 0.0548 - val_accuracy: 0.9849 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.0428 - accuracy: 0.9884 - val_loss: 0.0494 - val_accuracy: 0.9863 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.0379 - accuracy: 0.9898 - val_loss: 0.0457 - val_accuracy: 0.9872 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.0340 - accuracy: 0.9909 - val_loss: 0.0443 - val_accuracy: 0.9875 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.0304 - accuracy: 0.9920 - val_loss: 0.0422 - val_accuracy: 0.9880 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 2s 136ms/step - loss: 0.0273 - accuracy: 0.9928 - val_loss: 0.0400 - val_accuracy: 0.9886 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.0247 - accuracy: 0.9936 - val_loss: 0.0391 - val_accuracy: 0.9890 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.0231 - accuracy: 0.9941 - val_loss: 0.0374 - val_accuracy: 0.9894 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.0205 - accuracy: 0.9949 - val_loss: 0.0367 - val_accuracy: 0.9898 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.0183 - accuracy: 0.9956 - val_loss: 0.0361 - val_accuracy: 0.9900 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.0166 - accuracy: 0.9960 - val_loss: 0.0363 - val_accuracy: 0.9901 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.0363 - val_accuracy: 0.9900 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.0141 - accuracy: 0.9968 - val_loss: 0.0362 - val_accuracy: 0.9902 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.0119 - accuracy: 0.9974 - val_loss: 0.0339 - val_accuracy: 0.9905 - lr: 1.0000e-03\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.0337 - val_accuracy: 0.9906 - lr: 1.0000e-03\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.0108 - accuracy: 0.9977 - val_loss: 0.0338 - val_accuracy: 0.9906 - lr: 1.0000e-03\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.0106 - accuracy: 0.9977 - val_loss: 0.0336 - val_accuracy: 0.9906 - lr: 1.0000e-03\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.0105 - accuracy: 0.9977 - val_loss: 0.0337 - val_accuracy: 0.9907 - lr: 1.0000e-03\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 0.0103 - accuracy: 0.9978 - val_loss: 0.0337 - val_accuracy: 0.9906 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 0.0103 - accuracy: 0.9978 - val_loss: 0.0336 - val_accuracy: 0.9906 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 2s 133ms/step - loss: 0.0103 - accuracy: 0.9978 - val_loss: 0.0337 - val_accuracy: 0.9906 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.0103 - accuracy: 0.9978 - val_loss: 0.0337 - val_accuracy: 0.9906 - lr: 1.0000e-05\n",
            "\n",
            "Number of units: 128.\n",
            "\n",
            "Model: \"m_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_8 (Bidirectio  (None, 249, 512)         628736    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_9 (Bidirectio  (None, 249, 256)         656384    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_10 (TimeDi  (None, 249, 46)          11822     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,296,942\n",
            "Trainable params: 1,296,942\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 10s 294ms/step - loss: 3.1768 - accuracy: 0.8802 - val_loss: 1.4553 - val_accuracy: 0.9293 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 3s 163ms/step - loss: 0.9046 - accuracy: 0.9349 - val_loss: 0.4712 - val_accuracy: 0.9468 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 3s 163ms/step - loss: 0.3232 - accuracy: 0.9524 - val_loss: 0.2067 - val_accuracy: 0.9572 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.1579 - accuracy: 0.9648 - val_loss: 0.1231 - val_accuracy: 0.9689 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.1028 - accuracy: 0.9734 - val_loss: 0.0924 - val_accuracy: 0.9750 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 3s 165ms/step - loss: 0.0796 - accuracy: 0.9782 - val_loss: 0.0763 - val_accuracy: 0.9782 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 3s 165ms/step - loss: 0.0650 - accuracy: 0.9816 - val_loss: 0.0657 - val_accuracy: 0.9815 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 3s 166ms/step - loss: 0.0541 - accuracy: 0.9850 - val_loss: 0.0572 - val_accuracy: 0.9840 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 3s 165ms/step - loss: 0.0464 - accuracy: 0.9872 - val_loss: 0.0525 - val_accuracy: 0.9850 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 3s 166ms/step - loss: 0.0409 - accuracy: 0.9886 - val_loss: 0.0476 - val_accuracy: 0.9864 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.0362 - accuracy: 0.9898 - val_loss: 0.0443 - val_accuracy: 0.9874 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 3s 166ms/step - loss: 0.0321 - accuracy: 0.9911 - val_loss: 0.0418 - val_accuracy: 0.9881 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 3s 166ms/step - loss: 0.0290 - accuracy: 0.9921 - val_loss: 0.0400 - val_accuracy: 0.9886 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.0260 - accuracy: 0.9929 - val_loss: 0.0386 - val_accuracy: 0.9890 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.0230 - accuracy: 0.9940 - val_loss: 0.0371 - val_accuracy: 0.9892 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 3s 166ms/step - loss: 0.0207 - accuracy: 0.9947 - val_loss: 0.0356 - val_accuracy: 0.9899 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.0187 - accuracy: 0.9951 - val_loss: 0.0345 - val_accuracy: 0.9902 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 3s 165ms/step - loss: 0.0165 - accuracy: 0.9959 - val_loss: 0.0349 - val_accuracy: 0.9902 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.0151 - accuracy: 0.9962 - val_loss: 0.0351 - val_accuracy: 0.9902 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 0.0135 - accuracy: 0.9967 - val_loss: 0.0354 - val_accuracy: 0.9903 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.0111 - accuracy: 0.9974 - val_loss: 0.0330 - val_accuracy: 0.9907 - lr: 1.0000e-03\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.0102 - accuracy: 0.9977 - val_loss: 0.0327 - val_accuracy: 0.9908 - lr: 1.0000e-03\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.0100 - accuracy: 0.9977 - val_loss: 0.0328 - val_accuracy: 0.9908 - lr: 1.0000e-03\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 3s 165ms/step - loss: 0.0098 - accuracy: 0.9978 - val_loss: 0.0327 - val_accuracy: 0.9908 - lr: 1.0000e-03\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 3s 165ms/step - loss: 0.0096 - accuracy: 0.9979 - val_loss: 0.0328 - val_accuracy: 0.9907 - lr: 1.0000e-03\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 3s 165ms/step - loss: 0.0094 - accuracy: 0.9979 - val_loss: 0.0327 - val_accuracy: 0.9908 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: 0.0327 - val_accuracy: 0.9908 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 3s 164ms/step - loss: 0.0093 - accuracy: 0.9980 - val_loss: 0.0327 - val_accuracy: 0.9908 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 3s 165ms/step - loss: 0.0093 - accuracy: 0.9980 - val_loss: 0.0327 - val_accuracy: 0.9908 - lr: 1.0000e-05\n",
            "\n",
            "Number of units: 256.\n",
            "\n",
            "Model: \"m_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_10 (Bidirecti  (None, 249, 512)         628736    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_11 (Bidirecti  (None, 249, 512)         1574912   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_11 (TimeDi  (None, 249, 46)          23598     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,227,246\n",
            "Trainable params: 2,227,246\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 10s 313ms/step - loss: 4.9793 - accuracy: 0.7717 - val_loss: 2.9831 - val_accuracy: 0.9161 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 3s 221ms/step - loss: 1.7596 - accuracy: 0.9190 - val_loss: 0.7971 - val_accuracy: 0.9231 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 3s 222ms/step - loss: 0.5412 - accuracy: 0.9272 - val_loss: 0.3529 - val_accuracy: 0.9306 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 4s 222ms/step - loss: 0.2901 - accuracy: 0.9322 - val_loss: 0.2401 - val_accuracy: 0.9391 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 3s 221ms/step - loss: 0.2143 - accuracy: 0.9433 - val_loss: 0.1922 - val_accuracy: 0.9503 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.1739 - accuracy: 0.9536 - val_loss: 0.1604 - val_accuracy: 0.9566 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 4s 223ms/step - loss: 0.1449 - accuracy: 0.9612 - val_loss: 0.1358 - val_accuracy: 0.9629 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.1221 - accuracy: 0.9673 - val_loss: 0.1174 - val_accuracy: 0.9669 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 4s 226ms/step - loss: 0.1054 - accuracy: 0.9712 - val_loss: 0.1040 - val_accuracy: 0.9715 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 4s 226ms/step - loss: 0.0924 - accuracy: 0.9747 - val_loss: 0.0932 - val_accuracy: 0.9736 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.0824 - accuracy: 0.9773 - val_loss: 0.0839 - val_accuracy: 0.9766 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 4s 225ms/step - loss: 0.0738 - accuracy: 0.9796 - val_loss: 0.0762 - val_accuracy: 0.9782 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.0669 - accuracy: 0.9812 - val_loss: 0.0711 - val_accuracy: 0.9796 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.0607 - accuracy: 0.9832 - val_loss: 0.0664 - val_accuracy: 0.9812 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.0559 - accuracy: 0.9846 - val_loss: 0.0616 - val_accuracy: 0.9826 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 4s 223ms/step - loss: 0.0520 - accuracy: 0.9857 - val_loss: 0.0584 - val_accuracy: 0.9836 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 4s 222ms/step - loss: 0.0487 - accuracy: 0.9866 - val_loss: 0.0555 - val_accuracy: 0.9846 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 4s 223ms/step - loss: 0.0450 - accuracy: 0.9878 - val_loss: 0.0547 - val_accuracy: 0.9847 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 3s 221ms/step - loss: 0.0419 - accuracy: 0.9886 - val_loss: 0.0505 - val_accuracy: 0.9860 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 4s 222ms/step - loss: 0.0390 - accuracy: 0.9895 - val_loss: 0.0493 - val_accuracy: 0.9862 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 3s 221ms/step - loss: 0.0373 - accuracy: 0.9899 - val_loss: 0.0507 - val_accuracy: 0.9857 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 4s 222ms/step - loss: 0.0356 - accuracy: 0.9903 - val_loss: 0.0472 - val_accuracy: 0.9867 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 4s 223ms/step - loss: 0.0325 - accuracy: 0.9913 - val_loss: 0.0444 - val_accuracy: 0.9874 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 4s 222ms/step - loss: 0.0303 - accuracy: 0.9919 - val_loss: 0.0430 - val_accuracy: 0.9880 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 4s 222ms/step - loss: 0.0290 - accuracy: 0.9923 - val_loss: 0.0423 - val_accuracy: 0.9881 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 4s 222ms/step - loss: 0.0269 - accuracy: 0.9930 - val_loss: 0.0418 - val_accuracy: 0.9883 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.0255 - accuracy: 0.9933 - val_loss: 0.0411 - val_accuracy: 0.9885 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.0240 - accuracy: 0.9938 - val_loss: 0.0396 - val_accuracy: 0.9890 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 4s 223ms/step - loss: 0.0227 - accuracy: 0.9941 - val_loss: 0.0398 - val_accuracy: 0.9889 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.0221 - accuracy: 0.9944 - val_loss: 0.0423 - val_accuracy: 0.9884 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 4s 225ms/step - loss: 0.0214 - accuracy: 0.9944 - val_loss: 0.0393 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.0200 - accuracy: 0.9950 - val_loss: 0.0394 - val_accuracy: 0.9892 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 4s 223ms/step - loss: 0.0182 - accuracy: 0.9954 - val_loss: 0.0385 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 4s 223ms/step - loss: 0.0178 - accuracy: 0.9956 - val_loss: 0.0393 - val_accuracy: 0.9892 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.0163 - accuracy: 0.9960 - val_loss: 0.0376 - val_accuracy: 0.9899 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 4s 223ms/step - loss: 0.0153 - accuracy: 0.9964 - val_loss: 0.0382 - val_accuracy: 0.9896 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.0144 - accuracy: 0.9966 - val_loss: 0.0368 - val_accuracy: 0.9901 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 4s 223ms/step - loss: 0.0132 - accuracy: 0.9971 - val_loss: 0.0375 - val_accuracy: 0.9898 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 4s 223ms/step - loss: 0.0125 - accuracy: 0.9972 - val_loss: 0.0368 - val_accuracy: 0.9902 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 4s 223ms/step - loss: 0.0117 - accuracy: 0.9974 - val_loss: 0.0370 - val_accuracy: 0.9901 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.0101 - accuracy: 0.9979 - val_loss: 0.0356 - val_accuracy: 0.9904 - lr: 1.0000e-03\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 4s 225ms/step - loss: 0.0094 - accuracy: 0.9980 - val_loss: 0.0355 - val_accuracy: 0.9904 - lr: 1.0000e-03\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.0092 - accuracy: 0.9981 - val_loss: 0.0356 - val_accuracy: 0.9904 - lr: 1.0000e-03\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 4s 223ms/step - loss: 0.0091 - accuracy: 0.9981 - val_loss: 0.0356 - val_accuracy: 0.9904 - lr: 1.0000e-03\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 4s 223ms/step - loss: 0.0090 - accuracy: 0.9982 - val_loss: 0.0356 - val_accuracy: 0.9904 - lr: 1.0000e-04\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 4s 225ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.0355 - val_accuracy: 0.9904 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.0355 - val_accuracy: 0.9904 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 4s 223ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.0355 - val_accuracy: 0.9904 - lr: 1.0000e-05\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 4s 224ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.0355 - val_accuracy: 0.9904 - lr: 1.0000e-05\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 4s 222ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.0355 - val_accuracy: 0.9904 - lr: 1.0000e-05\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 4s 223ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.0355 - val_accuracy: 0.9904 - lr: 1.0000e-06\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 4s 223ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.0355 - val_accuracy: 0.9904 - lr: 1.0000e-06\n"
          ]
        }
      ],
      "source": [
        "# Possible units.\n",
        "double_lstm_units = [32, 64, 128, 256]\n",
        "\n",
        "# Computing models and histories.\n",
        "double_lstm_models, double_lstm_model_histories = grid_search(models_name[2], double_lstm_units, baseline_best_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-HZGh7gPCZ3",
        "outputId": "22448d80-4ac3-46cd-a51b-1816f0365a6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 2s 23ms/step\n",
            "41/41 [==============================] - 2s 21ms/step\n",
            "41/41 [==============================] - 2s 25ms/step\n",
            "41/41 [==============================] - 2s 27ms/step\n",
            "The best number of units is: 128.\n"
          ]
        }
      ],
      "source": [
        "# Storing best model.\n",
        "_, double_lstm_f1_scores, models[models_name[2]] = get_best_model(double_lstm_models, double_lstm_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "nXa5naV_dDPV",
        "outputId": "49d9b282-843c-4c8e-eb0f-def3bc8a8e13"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plotting losses and saving figure as .pdf file.\n",
        "plot_training_loss(models_name[2], double_lstm_units, double_lstm_model_histories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "zm-3dM5PldPF",
        "outputId": "0f8683f9-87bc-44e6-ffbb-6ec224c15d5a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plotting scores and saving figure as .pdf file.\n",
        "plot_f1_scores(models_name[2], double_lstm_units, double_lstm_f1_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIOxs5nNC3yG"
      },
      "source": [
        "### Double Dense Layer Model ($m_3$)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wPBLVr5PeUE",
        "outputId": "f6b4e027-eace-4432-ab22-4ec713b36007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid-search, m_3 model.\n",
            "\n",
            "Number of units: 32.\n",
            "\n",
            "Model: \"m_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_12 (Bidirecti  (None, 249, 512)         628736    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_12 (TimeDi  (None, 249, 32)          16416     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 249, 32)           0         \n",
            "                                                                 \n",
            " time_distributed_13 (TimeDi  (None, 249, 46)          1518      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 646,670\n",
            "Trainable params: 646,670\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 6s 192ms/step - loss: 2.3945 - accuracy: 0.8873 - val_loss: 0.7875 - val_accuracy: 0.9326 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.4876 - accuracy: 0.9422 - val_loss: 0.2866 - val_accuracy: 0.9530 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.2105 - accuracy: 0.9587 - val_loss: 0.1540 - val_accuracy: 0.9636 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.1245 - accuracy: 0.9688 - val_loss: 0.1086 - val_accuracy: 0.9713 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0916 - accuracy: 0.9749 - val_loss: 0.0865 - val_accuracy: 0.9755 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0740 - accuracy: 0.9795 - val_loss: 0.0735 - val_accuracy: 0.9791 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0624 - accuracy: 0.9824 - val_loss: 0.0652 - val_accuracy: 0.9814 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0539 - accuracy: 0.9849 - val_loss: 0.0580 - val_accuracy: 0.9832 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0471 - accuracy: 0.9867 - val_loss: 0.0540 - val_accuracy: 0.9844 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0419 - accuracy: 0.9883 - val_loss: 0.0511 - val_accuracy: 0.9854 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0383 - accuracy: 0.9892 - val_loss: 0.0490 - val_accuracy: 0.9859 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0349 - accuracy: 0.9901 - val_loss: 0.0456 - val_accuracy: 0.9868 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0316 - accuracy: 0.9910 - val_loss: 0.0441 - val_accuracy: 0.9874 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0284 - accuracy: 0.9921 - val_loss: 0.0432 - val_accuracy: 0.9877 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0260 - accuracy: 0.9928 - val_loss: 0.0414 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0236 - accuracy: 0.9935 - val_loss: 0.0413 - val_accuracy: 0.9885 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0219 - accuracy: 0.9940 - val_loss: 0.0393 - val_accuracy: 0.9890 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0199 - accuracy: 0.9946 - val_loss: 0.0384 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0181 - accuracy: 0.9952 - val_loss: 0.0390 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0167 - accuracy: 0.9957 - val_loss: 0.0397 - val_accuracy: 0.9894 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0154 - accuracy: 0.9961 - val_loss: 0.0379 - val_accuracy: 0.9896 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0141 - accuracy: 0.9964 - val_loss: 0.0379 - val_accuracy: 0.9898 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0126 - accuracy: 0.9968 - val_loss: 0.0399 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0122 - accuracy: 0.9971 - val_loss: 0.0397 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.0372 - val_accuracy: 0.9900 - lr: 1.0000e-03\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0089 - accuracy: 0.9979 - val_loss: 0.0368 - val_accuracy: 0.9900 - lr: 1.0000e-03\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 0.0369 - val_accuracy: 0.9900 - lr: 1.0000e-03\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.0367 - val_accuracy: 0.9900 - lr: 1.0000e-03\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 0.0369 - val_accuracy: 0.9901 - lr: 1.0000e-03\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 0.0369 - val_accuracy: 0.9900 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 0.0369 - val_accuracy: 0.9900 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 1s 88ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 0.0369 - val_accuracy: 0.9900 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0082 - accuracy: 0.9981 - val_loss: 0.0369 - val_accuracy: 0.9901 - lr: 1.0000e-05\n",
            "\n",
            "Number of units: 64.\n",
            "\n",
            "Model: \"m_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_13 (Bidirecti  (None, 249, 512)         628736    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_14 (TimeDi  (None, 249, 64)          32832     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 249, 64)           0         \n",
            "                                                                 \n",
            " time_distributed_15 (TimeDi  (None, 249, 46)          2990      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 664,558\n",
            "Trainable params: 664,558\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 5s 147ms/step - loss: 2.4007 - accuracy: 0.8975 - val_loss: 0.9780 - val_accuracy: 0.9349 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.5956 - accuracy: 0.9428 - val_loss: 0.3318 - val_accuracy: 0.9533 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.2308 - accuracy: 0.9600 - val_loss: 0.1535 - val_accuracy: 0.9650 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.1210 - accuracy: 0.9709 - val_loss: 0.1029 - val_accuracy: 0.9735 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0858 - accuracy: 0.9766 - val_loss: 0.0800 - val_accuracy: 0.9779 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0688 - accuracy: 0.9805 - val_loss: 0.0701 - val_accuracy: 0.9800 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0588 - accuracy: 0.9832 - val_loss: 0.0633 - val_accuracy: 0.9820 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0517 - accuracy: 0.9853 - val_loss: 0.0572 - val_accuracy: 0.9836 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0458 - accuracy: 0.9869 - val_loss: 0.0556 - val_accuracy: 0.9836 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0419 - accuracy: 0.9879 - val_loss: 0.0503 - val_accuracy: 0.9853 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0383 - accuracy: 0.9891 - val_loss: 0.0479 - val_accuracy: 0.9860 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0344 - accuracy: 0.9900 - val_loss: 0.0462 - val_accuracy: 0.9865 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0323 - accuracy: 0.9906 - val_loss: 0.0439 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0293 - accuracy: 0.9915 - val_loss: 0.0423 - val_accuracy: 0.9877 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0267 - accuracy: 0.9924 - val_loss: 0.0411 - val_accuracy: 0.9880 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0246 - accuracy: 0.9931 - val_loss: 0.0409 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0229 - accuracy: 0.9937 - val_loss: 0.0402 - val_accuracy: 0.9883 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0210 - accuracy: 0.9942 - val_loss: 0.0401 - val_accuracy: 0.9887 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0195 - accuracy: 0.9947 - val_loss: 0.0401 - val_accuracy: 0.9888 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0177 - accuracy: 0.9953 - val_loss: 0.0397 - val_accuracy: 0.9891 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0164 - accuracy: 0.9957 - val_loss: 0.0393 - val_accuracy: 0.9892 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0153 - accuracy: 0.9960 - val_loss: 0.0393 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0141 - accuracy: 0.9964 - val_loss: 0.0406 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0132 - accuracy: 0.9967 - val_loss: 0.0395 - val_accuracy: 0.9896 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 89ms/step - loss: 0.0106 - accuracy: 0.9975 - val_loss: 0.0378 - val_accuracy: 0.9898 - lr: 1.0000e-03\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 0.0376 - val_accuracy: 0.9898 - lr: 1.0000e-03\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0095 - accuracy: 0.9977 - val_loss: 0.0378 - val_accuracy: 0.9898 - lr: 1.0000e-03\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0094 - accuracy: 0.9978 - val_loss: 0.0376 - val_accuracy: 0.9899 - lr: 1.0000e-03\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0093 - accuracy: 0.9978 - val_loss: 0.0377 - val_accuracy: 0.9898 - lr: 1.0000e-03\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0091 - accuracy: 0.9979 - val_loss: 0.0377 - val_accuracy: 0.9899 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.0377 - val_accuracy: 0.9899 - lr: 1.0000e-04\n",
            "\n",
            "Number of units: 128.\n",
            "\n",
            "Model: \"m_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_14 (Bidirecti  (None, 249, 512)         628736    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_16 (TimeDi  (None, 249, 128)         65664     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_16 (Activation)  (None, 249, 128)          0         \n",
            "                                                                 \n",
            " time_distributed_17 (TimeDi  (None, 249, 46)          5934      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_17 (Activation)  (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 700,334\n",
            "Trainable params: 700,334\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 6s 172ms/step - loss: 2.7452 - accuracy: 0.8834 - val_loss: 1.3621 - val_accuracy: 0.9240 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.8026 - accuracy: 0.9347 - val_loss: 0.3930 - val_accuracy: 0.9472 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.2798 - accuracy: 0.9536 - val_loss: 0.1865 - val_accuracy: 0.9608 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.1451 - accuracy: 0.9663 - val_loss: 0.1192 - val_accuracy: 0.9690 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.1003 - accuracy: 0.9725 - val_loss: 0.0935 - val_accuracy: 0.9738 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0809 - accuracy: 0.9769 - val_loss: 0.0801 - val_accuracy: 0.9772 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0690 - accuracy: 0.9804 - val_loss: 0.0716 - val_accuracy: 0.9793 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0599 - accuracy: 0.9829 - val_loss: 0.0645 - val_accuracy: 0.9817 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0531 - accuracy: 0.9847 - val_loss: 0.0607 - val_accuracy: 0.9830 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0482 - accuracy: 0.9861 - val_loss: 0.0552 - val_accuracy: 0.9842 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0442 - accuracy: 0.9871 - val_loss: 0.0523 - val_accuracy: 0.9850 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0404 - accuracy: 0.9883 - val_loss: 0.0501 - val_accuracy: 0.9858 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0375 - accuracy: 0.9891 - val_loss: 0.0476 - val_accuracy: 0.9864 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0346 - accuracy: 0.9900 - val_loss: 0.0463 - val_accuracy: 0.9867 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0315 - accuracy: 0.9910 - val_loss: 0.0445 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0291 - accuracy: 0.9917 - val_loss: 0.0425 - val_accuracy: 0.9880 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0267 - accuracy: 0.9925 - val_loss: 0.0416 - val_accuracy: 0.9881 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0250 - accuracy: 0.9930 - val_loss: 0.0421 - val_accuracy: 0.9881 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0232 - accuracy: 0.9935 - val_loss: 0.0405 - val_accuracy: 0.9887 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0217 - accuracy: 0.9941 - val_loss: 0.0417 - val_accuracy: 0.9886 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0202 - accuracy: 0.9945 - val_loss: 0.0392 - val_accuracy: 0.9890 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0190 - accuracy: 0.9948 - val_loss: 0.0401 - val_accuracy: 0.9889 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 94ms/step - loss: 0.0175 - accuracy: 0.9953 - val_loss: 0.0397 - val_accuracy: 0.9892 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.0397 - val_accuracy: 0.9890 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 94ms/step - loss: 0.0142 - accuracy: 0.9963 - val_loss: 0.0377 - val_accuracy: 0.9896 - lr: 1.0000e-03\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0132 - accuracy: 0.9965 - val_loss: 0.0374 - val_accuracy: 0.9896 - lr: 1.0000e-03\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0129 - accuracy: 0.9966 - val_loss: 0.0374 - val_accuracy: 0.9896 - lr: 1.0000e-03\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 94ms/step - loss: 0.0127 - accuracy: 0.9967 - val_loss: 0.0373 - val_accuracy: 0.9897 - lr: 1.0000e-03\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0126 - accuracy: 0.9967 - val_loss: 0.0373 - val_accuracy: 0.9897 - lr: 1.0000e-03\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0125 - accuracy: 0.9967 - val_loss: 0.0375 - val_accuracy: 0.9896 - lr: 1.0000e-03\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0123 - accuracy: 0.9968 - val_loss: 0.0373 - val_accuracy: 0.9898 - lr: 1.0000e-03\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0373 - val_accuracy: 0.9897 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0373 - val_accuracy: 0.9897 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0374 - val_accuracy: 0.9897 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0121 - accuracy: 0.9969 - val_loss: 0.0374 - val_accuracy: 0.9897 - lr: 1.0000e-05\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0373 - val_accuracy: 0.9897 - lr: 1.0000e-05\n",
            "\n",
            "Number of units: 256.\n",
            "\n",
            "Model: \"m_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_15 (Bidirecti  (None, 249, 512)         628736    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_18 (TimeDi  (None, 249, 256)         131328    \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_18 (Activation)  (None, 249, 256)          0         \n",
            "                                                                 \n",
            " time_distributed_19 (TimeDi  (None, 249, 46)          11822     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_19 (Activation)  (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 771,886\n",
            "Trainable params: 771,886\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 5s 155ms/step - loss: 3.2067 - accuracy: 0.8350 - val_loss: 1.9098 - val_accuracy: 0.9275 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 1.3879 - accuracy: 0.9425 - val_loss: 0.7704 - val_accuracy: 0.9544 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 2s 95ms/step - loss: 0.4960 - accuracy: 0.9601 - val_loss: 0.2833 - val_accuracy: 0.9650 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 0.2038 - accuracy: 0.9698 - val_loss: 0.1476 - val_accuracy: 0.9721 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 0.1175 - accuracy: 0.9759 - val_loss: 0.1018 - val_accuracy: 0.9762 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 95ms/step - loss: 0.0839 - accuracy: 0.9797 - val_loss: 0.0793 - val_accuracy: 0.9795 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 2s 95ms/step - loss: 0.0666 - accuracy: 0.9825 - val_loss: 0.0675 - val_accuracy: 0.9819 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 0.0563 - accuracy: 0.9847 - val_loss: 0.0613 - val_accuracy: 0.9825 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 0.0486 - accuracy: 0.9865 - val_loss: 0.0560 - val_accuracy: 0.9839 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 0.0435 - accuracy: 0.9876 - val_loss: 0.0518 - val_accuracy: 0.9849 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 0.0391 - accuracy: 0.9888 - val_loss: 0.0487 - val_accuracy: 0.9857 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 0.0354 - accuracy: 0.9898 - val_loss: 0.0462 - val_accuracy: 0.9865 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 0.0330 - accuracy: 0.9904 - val_loss: 0.0459 - val_accuracy: 0.9865 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 0.0304 - accuracy: 0.9913 - val_loss: 0.0447 - val_accuracy: 0.9870 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 0.0277 - accuracy: 0.9920 - val_loss: 0.0420 - val_accuracy: 0.9878 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 0.0252 - accuracy: 0.9928 - val_loss: 0.0405 - val_accuracy: 0.9884 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 0.0235 - accuracy: 0.9932 - val_loss: 0.0404 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 0.0224 - accuracy: 0.9935 - val_loss: 0.0397 - val_accuracy: 0.9885 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 0.0202 - accuracy: 0.9942 - val_loss: 0.0396 - val_accuracy: 0.9888 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 0.0187 - accuracy: 0.9947 - val_loss: 0.0387 - val_accuracy: 0.9890 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 0.0390 - val_accuracy: 0.9891 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 0.0165 - accuracy: 0.9954 - val_loss: 0.0394 - val_accuracy: 0.9892 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 0.0150 - accuracy: 0.9958 - val_loss: 0.0393 - val_accuracy: 0.9894 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 0.0126 - accuracy: 0.9966 - val_loss: 0.0374 - val_accuracy: 0.9897 - lr: 1.0000e-03\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0370 - val_accuracy: 0.9899 - lr: 1.0000e-03\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 2s 98ms/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.0369 - val_accuracy: 0.9899 - lr: 1.0000e-03\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 2s 98ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.0370 - val_accuracy: 0.9899 - lr: 1.0000e-03\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 2s 98ms/step - loss: 0.0112 - accuracy: 0.9970 - val_loss: 0.0369 - val_accuracy: 0.9899 - lr: 1.0000e-03\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 2s 100ms/step - loss: 0.0111 - accuracy: 0.9971 - val_loss: 0.0370 - val_accuracy: 0.9899 - lr: 1.0000e-03\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 2s 103ms/step - loss: 0.0110 - accuracy: 0.9971 - val_loss: 0.0373 - val_accuracy: 0.9898 - lr: 1.0000e-03\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 2s 99ms/step - loss: 0.0109 - accuracy: 0.9971 - val_loss: 0.0371 - val_accuracy: 0.9899 - lr: 1.0000e-03\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 2s 98ms/step - loss: 0.0107 - accuracy: 0.9972 - val_loss: 0.0371 - val_accuracy: 0.9900 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 2s 99ms/step - loss: 0.0106 - accuracy: 0.9972 - val_loss: 0.0371 - val_accuracy: 0.9899 - lr: 1.0000e-04\n"
          ]
        }
      ],
      "source": [
        "# Possible units.\n",
        "double_dense_units = [32, 64, 128, 256]\n",
        "\n",
        "# Computing models and histories.\n",
        "double_dense_models, double_dense_model_histories = grid_search(models_name[3], double_dense_units, baseline_best_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSvZYbeoQTnv",
        "outputId": "870c0243-01af-4302-ff55-8bd5095b492f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 1s 12ms/step\n",
            "41/41 [==============================] - 1s 12ms/step\n",
            "41/41 [==============================] - 1s 12ms/step\n",
            "41/41 [==============================] - 1s 13ms/step\n",
            "The best number of units is: 256.\n"
          ]
        }
      ],
      "source": [
        "# Storing best model.\n",
        "_, double_dense_f1_scores, models[models_name[3]] = get_best_model(double_dense_models, double_dense_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "2a2RUiMSdRca",
        "outputId": "ffee0117-1c37-448e-f620-e6a23b7f5d54"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plotting losses and saving figure as .pdf file.\n",
        "plot_training_loss(models_name[3], double_dense_units, double_dense_model_histories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "WW_w2k22livM",
        "outputId": "04310142-a9fc-497e-91b3-6d0e76b87c76"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plotting scores and saving figure as .pdf file.\n",
        "plot_f1_scores(models_name[3], double_dense_units, double_dense_f1_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcGpnTPPXLS4",
        "outputId": "faa515d4-9aad-407d-f637-97f9f095edee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 1s 21ms/step\n",
            "The macro F1-score for model m_0 is: 0.7273296529644282.\n",
            "41/41 [==============================] - 1s 10ms/step\n",
            "The macro F1-score for model m_1 is: 0.6286681630831981.\n",
            "41/41 [==============================] - 2s 43ms/step\n",
            "The macro F1-score for model m_2 is: 0.7068958913570299.\n",
            "41/41 [==============================] - 1s 26ms/step\n",
            "The macro F1-score for model m_3 is: 0.7031121499201956.\n"
          ]
        }
      ],
      "source": [
        "# Models macro F1-scores.\n",
        "models_score = {}\n",
        "\n",
        "# Computing macro F1-scores on the four models selected with grid-search.\n",
        "for model in models:\n",
        "\n",
        "  # Computing macro F1-score.\n",
        "  models_score[model] = compute_F1_score(models[model], validation_features, validation_tags, tag_to_index)[0]\n",
        "\n",
        "  # Computing and printing macro F1-score.\n",
        "  print(f\"The macro F1-score for model {model} is: {models_score[model]}.\")\n",
        "\n",
        "# Storing the two best models.\n",
        "best_models = sorted(models_score, key = models_score.get, reverse = True)[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXJiM4jgQuAb"
      },
      "source": [
        "## Models Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2BQysorQxR3",
        "outputId": "f53beae5-19c1-4545-d663-ed5559635135"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline model (m_0): \n",
            " - Bi-directional LSTM layer. \n",
            " - Time-distributed dense layer. \n",
            " - Softmax activation function.\n",
            "\n",
            "21/21 [==============================] - 0s 18ms/step\n",
            "The macro F1-score, on the test set, for model m_0 is: 0.7219506363115593.\n",
            "\n",
            "Double bi-directional LSTM model (m_2): \n",
            " - Bi-directional LSTM layer. \n",
            " - Bi-directional LSTM layer. \n",
            " - Time-distributed dense layer. \n",
            " - Softmax activation function.\n",
            "\n",
            "21/21 [==============================] - 1s 25ms/step\n",
            "The macro F1-score, on the test set, for model m_2 is: 0.7248297840620403.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Dictionary of predictions of the two best models.\n",
        "best_pred = {}\n",
        "\n",
        "# Testing the two best models.\n",
        "for model in best_models:\n",
        "\n",
        "  # Printing the description of the two best models.\n",
        "  print(f\"{descriptions_dict[model]}\\n\")\n",
        "\n",
        "  # Computing predictions and f1-score.\n",
        "  f1_score, best_pred[model] = compute_F1_score(models[model], test_features, test_tags, tag_to_index)\n",
        "\n",
        "  # Printing macro F1-score.\n",
        "  print(f\"The macro F1-score, on the test set, for model {model} is: {f1_score}.\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Error Analysis"
      ],
      "metadata": {
        "id": "mzcYbRABcNfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: confusion matrices, recall, precision, comparison between validation and test results."
      ],
      "metadata": {
        "id": "YiEit8vQcTpr"
      },
      "execution_count": 41,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}