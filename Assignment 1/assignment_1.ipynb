{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "    <h1> Natural Language Processing</h1>\n",
        "    <h2> Assignment 1 </h2>\n",
        "    <a href=\"mailto:ildebrando.simeoni@studio.unibo.it\">Ildebrando Simeoni</a>, <a href=\"mailto:diego.biagini2@studio.unibo.it\">Diego Biagini</a>, <a href=\"mailto:matteo.donati10@studio.unibo.it\">Matteo Donati</a>\n",
        "</center>\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "dzbv4ZVhdC7F"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OBJyXJaTZzd"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "C7sW4HdzTURu"
      },
      "outputs": [],
      "source": [
        "# Importing os.\n",
        "import os\n",
        "\n",
        "# Importing urllib.request.\n",
        "import urllib.request\n",
        "\n",
        "# Importing zipfile.\n",
        "import zipfile\n",
        "\n",
        "# Importing pandas.\n",
        "import pandas as pd\n",
        "\n",
        "# Importing numpy.\n",
        "import numpy as np\n",
        "\n",
        "# Importing random.\n",
        "import random\n",
        "\n",
        "# Importing tensorflow.\n",
        "import tensorflow as tf\n",
        "\n",
        "# Importing pad_sequences.\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Importing Sequential.\n",
        "from keras.models import Sequential\n",
        "\n",
        "# Importing Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation.\n",
        "from keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding, Activation, GRU\n",
        "\n",
        "# Importing L2.\n",
        "from keras.regularizers import l2\n",
        "\n",
        "# Importing Adam.\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Importing EarlyStopping and ReduceLROnPlateau.\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Importing classification_report.\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Importing pyplot.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sets reproducibility.\n",
        "def set_reproducibility(seed):\n",
        "\n",
        "  # Setting seeds.\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  tf.random.set_seed(seed)\n",
        "  os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "  os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
        "  os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
        "\n",
        "# Setting seed.\n",
        "set_reproducibility(seed = 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9thEzbNTfiz"
      },
      "source": [
        "## Dataset Analysis and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hOWsBikzhqq8"
      },
      "outputs": [],
      "source": [
        "# Function used to download .zips.\n",
        "def downloader(url, folder_name, filename):\n",
        "\n",
        "  # Defining data folder path.\n",
        "  data_path = os.path.join(os.getcwd(), folder_name)\n",
        "\n",
        "  # Creating data folder.\n",
        "  if not os.path.exists(data_path):\n",
        "      os.makedirs(data_path)\n",
        "\n",
        "  # Defining .zip file path.\n",
        "  zip_path = os.path.join(os.getcwd(), folder_name, filename)\n",
        "\n",
        "  # Requesting .zip file.\n",
        "  if not os.path.exists(zip_path):\n",
        "      urllib.request.urlretrieve(url, zip_path)\n",
        "\n",
        "  # Extracting data from .zip.\n",
        "  with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "      zip_ref.extractall(path = data_path)\n",
        "\n",
        "  # Returning data_path and zip_path.\n",
        "  return data_path, zip_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7f3f0k3KTcr3"
      },
      "outputs": [],
      "source": [
        "# Downloading dataset.\n",
        "data_path, _ = downloader(url = \"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\", folder_name = \"data\", filename = \"dependency_treebank.zip\")\n",
        "\n",
        "# Downloading glove.\n",
        "glove_path, _ = downloader(url = \"https://nlp.stanford.edu/data/glove.6B.zip\", folder_name = \"glove\", filename = \"glove.6B.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZDEgowtTqYf",
        "outputId": "05344df4-d711-47e0-c88f-f9323e07d832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pierre\tNNP\t2\n",
            "Vinken\tNNP\t8\n",
            ",\t,\t2\n",
            "61\tCD\t5\n",
            "years\tNNS\t6\n",
            "old\tJJ\t2\n",
            ",\t,\t2\n",
            "will\tMD\t0\n",
            "join\tVB\t8\n",
            "the\tDT\t11\n",
            "board\tNN\t9\n",
            "as\tIN\t9\n",
            "a\tDT\t15\n",
            "nonexecutive\tJJ\t15\n",
            "director\tNN\t12\n",
            "Nov.\tNNP\t9\n",
            "29\tCD\t16\n",
            ".\t.\t8\n",
            "\n",
            "Mr.\tNNP\t2\n",
            "Vinken\tNNP\t3\n",
            "is\tVBZ\t0\n",
            "chairman\tNN\t3\n",
            "of\tIN\t4\n",
            "Elsevier\tNNP\t7\n",
            "N.V.\tNNP\t12\n",
            ",\t,\t12\n",
            "the\tDT\t12\n",
            "Dutch\tNNP\t12\n",
            "publishing\tVBG\t12\n",
            "group\tNN\t5\n",
            ".\t.\t3\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Defining the dataset name.\n",
        "dataset_name = \"dependency_treebank\"\n",
        "\n",
        "# Defining path to first training sample.\n",
        "file_path = os.path.join(data_path, dataset_name, \"wsj_0001.dp\")\n",
        "\n",
        "# Reading first training sample.\n",
        "if os.path.isfile(file_path):\n",
        "\n",
        "  # Printing file.\n",
        "  with open(file_path, mode = \"r\") as text_file: print(text_file.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TkeSn0ePqsG2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3346b4ff-549d-4b55-89df-4bf184be4d45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The embedding for 'the' is:\n",
            "[ 4.1800e-01  2.4968e-01 -4.1242e-01  1.2170e-01  3.4527e-01 -4.4457e-02\n",
            " -4.9688e-01 -1.7862e-01 -6.6023e-04 -6.5660e-01  2.7843e-01 -1.4767e-01\n",
            " -5.5677e-01  1.4658e-01 -9.5095e-03  1.1658e-02  1.0204e-01 -1.2792e-01\n",
            " -8.4430e-01 -1.2181e-01 -1.6801e-02 -3.3279e-01 -1.5520e-01 -2.3131e-01\n",
            " -1.9181e-01 -1.8823e+00 -7.6746e-01  9.9051e-02 -4.2125e-01 -1.9526e-01\n",
            "  4.0071e+00 -1.8594e-01 -5.2287e-01 -3.1681e-01  5.9213e-04  7.4449e-03\n",
            "  1.7778e-01 -1.5897e-01  1.2041e-02 -5.4223e-02 -2.9871e-01 -1.5749e-01\n",
            " -3.4758e-01 -4.5637e-02 -4.4251e-01  1.8785e-01  2.7849e-03 -1.8411e-01\n",
            " -1.1514e-01 -7.8581e-01].\n"
          ]
        }
      ],
      "source": [
        "# Defining embedding size.\n",
        "EMBEDDING_SIZE = 50\n",
        "\n",
        "# Defining specific glove's file path.\n",
        "glove_file = os.path.join(os.getcwd(), glove_path, f\"glove.6B.{str(EMBEDDING_SIZE)}d.txt\")\n",
        "\n",
        "# Reading lines of file.\n",
        "with open(glove_file, encoding = \"utf8\" ) as text_file: \n",
        "  lines = text_file.readlines()\n",
        "\n",
        "# Defining initial vocabulary.\n",
        "embedding_vocabulary = {}\n",
        "\n",
        "# Reading single lines.\n",
        "for line in lines:\n",
        "\n",
        "  # Splitting line.\n",
        "  splits = line.split()\n",
        "\n",
        "  # Storing line into vocabulary.\n",
        "  embedding_vocabulary[splits[0]] = np.array([float(val) for val in splits[1:]])\n",
        "\n",
        "# Printing one entry of the vocabulary.\n",
        "print(\"The embedding for 'the' is:\\n{}.\".format(embedding_vocabulary[\"the\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KACvAIENUlQ2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b62870cb-6c15-413c-d1e5-503c1dca0342"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   file_id                                           sentence  \\\n",
              "0        1  [Pierre, Vinken, ,, 61, years, old, ,, will, j...   \n",
              "1        1  [Mr., Vinken, is, chairman, of, Elsevier, N.V....   \n",
              "2        2  [Rudolph, Agnew, ,, 55, years, old, and, forme...   \n",
              "3        3  [A, form, of, asbestos, once, used, to, make, ...   \n",
              "4        3  [The, asbestos, fiber, ,, crocidolite, ,, is, ...   \n",
              "\n",
              "                                                tags  \\\n",
              "0  [NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...   \n",
              "1  [NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...   \n",
              "2  [NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...   \n",
              "3  [DT, NN, IN, NN, RB, VBN, TO, VB, NNP, NN, NNS...   \n",
              "4  [DT, NN, NN, ,, NN, ,, VBZ, RB, JJ, IN, PRP, V...   \n",
              "\n",
              "                                            features  \n",
              "0  [[0.23568, 0.39638, -0.60135, -0.52681, 0.1587...  \n",
              "1  [[0.006008, 0.57028, -0.064426, -0.044687, 0.8...  \n",
              "2  [[0.86274, 0.056588, -0.081828, -0.35318, -0.0...  \n",
              "3  [[0.21705, 0.46515, -0.46757, 0.10082, 1.0135,...  \n",
              "4  [[0.418, 0.24968, -0.41242, 0.1217, 0.34527, -...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1cc0c485-fb5c-4c4a-9e84-f17217349209\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>tags</th>\n",
              "      <th>features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[Pierre, Vinken, ,, 61, years, old, ,, will, j...</td>\n",
              "      <td>[NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...</td>\n",
              "      <td>[[0.23568, 0.39638, -0.60135, -0.52681, 0.1587...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[Mr., Vinken, is, chairman, of, Elsevier, N.V....</td>\n",
              "      <td>[NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...</td>\n",
              "      <td>[[0.006008, 0.57028, -0.064426, -0.044687, 0.8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[Rudolph, Agnew, ,, 55, years, old, and, forme...</td>\n",
              "      <td>[NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...</td>\n",
              "      <td>[[0.86274, 0.056588, -0.081828, -0.35318, -0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[A, form, of, asbestos, once, used, to, make, ...</td>\n",
              "      <td>[DT, NN, IN, NN, RB, VBN, TO, VB, NNP, NN, NNS...</td>\n",
              "      <td>[[0.21705, 0.46515, -0.46757, 0.10082, 1.0135,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>[The, asbestos, fiber, ,, crocidolite, ,, is, ...</td>\n",
              "      <td>[DT, NN, NN, ,, NN, ,, VBZ, RB, JJ, IN, PRP, V...</td>\n",
              "      <td>[[0.418, 0.24968, -0.41242, 0.1217, 0.34527, -...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1cc0c485-fb5c-4c4a-9e84-f17217349209')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1cc0c485-fb5c-4c4a-9e84-f17217349209 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1cc0c485-fb5c-4c4a-9e84-f17217349209');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Function used to get a list of embeddings.\n",
        "def get_embeddings(sentence, vocabulary, embedding_size):\n",
        "\n",
        "  # List of embeddings for the input sentence.\n",
        "  embeddings = []\n",
        "\n",
        "  # Retrieving embedding vector for each word.\n",
        "  for word in sentence:\n",
        "\n",
        "    # Computing the embedding.\n",
        "    embedding = vocabulary.get(word.lower())\n",
        "\n",
        "    # Checking the embedding.\n",
        "    if embedding is not None:\n",
        "      \n",
        "      # Populating the list of embeddings.\n",
        "      embeddings.append(embedding)\n",
        "    \n",
        "    else:\n",
        "\n",
        "      # Storing vector of zeros for OOV terms.\n",
        "      embeddings.append(list(np.zeros(embedding_size)))\n",
        "\n",
        "  # Returning list of embeddings.\n",
        "  return embeddings\n",
        "\n",
        "# List containing dataframe rows.\n",
        "dataframe_rows = []\n",
        "\n",
        "# List containing words of a single sentence.\n",
        "row_words = []\n",
        "\n",
        "# List containing tags of a single sentence.\n",
        "row_tags = []\n",
        "\n",
        "# Defining data folder path.\n",
        "folder = os.path.join(data_path, dataset_name)\n",
        "\n",
        "# Storing rows.\n",
        "for filename in sorted(os.listdir(folder)):\n",
        "\n",
        "  # Computing path to file.\n",
        "  file_path = os.path.join(folder, filename)\n",
        "\n",
        "  # Checking existance of file.\n",
        "  if os.path.isfile(file_path):\n",
        "\n",
        "    # Opening the file.\n",
        "    with open(file_path, mode = \"r\") as text_file:\n",
        "\n",
        "      # Reading lines.\n",
        "      while True:\n",
        "\n",
        "        # Reading next line.\n",
        "        line = text_file.readline()\n",
        "\n",
        "        # Checking that line is different from \"\\n\" (empty line) and from last line (EOF).\n",
        "        if line and line != \"\\n\":\n",
        "\n",
        "          # Storing the word.\n",
        "          row_words.append(line.split()[0])\n",
        "\n",
        "          # Storing the POS tag.\n",
        "          row_tags.append(line.split()[1])\n",
        "\n",
        "        # Creating new dataframe row.\n",
        "        else:\n",
        "\n",
        "          # Creating a row.\n",
        "          dataframe_row = {\"file_id\": int(filename.split(\".\")[0].split(\"_\")[1]), \n",
        "                           \"sentence\": row_words, \n",
        "                           \"tags\": row_tags, \n",
        "                           \"features\": get_embeddings(row_words, embedding_vocabulary, EMBEDDING_SIZE)}\n",
        "\n",
        "          # Appending row.\n",
        "          dataframe_rows.append(dataframe_row)\n",
        "\n",
        "          # Resetting row_words list so to store a new sentence.\n",
        "          row_words = []\n",
        "\n",
        "          # Resetting row_tags list so to store a new sentence.\n",
        "          row_tags = []\n",
        "\n",
        "          # If, in particular, EOF is reached, then break the inner loop.\n",
        "          if not line: break\n",
        "\n",
        "# Creating pandas dataframe.\n",
        "dataframe = pd.DataFrame(dataframe_rows)\n",
        "\n",
        "# Printing dataframe head.\n",
        "dataframe.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "51jxVKeVa0C3"
      },
      "outputs": [],
      "source": [
        "# Defining training split.\n",
        "TRAINING_SPLIT = range(1, 101)\n",
        "\n",
        "# Defining validation split.\n",
        "VALIDATION_SPLIT = range(101, 151)\n",
        "\n",
        "# Defining test split.\n",
        "TEST_SPLIT = range(151, 200)\n",
        "\n",
        "# Computing train dataframe.\n",
        "train = dataframe.loc[dataframe[\"file_id\"].isin(TRAINING_SPLIT)]\n",
        "\n",
        "# Computing validation dataframe.\n",
        "validation = dataframe.loc[dataframe[\"file_id\"].isin(VALIDATION_SPLIT)]\n",
        "\n",
        "# Computing test dataframe.\n",
        "test = dataframe.loc[dataframe[\"file_id\"].isin(TEST_SPLIT)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jC61XX7MAJoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fc1de7d-080c-4e30-cf0b-4029b292a030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataframe consists of 3914 sentences:\n",
            " - 1963 of these sentences define the training set.\n",
            " - 1299 of these sentences define the validation set.\n",
            " - 652 of these sentences define the test set.\n"
          ]
        }
      ],
      "source": [
        "# Printing total number of sentences.\n",
        "print(f\"The dataframe consists of {len(dataframe)} sentences:\")\n",
        "\n",
        "# Printing number of training sentences.\n",
        "print(f\" - {len(train)} of these sentences define the training set.\")\n",
        "\n",
        "# Printing number of validation sentences.\n",
        "print(f\" - {len(validation)} of these sentences define the validation set.\")\n",
        "\n",
        "# Printing number of test sentences.\n",
        "print(f\" - {len(test)} of these sentences define the test set.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "jTgbsNPNoI9g"
      },
      "outputs": [],
      "source": [
        "# Computing length of longest train sentence.\n",
        "MAX_LENGTH = len(max(train[\"sentence\"].tolist(), key = len))\n",
        "\n",
        "# Padding train features.\n",
        "train_features = pad_sequences(train[\"features\"].tolist(), maxlen = MAX_LENGTH, padding = \"post\", dtype = \"float32\")\n",
        "\n",
        "# Padding validation features.\n",
        "validation_features = pad_sequences(validation[\"features\"].tolist(), maxlen = MAX_LENGTH, padding = \"post\", dtype = \"float32\")\n",
        "\n",
        "# Padding test features.\n",
        "test_features = pad_sequences(test[\"features\"].tolist(), maxlen = MAX_LENGTH, padding = \"post\", dtype = \"float32\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing all training tags. The training set already contains all of them.\n",
        "train_tags = [item for sublist in train[\"tags\"].tolist() for item in sublist]\n",
        "\n",
        "# Storing all validation tags.\n",
        "validation_tags = [item for sublist in validation[\"tags\"].tolist() for item in sublist]\n",
        "\n",
        "# Storing all test tags.\n",
        "test_tags = [item for sublist in test[\"tags\"].tolist() for item in sublist]\n",
        "\n",
        "# Removing duplicates from train_tags. By using a dict instead of a set I can get reproducible results (sets are not ordered).\n",
        "tags = list(dict.fromkeys(train_tags))"
      ],
      "metadata": {
        "id": "I3fKMnEEOKg7"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gzIGFLjNibLW"
      },
      "outputs": [],
      "source": [
        "# Punctuation tag list.\n",
        "punctuation_tag_list = [\"PAD\", \",\", \".\", \"``\", \"''\", \":\", \"$\", \"#\"]\n",
        "\n",
        "# Defining figures folder path.\n",
        "figures_path = os.path.join(os.getcwd(), \"figures\")\n",
        "\n",
        "# Creating data folder.\n",
        "if not os.path.exists(figures_path): os.makedirs(figures_path)\n",
        "\n",
        "# Function used to plot classes distribution.\n",
        "def plot_classes_distribution(classes, counts, filename, figures_path = figures_path):\n",
        "\n",
        "  # Defining figure.\n",
        "  fig, ax = plt.subplots(1, 1, figsize = (9, 4))\n",
        "\n",
        "  # Plotting counts.\n",
        "  bars = ax.bar(np.arange(0, len(classes), 1), counts)\n",
        "\n",
        "  # Setting opacity to punctuation bars.\n",
        "  for i in range(len(classes)): \n",
        "    if classes[i] in punctuation_tag_list: bars[i].set_alpha(0.5)\n",
        "\n",
        "  # Setting x label.\n",
        "  ax.set_xlabel(\"Class\")\n",
        "\n",
        "  # Setting y label.\n",
        "  ax.set_ylabel(\"Count\")\n",
        "\n",
        "  # Setting y scale.\n",
        "  ax.set_yscale(\"log\")\n",
        "\n",
        "  # Setting xticks.\n",
        "  ax.set_xticks(np.arange(0, len(classes), 1))\n",
        "\n",
        "  # Setting xticklabels.\n",
        "  ax.set_xticklabels(classes, rotation = 90)\n",
        "\n",
        "  # Saving figure.\n",
        "  fig.savefig(f\"{figures_path}/{filename}_classes_distribution.pdf\", bbox_inches = \"tight\")\n",
        "\n",
        "  # Showing the plot.\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting distribution.\n",
        "plot_classes_distribution(tags, [train_tags.count(tag) for tag in tags], \"training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "ZTo2sTuKQC62",
        "outputId": "fbb59e0c-59f1-4a32-ea6e-d4b5ae746df7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting distribution.\n",
        "plot_classes_distribution(tags, [validation_tags.count(tag) for tag in tags], \"validation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "A1FsN3QSQFj6",
        "outputId": "8d9a714a-b799-45c7-d0d6-303d4981c1e2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting distribution.\n",
        "plot_classes_distribution(tags, [test_tags.count(tag) for tag in tags], \"test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "w-tjEtOlQHxO",
        "outputId": "6b3fa4c2-14cb-42d4-8dcf-6e9dace242e1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocabulary for tags.\n",
        "tag_to_index = {}\n",
        "\n",
        "# PAD is mapped onto 0.\n",
        "tag_to_index[\"PAD\"] = 0\n",
        "\n",
        "# All other tags are mapped onto other indexes, starting from 1 up to |tags|.\n",
        "for i, tag in enumerate(list(tags)): tag_to_index[tag] = i + 1\n",
        "\n",
        "# Function used to transform list of tags into vectors of integers using a tag-to-index vocabulary.\n",
        "def convert_tags(input_tags, vocabulary):\n",
        "\n",
        "  # Output tags.\n",
        "  output_tags = []\n",
        "\n",
        "  # Converting input tags.\n",
        "  for tags_list in input_tags:\n",
        "\n",
        "    # Computing index.\n",
        "    output_tags.append([vocabulary[tag] for tag in tags_list])\n",
        "\n",
        "  # Returning output_tags.\n",
        "  return output_tags\n",
        "\n",
        "# Computing train tags.\n",
        "train_tags = convert_tags(input_tags = train[\"tags\"].tolist(), vocabulary = tag_to_index)\n",
        "\n",
        "# Computing validation tags.\n",
        "validation_tags = convert_tags(input_tags = validation[\"tags\"].tolist(), vocabulary = tag_to_index)\n",
        "\n",
        "# Computing test tags.\n",
        "test_tags = convert_tags(input_tags = test[\"tags\"].tolist(), vocabulary = tag_to_index)\n",
        "\n",
        "# Padding train tags.\n",
        "train_tags = pad_sequences(train_tags, maxlen = MAX_LENGTH, padding = \"post\")\n",
        "\n",
        "# Padding validation tags.\n",
        "validation_tags = pad_sequences(validation_tags, maxlen = MAX_LENGTH, padding = \"post\")\n",
        "\n",
        "# Padding test tags.\n",
        "test_tags = pad_sequences(test_tags, maxlen = MAX_LENGTH, padding = \"post\")"
      ],
      "metadata": {
        "id": "MPrVCjEzCr7E"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eefy9o5A6e6x"
      },
      "source": [
        "## Models Definition and Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HFHMaanl2IRf"
      },
      "outputs": [],
      "source": [
        "# List of models' names.\n",
        "models_name = [\"m_0\", \"m_1\", \"m_2\", \"m_3\"]\n",
        "\n",
        "# Dictionary of models' description.\n",
        "descriptions_dict = {models_name[0]: (f\"Baseline model ({models_name[0]}): \\n\"\n",
        "                                      \" - Bi-directional LSTM layer. \\n\"\n",
        "                                      \" - Time-distributed dense layer. \\n\"\n",
        "                                      \" - Softmax activation function.\"),\n",
        "                     models_name[1]: (f\"BiGRU model ({models_name[1]}): \\n\"\n",
        "                                      \" - Bi-directional GRU layer. \\n\"\n",
        "                                      \" - Time-distributed dense layer. \\n\"\n",
        "                                      \" - Softmax activation function.\"),\n",
        "                     models_name[2]: (f\"Additional bi-directional LSTM model ({models_name[2]}): \\n\"\n",
        "                                      \" - Bi-directional LSTM layer. \\n\"\n",
        "                                      \" - Bi-directional LSTM layer. \\n\"\n",
        "                                      \" - Time-distributed dense layer. \\n\"\n",
        "                                      \" - Softmax activation function.\"),\n",
        "                     models_name[3]: (f\"Additional dense layer model ({models_name[3]}): \\n\"\n",
        "                                      \" - Bi-directional LSTM layer. \\n\"\n",
        "                                      \" - Time-distributed dense layer. \\n\"\n",
        "                                      \" - ReLU activation function. \\n\"\n",
        "                                      \" - Time-distributed dense layer. \\n\"\n",
        "                                      \" - Softmax activation function.\")}\n",
        "\n",
        "# Dictionary of models.\n",
        "models = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "5zt4AACHGSNA"
      },
      "outputs": [],
      "source": [
        "# Batch size.\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# Epochs.\n",
        "EPOCHS = 100\n",
        "\n",
        "# Initial learning rate.\n",
        "LR = 0.01\n",
        "\n",
        "# Weight decay parameter.\n",
        "REG = 0.01\n",
        "\n",
        "# Early stopping callback.\n",
        "early_stopping = EarlyStopping(monitor = \"val_loss\", patience = 5, restore_best_weights = True)\n",
        "\n",
        "# Reduce learning rate on plateau callback.\n",
        "reduce_lr = ReduceLROnPlateau(monitor = \"val_loss\", patience = 3, factor = 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "UzNmDy4dLmjL"
      },
      "outputs": [],
      "source": [
        "# Function that creates the model.\n",
        "def get_model(name, layers, input_shape):\n",
        "\n",
        "  # Sequential model.\n",
        "  model = Sequential()\n",
        "\n",
        "  # Adding input layer.\n",
        "  model.add(InputLayer(input_shape = input_shape))\n",
        "\n",
        "  # Adding layers.\n",
        "  for layer in layers:\n",
        "\n",
        "    # Adding layers.\n",
        "    model.add(layer)\n",
        "  \n",
        "  # Output dense layer.\n",
        "  model.add(TimeDistributed(Dense(len(tag_to_index))))\n",
        "\n",
        "  # Softmax.\n",
        "  model.add(Activation(\"softmax\"))\n",
        "\n",
        "  # Adding a name to the model.\n",
        "  model._name = name\n",
        "\n",
        "  # Returning the model.\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_ziwP6lcHh6q"
      },
      "outputs": [],
      "source": [
        "# Function used to grid-search.\n",
        "def grid_search(model_name, units, best_baseline_LSTM_units = None):\n",
        "\n",
        "  # List of models obtained during grid-search.\n",
        "  models = []\n",
        "\n",
        "  # List of histories.\n",
        "  histories = []\n",
        "\n",
        "  # Printing description of the model.\n",
        "  print(f\"Grid-search, {model_name} model.\")\n",
        "\n",
        "  # Grid-search over possible number of units so to find the best model.\n",
        "  for n in units:\n",
        "\n",
        "    # Checking model name.\n",
        "    if model_name == \"m_0\":\n",
        "\n",
        "      # List of layers.\n",
        "      layers = [Bidirectional(LSTM(n, return_sequences = True, recurrent_regularizer = l2(REG)))]\n",
        "    \n",
        "    elif model_name == \"m_1\":\n",
        "\n",
        "      # List of layers.\n",
        "      layers = [Bidirectional(GRU(n, return_sequences = True, recurrent_regularizer = l2(REG)))]\n",
        "\n",
        "    elif model_name == \"m_2\" and best_baseline_LSTM_units != None:\n",
        "\n",
        "      # List of layers.\n",
        "      layers = [Bidirectional(LSTM(best_baseline_LSTM_units, return_sequences = True, recurrent_regularizer = l2(REG))),\n",
        "                Bidirectional(LSTM(n, return_sequences = True, recurrent_regularizer = l2(REG)))]\n",
        "\n",
        "    elif model_name == \"m_3\" and best_baseline_LSTM_units != None:\n",
        "\n",
        "      # List of layers.\n",
        "      layers = [Bidirectional(LSTM(best_baseline_LSTM_units, return_sequences = True, recurrent_regularizer = l2(REG))),\n",
        "                TimeDistributed(Dense(n)),\n",
        "                Activation(\"relu\")]\n",
        "\n",
        "    # Creating the double lstm model.\n",
        "    model = get_model(name = model_name, layers = layers, input_shape = (MAX_LENGTH, EMBEDDING_SIZE))\n",
        "\n",
        "    # Compiling.\n",
        "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = Adam(LR), metrics = [\"accuracy\"])\n",
        "\n",
        "    # Storing model.\n",
        "    models.append(model)\n",
        "\n",
        "    # Printing info.\n",
        "    print(f\"\\nNumber of units: {n}.\\n\")\n",
        "\n",
        "    # Printing summary.\n",
        "    models[-1].summary()\n",
        "\n",
        "    # Fitting the model.\n",
        "    history = models[-1].fit(train_features, train_tags, batch_size = BATCH_SIZE, epochs = EPOCHS, validation_data = (validation_features, validation_tags), callbacks = [early_stopping, reduce_lr])\n",
        "\n",
        "    # Storing history.\n",
        "    histories.append(history)\n",
        "\n",
        "  # Returning models and histories.\n",
        "  return models, histories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "i1oYG_Kj40Km"
      },
      "outputs": [],
      "source": [
        "# Function used to compute macro F1-score.\n",
        "def compute_F1_score(model, X, y, tag_to_index_vocabulary):\n",
        "\n",
        "  # Computing predictions.\n",
        "  pred = model.predict(X)\n",
        "\n",
        "  # Computing classification report.\n",
        "  report = classification_report(y.flatten(), \n",
        "                                 np.argmax(pred, axis = 2).flatten(), \n",
        "                                 labels = np.arange(0, len(tag_to_index_vocabulary), 1),\n",
        "                                 target_names = list(tag_to_index_vocabulary.keys()),\n",
        "                                 zero_division = 0,\n",
        "                                 output_dict = True)\n",
        "\n",
        "  # Macro F1-score without punctuation classes.\n",
        "  macro_f1 = 0\n",
        "\n",
        "  # Iterating over classes.\n",
        "  for tag in list(tag_to_index_vocabulary.keys()):\n",
        "\n",
        "    # Updating the macro F1-score.\n",
        "    if tag not in punctuation_tag_list: macro_f1 = macro_f1 + report[tag][\"f1-score\"]\n",
        "\n",
        "  # Dividing macro F1-score with the number of non-punctuation classes.\n",
        "  macro_f1 = macro_f1 / (len(list(tag_to_index_vocabulary.keys())) - len(punctuation_tag_list))\n",
        "\n",
        "  # Returning macro F1-score and predictions.\n",
        "  return macro_f1, pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "O1R8c9swIzIA"
      },
      "outputs": [],
      "source": [
        "# Function used to get the best model among a set of models.\n",
        "def get_best_model(models, units):\n",
        "\n",
        "  # Computing F1-scores.\n",
        "  f1_scores = [compute_F1_score(model, validation_features, validation_tags, tag_to_index)[0] for model in models]\n",
        "\n",
        "  # Computing best number of units .\n",
        "  best = units[np.argmax(f1_scores)]\n",
        "\n",
        "  # Printing best number of units.\n",
        "  print(f\"The best number of units is: {best}.\")\n",
        "\n",
        "  # Returning the best model.\n",
        "  return best, f1_scores, models[np.argmax(f1_scores)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Ti49IGGKJPpG"
      },
      "outputs": [],
      "source": [
        "# Function used to plot training losses.\n",
        "def plot_training_loss(model_name, units, histories, figures_path = figures_path):\n",
        "\n",
        "  # Computing best epoch for each model.\n",
        "  best_epochs = [np.argmin(history.history[\"val_loss\"]) + 1 for history in histories]\n",
        "\n",
        "  # Creating the figure and axes.\n",
        "  fig, ax = plt.subplots(1, 1, figsize = (4, 4))\n",
        "\n",
        "  # Plotting every history.\n",
        "  for i in range(len(units)):\n",
        "\n",
        "    # Computing the x axis array.\n",
        "    x = np.arange(1, len(histories[i].history[\"val_loss\"]) + 1, 1)\n",
        "\n",
        "    # Plotting validation loss.\n",
        "    ax.plot(x, histories[i].history[\"val_loss\"], label = r\"${}^{}$\".format(model_name, i + 1))\n",
        "\n",
        "  # Setting labels.\n",
        "  ax.set_ylabel(\"Loss\")\n",
        "\n",
        "  # Setting labels.\n",
        "  ax.set_xlabel(\"Epoch\")\n",
        "\n",
        "  # Displying legend.\n",
        "  ax.legend()\n",
        "\n",
        "  # Saving the figure.\n",
        "  fig.savefig(f\"{figures_path}/val_loss_{model_name}.pdf\", bbox_inches = \"tight\")\n",
        "\n",
        "  # Showing the plot.\n",
        "  plt.show\n",
        "\n",
        "# Function used to plot f1_scores.\n",
        "def plot_f1_scores(model_name, units, f1_scores, figures_path = figures_path):\n",
        "  \n",
        "  # Creating the figure and axes.\n",
        "  fig, ax = plt.subplots(1, 1, figsize = (4, 4))\n",
        "\n",
        "  # Plotting.\n",
        "  ax.plot(np.arange(0, len(f1_scores), 1), f1_scores, marker = \"o\")\n",
        "\n",
        "  # Setting labels.\n",
        "  ax.set_ylabel(r\"$F_1$-score\")\n",
        "\n",
        "  # Setting labels.\n",
        "  ax.set_xlabel(\"Model\")\n",
        "\n",
        "  # Setting x ticks.\n",
        "  ax.set_xticks(np.arange(0, len(f1_scores), 1))\n",
        "\n",
        "  # Setting x ticks labels.\n",
        "  ax.set_xticklabels([r\"${}^{}$\".format(model_name, i + 1) for i in range(len(units))])\n",
        "\n",
        "  # Saving the figure.\n",
        "  fig.savefig(f\"{figures_path}/f1_scores_{model_name}.pdf\", bbox_inches = \"tight\")\n",
        "\n",
        "  # Showing the plot.\n",
        "  plt.show"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4YdLEyuxPuH"
      },
      "source": [
        "### Baseline Model ($m_0$)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "momN-VqKCtlx",
        "outputId": "4b5f45e2-c446-44b2-eee4-99b308c9dbd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid-search, m_0 model.\n",
            "\n",
            "Number of units: 32.\n",
            "\n",
            "Model: \"m_0\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  (None, 249, 64)          21248     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 249, 46)          2990      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " activation (Activation)     (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,238\n",
            "Trainable params: 24,238\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 10s 107ms/step - loss: 1.8719 - accuracy: 0.8906 - val_loss: 0.5530 - val_accuracy: 0.9305 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.4803 - accuracy: 0.9394 - val_loss: 0.3939 - val_accuracy: 0.9465 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.3333 - accuracy: 0.9502 - val_loss: 0.2716 - val_accuracy: 0.9550 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.2343 - accuracy: 0.9577 - val_loss: 0.2005 - val_accuracy: 0.9603 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.1766 - accuracy: 0.9643 - val_loss: 0.1596 - val_accuracy: 0.9660 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.1433 - accuracy: 0.9693 - val_loss: 0.1351 - val_accuracy: 0.9697 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.1225 - accuracy: 0.9725 - val_loss: 0.1192 - val_accuracy: 0.9720 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.1083 - accuracy: 0.9745 - val_loss: 0.1078 - val_accuracy: 0.9737 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0977 - accuracy: 0.9764 - val_loss: 0.0988 - val_accuracy: 0.9754 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0892 - accuracy: 0.9780 - val_loss: 0.0917 - val_accuracy: 0.9768 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0824 - accuracy: 0.9794 - val_loss: 0.0857 - val_accuracy: 0.9778 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0765 - accuracy: 0.9805 - val_loss: 0.0807 - val_accuracy: 0.9790 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0715 - accuracy: 0.9815 - val_loss: 0.0766 - val_accuracy: 0.9798 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0672 - accuracy: 0.9827 - val_loss: 0.0730 - val_accuracy: 0.9808 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0635 - accuracy: 0.9835 - val_loss: 0.0699 - val_accuracy: 0.9816 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0602 - accuracy: 0.9843 - val_loss: 0.0672 - val_accuracy: 0.9823 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0572 - accuracy: 0.9852 - val_loss: 0.0648 - val_accuracy: 0.9829 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0546 - accuracy: 0.9858 - val_loss: 0.0627 - val_accuracy: 0.9834 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0523 - accuracy: 0.9863 - val_loss: 0.0609 - val_accuracy: 0.9838 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0502 - accuracy: 0.9868 - val_loss: 0.0594 - val_accuracy: 0.9840 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0483 - accuracy: 0.9872 - val_loss: 0.0579 - val_accuracy: 0.9843 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0466 - accuracy: 0.9876 - val_loss: 0.0566 - val_accuracy: 0.9846 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0450 - accuracy: 0.9880 - val_loss: 0.0555 - val_accuracy: 0.9850 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0436 - accuracy: 0.9883 - val_loss: 0.0546 - val_accuracy: 0.9850 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0422 - accuracy: 0.9886 - val_loss: 0.0535 - val_accuracy: 0.9853 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0409 - accuracy: 0.9889 - val_loss: 0.0529 - val_accuracy: 0.9855 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0397 - accuracy: 0.9892 - val_loss: 0.0522 - val_accuracy: 0.9856 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0386 - accuracy: 0.9895 - val_loss: 0.0513 - val_accuracy: 0.9857 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0377 - accuracy: 0.9897 - val_loss: 0.0509 - val_accuracy: 0.9858 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0367 - accuracy: 0.9900 - val_loss: 0.0504 - val_accuracy: 0.9859 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0358 - accuracy: 0.9903 - val_loss: 0.0498 - val_accuracy: 0.9862 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0349 - accuracy: 0.9905 - val_loss: 0.0493 - val_accuracy: 0.9863 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0340 - accuracy: 0.9907 - val_loss: 0.0489 - val_accuracy: 0.9863 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0332 - accuracy: 0.9909 - val_loss: 0.0485 - val_accuracy: 0.9865 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0325 - accuracy: 0.9911 - val_loss: 0.0482 - val_accuracy: 0.9865 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0318 - accuracy: 0.9913 - val_loss: 0.0478 - val_accuracy: 0.9866 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0311 - accuracy: 0.9915 - val_loss: 0.0476 - val_accuracy: 0.9867 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0304 - accuracy: 0.9917 - val_loss: 0.0472 - val_accuracy: 0.9867 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0297 - accuracy: 0.9919 - val_loss: 0.0470 - val_accuracy: 0.9867 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0291 - accuracy: 0.9920 - val_loss: 0.0468 - val_accuracy: 0.9867 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0285 - accuracy: 0.9921 - val_loss: 0.0465 - val_accuracy: 0.9870 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0280 - accuracy: 0.9923 - val_loss: 0.0463 - val_accuracy: 0.9870 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0274 - accuracy: 0.9925 - val_loss: 0.0462 - val_accuracy: 0.9870 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0268 - accuracy: 0.9926 - val_loss: 0.0461 - val_accuracy: 0.9870 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0264 - accuracy: 0.9928 - val_loss: 0.0459 - val_accuracy: 0.9871 - lr: 0.0100\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0259 - accuracy: 0.9929 - val_loss: 0.0458 - val_accuracy: 0.9872 - lr: 0.0100\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0254 - accuracy: 0.9930 - val_loss: 0.0457 - val_accuracy: 0.9872 - lr: 0.0100\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0249 - accuracy: 0.9932 - val_loss: 0.0456 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 0.0454 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0241 - accuracy: 0.9934 - val_loss: 0.0454 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0237 - accuracy: 0.9936 - val_loss: 0.0453 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0232 - accuracy: 0.9937 - val_loss: 0.0453 - val_accuracy: 0.9874 - lr: 0.0100\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0230 - accuracy: 0.9938 - val_loss: 0.0453 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0225 - accuracy: 0.9938 - val_loss: 0.0450 - val_accuracy: 0.9874 - lr: 0.0100\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0222 - accuracy: 0.9940 - val_loss: 0.0452 - val_accuracy: 0.9874 - lr: 0.0100\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0219 - accuracy: 0.9940 - val_loss: 0.0451 - val_accuracy: 0.9874 - lr: 0.0100\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0215 - accuracy: 0.9942 - val_loss: 0.0453 - val_accuracy: 0.9875 - lr: 0.0100\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0209 - accuracy: 0.9945 - val_loss: 0.0450 - val_accuracy: 0.9875 - lr: 1.0000e-03\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0207 - accuracy: 0.9945 - val_loss: 0.0449 - val_accuracy: 0.9876 - lr: 1.0000e-03\n",
            "Epoch 60/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0207 - accuracy: 0.9945 - val_loss: 0.0449 - val_accuracy: 0.9875 - lr: 1.0000e-03\n",
            "Epoch 61/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 0.0449 - val_accuracy: 0.9875 - lr: 1.0000e-04\n",
            "Epoch 62/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 0.0449 - val_accuracy: 0.9876 - lr: 1.0000e-04\n",
            "Epoch 63/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 0.0449 - val_accuracy: 0.9875 - lr: 1.0000e-04\n",
            "Epoch 64/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 0.0449 - val_accuracy: 0.9875 - lr: 1.0000e-05\n",
            "\n",
            "Number of units: 64.\n",
            "\n",
            "Model: \"m_0\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_1 (Bidirectio  (None, 249, 128)         58880     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 249, 46)          5934      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 64,814\n",
            "Trainable params: 64,814\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 5s 127ms/step - loss: 1.6377 - accuracy: 0.9001 - val_loss: 0.6213 - val_accuracy: 0.9400 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.4928 - accuracy: 0.9457 - val_loss: 0.3520 - val_accuracy: 0.9524 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.2754 - accuracy: 0.9582 - val_loss: 0.2077 - val_accuracy: 0.9632 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 0.1713 - accuracy: 0.9678 - val_loss: 0.1438 - val_accuracy: 0.9696 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 0.1254 - accuracy: 0.9722 - val_loss: 0.1150 - val_accuracy: 0.9727 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 0.1026 - accuracy: 0.9755 - val_loss: 0.0984 - val_accuracy: 0.9762 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0881 - accuracy: 0.9785 - val_loss: 0.0871 - val_accuracy: 0.9779 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 0.0775 - accuracy: 0.9806 - val_loss: 0.0789 - val_accuracy: 0.9792 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 0.0695 - accuracy: 0.9822 - val_loss: 0.0724 - val_accuracy: 0.9806 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0628 - accuracy: 0.9838 - val_loss: 0.0671 - val_accuracy: 0.9822 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 0.0575 - accuracy: 0.9851 - val_loss: 0.0629 - val_accuracy: 0.9831 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0531 - accuracy: 0.9861 - val_loss: 0.0593 - val_accuracy: 0.9837 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0492 - accuracy: 0.9870 - val_loss: 0.0563 - val_accuracy: 0.9845 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 0.0459 - accuracy: 0.9879 - val_loss: 0.0540 - val_accuracy: 0.9852 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 0.0430 - accuracy: 0.9884 - val_loss: 0.0517 - val_accuracy: 0.9858 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 0.0404 - accuracy: 0.9892 - val_loss: 0.0500 - val_accuracy: 0.9862 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 0.0382 - accuracy: 0.9897 - val_loss: 0.0485 - val_accuracy: 0.9864 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 0.0362 - accuracy: 0.9903 - val_loss: 0.0471 - val_accuracy: 0.9868 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0344 - accuracy: 0.9907 - val_loss: 0.0461 - val_accuracy: 0.9869 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0328 - accuracy: 0.9911 - val_loss: 0.0450 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 0.0312 - accuracy: 0.9916 - val_loss: 0.0443 - val_accuracy: 0.9876 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0299 - accuracy: 0.9920 - val_loss: 0.0434 - val_accuracy: 0.9877 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 0.0286 - accuracy: 0.9923 - val_loss: 0.0427 - val_accuracy: 0.9880 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 0.0274 - accuracy: 0.9927 - val_loss: 0.0423 - val_accuracy: 0.9881 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0263 - accuracy: 0.9931 - val_loss: 0.0418 - val_accuracy: 0.9881 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 0.0253 - accuracy: 0.9933 - val_loss: 0.0413 - val_accuracy: 0.9883 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 0.0243 - accuracy: 0.9935 - val_loss: 0.0412 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 0.0234 - accuracy: 0.9938 - val_loss: 0.0404 - val_accuracy: 0.9885 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0226 - accuracy: 0.9940 - val_loss: 0.0405 - val_accuracy: 0.9885 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0217 - accuracy: 0.9942 - val_loss: 0.0401 - val_accuracy: 0.9886 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0209 - accuracy: 0.9945 - val_loss: 0.0398 - val_accuracy: 0.9887 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0202 - accuracy: 0.9947 - val_loss: 0.0399 - val_accuracy: 0.9888 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0195 - accuracy: 0.9949 - val_loss: 0.0396 - val_accuracy: 0.9888 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 1s 46ms/step - loss: 0.0188 - accuracy: 0.9952 - val_loss: 0.0393 - val_accuracy: 0.9889 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0182 - accuracy: 0.9953 - val_loss: 0.0395 - val_accuracy: 0.9890 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0177 - accuracy: 0.9955 - val_loss: 0.0394 - val_accuracy: 0.9889 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0170 - accuracy: 0.9957 - val_loss: 0.0392 - val_accuracy: 0.9891 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0164 - accuracy: 0.9959 - val_loss: 0.0394 - val_accuracy: 0.9889 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 1s 55ms/step - loss: 0.0159 - accuracy: 0.9960 - val_loss: 0.0393 - val_accuracy: 0.9890 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 0.0154 - accuracy: 0.9961 - val_loss: 0.0393 - val_accuracy: 0.9890 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0145 - accuracy: 0.9964 - val_loss: 0.0392 - val_accuracy: 0.9891 - lr: 1.0000e-03\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 0.0143 - accuracy: 0.9965 - val_loss: 0.0390 - val_accuracy: 0.9891 - lr: 1.0000e-03\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 1s 45ms/step - loss: 0.0143 - accuracy: 0.9965 - val_loss: 0.0390 - val_accuracy: 0.9891 - lr: 1.0000e-03\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 1s 44ms/step - loss: 0.0142 - accuracy: 0.9965 - val_loss: 0.0390 - val_accuracy: 0.9891 - lr: 1.0000e-03\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 0.0141 - accuracy: 0.9966 - val_loss: 0.0390 - val_accuracy: 0.9891 - lr: 1.0000e-03\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 1s 42ms/step - loss: 0.0141 - accuracy: 0.9966 - val_loss: 0.0390 - val_accuracy: 0.9891 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 0.0390 - val_accuracy: 0.9891 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 0.0390 - val_accuracy: 0.9891 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 1s 43ms/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 0.0390 - val_accuracy: 0.9891 - lr: 1.0000e-05\n",
            "\n",
            "Number of units: 128.\n",
            "\n",
            "Model: \"m_0\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_2 (Bidirectio  (None, 249, 256)         183296    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDis  (None, 249, 46)          11822     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 195,118\n",
            "Trainable params: 195,118\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 5s 120ms/step - loss: 1.7563 - accuracy: 0.9058 - val_loss: 0.7155 - val_accuracy: 0.9500 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.5331 - accuracy: 0.9574 - val_loss: 0.3544 - val_accuracy: 0.9637 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.2664 - accuracy: 0.9697 - val_loss: 0.1914 - val_accuracy: 0.9716 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.1500 - accuracy: 0.9752 - val_loss: 0.1204 - val_accuracy: 0.9760 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0993 - accuracy: 0.9788 - val_loss: 0.0899 - val_accuracy: 0.9790 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0762 - accuracy: 0.9818 - val_loss: 0.0745 - val_accuracy: 0.9811 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 54ms/step - loss: 0.0632 - accuracy: 0.9842 - val_loss: 0.0655 - val_accuracy: 0.9829 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 54ms/step - loss: 0.0544 - accuracy: 0.9860 - val_loss: 0.0593 - val_accuracy: 0.9839 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.0481 - accuracy: 0.9873 - val_loss: 0.0545 - val_accuracy: 0.9849 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.0427 - accuracy: 0.9886 - val_loss: 0.0504 - val_accuracy: 0.9858 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.0387 - accuracy: 0.9895 - val_loss: 0.0479 - val_accuracy: 0.9863 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 55ms/step - loss: 0.0353 - accuracy: 0.9904 - val_loss: 0.0455 - val_accuracy: 0.9870 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 54ms/step - loss: 0.0326 - accuracy: 0.9912 - val_loss: 0.0438 - val_accuracy: 0.9874 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 56ms/step - loss: 0.0300 - accuracy: 0.9920 - val_loss: 0.0424 - val_accuracy: 0.9878 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 71ms/step - loss: 0.0278 - accuracy: 0.9926 - val_loss: 0.0409 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 76ms/step - loss: 0.0260 - accuracy: 0.9931 - val_loss: 0.0404 - val_accuracy: 0.9883 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 57ms/step - loss: 0.0242 - accuracy: 0.9937 - val_loss: 0.0393 - val_accuracy: 0.9888 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 54ms/step - loss: 0.0226 - accuracy: 0.9941 - val_loss: 0.0390 - val_accuracy: 0.9888 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 54ms/step - loss: 0.0213 - accuracy: 0.9945 - val_loss: 0.0384 - val_accuracy: 0.9891 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0200 - accuracy: 0.9949 - val_loss: 0.0384 - val_accuracy: 0.9890 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.0189 - accuracy: 0.9952 - val_loss: 0.0376 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 54ms/step - loss: 0.0177 - accuracy: 0.9956 - val_loss: 0.0382 - val_accuracy: 0.9892 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 55ms/step - loss: 0.0167 - accuracy: 0.9959 - val_loss: 0.0376 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0157 - accuracy: 0.9961 - val_loss: 0.0374 - val_accuracy: 0.9894 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.0147 - accuracy: 0.9965 - val_loss: 0.0371 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 54ms/step - loss: 0.0139 - accuracy: 0.9967 - val_loss: 0.0370 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0132 - accuracy: 0.9968 - val_loss: 0.0370 - val_accuracy: 0.9896 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.0124 - accuracy: 0.9971 - val_loss: 0.0370 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 1s 54ms/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 0.0373 - val_accuracy: 0.9896 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.0106 - accuracy: 0.9977 - val_loss: 0.0364 - val_accuracy: 0.9897 - lr: 1.0000e-03\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 1s 54ms/step - loss: 0.0101 - accuracy: 0.9978 - val_loss: 0.0362 - val_accuracy: 0.9898 - lr: 1.0000e-03\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0100 - accuracy: 0.9978 - val_loss: 0.0362 - val_accuracy: 0.9898 - lr: 1.0000e-03\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.0099 - accuracy: 0.9978 - val_loss: 0.0363 - val_accuracy: 0.9897 - lr: 1.0000e-03\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0098 - accuracy: 0.9979 - val_loss: 0.0363 - val_accuracy: 0.9897 - lr: 1.0000e-03\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.0363 - val_accuracy: 0.9897 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 1s 54ms/step - loss: 0.0097 - accuracy: 0.9979 - val_loss: 0.0363 - val_accuracy: 0.9897 - lr: 1.0000e-04\n",
            "\n",
            "Number of units: 256.\n",
            "\n",
            "Model: \"m_0\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_3 (Bidirectio  (None, 249, 512)         628736    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDis  (None, 249, 46)          23598     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 652,334\n",
            "Trainable params: 652,334\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 6s 173ms/step - loss: 2.0510 - accuracy: 0.9057 - val_loss: 0.7254 - val_accuracy: 0.9529 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.4362 - accuracy: 0.9615 - val_loss: 0.2385 - val_accuracy: 0.9672 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 90ms/step - loss: 0.1671 - accuracy: 0.9725 - val_loss: 0.1188 - val_accuracy: 0.9741 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0943 - accuracy: 0.9782 - val_loss: 0.0824 - val_accuracy: 0.9787 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0691 - accuracy: 0.9822 - val_loss: 0.0675 - val_accuracy: 0.9818 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0567 - accuracy: 0.9849 - val_loss: 0.0590 - val_accuracy: 0.9836 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0491 - accuracy: 0.9867 - val_loss: 0.0537 - val_accuracy: 0.9849 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0431 - accuracy: 0.9883 - val_loss: 0.0496 - val_accuracy: 0.9859 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0384 - accuracy: 0.9895 - val_loss: 0.0467 - val_accuracy: 0.9869 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0345 - accuracy: 0.9906 - val_loss: 0.0437 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0317 - accuracy: 0.9914 - val_loss: 0.0425 - val_accuracy: 0.9877 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0289 - accuracy: 0.9922 - val_loss: 0.0397 - val_accuracy: 0.9885 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0268 - accuracy: 0.9929 - val_loss: 0.0394 - val_accuracy: 0.9886 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0245 - accuracy: 0.9936 - val_loss: 0.0380 - val_accuracy: 0.9890 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0223 - accuracy: 0.9942 - val_loss: 0.0368 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0205 - accuracy: 0.9948 - val_loss: 0.0356 - val_accuracy: 0.9898 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0191 - accuracy: 0.9952 - val_loss: 0.0352 - val_accuracy: 0.9898 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0177 - accuracy: 0.9957 - val_loss: 0.0344 - val_accuracy: 0.9901 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0163 - accuracy: 0.9961 - val_loss: 0.0350 - val_accuracy: 0.9900 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0150 - accuracy: 0.9965 - val_loss: 0.0343 - val_accuracy: 0.9902 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0138 - accuracy: 0.9969 - val_loss: 0.0340 - val_accuracy: 0.9904 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0128 - accuracy: 0.9971 - val_loss: 0.0335 - val_accuracy: 0.9905 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0120 - accuracy: 0.9973 - val_loss: 0.0341 - val_accuracy: 0.9905 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 1s 94ms/step - loss: 0.0111 - accuracy: 0.9977 - val_loss: 0.0333 - val_accuracy: 0.9907 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0103 - accuracy: 0.9979 - val_loss: 0.0345 - val_accuracy: 0.9906 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 94ms/step - loss: 0.0098 - accuracy: 0.9980 - val_loss: 0.0336 - val_accuracy: 0.9907 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 94ms/step - loss: 0.0092 - accuracy: 0.9982 - val_loss: 0.0339 - val_accuracy: 0.9905 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 94ms/step - loss: 0.0076 - accuracy: 0.9986 - val_loss: 0.0325 - val_accuracy: 0.9908 - lr: 1.0000e-03\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 1s 95ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.0324 - val_accuracy: 0.9908 - lr: 1.0000e-03\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 1s 94ms/step - loss: 0.0069 - accuracy: 0.9987 - val_loss: 0.0325 - val_accuracy: 0.9909 - lr: 1.0000e-03\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 1s 94ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.0324 - val_accuracy: 0.9909 - lr: 1.0000e-03\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 1s 94ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.0324 - val_accuracy: 0.9909 - lr: 1.0000e-03\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 1s 95ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.0325 - val_accuracy: 0.9909 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 1s 94ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.0325 - val_accuracy: 0.9909 - lr: 1.0000e-04\n"
          ]
        }
      ],
      "source": [
        "# Possible units.\n",
        "baseline_units = [32, 64, 128, 256]\n",
        "\n",
        "# Computing models and histories.\n",
        "baseline_models, baseline_model_histories = grid_search(models_name[0], baseline_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i68Sx5VvShFD",
        "outputId": "f8db4dc4-6258-4ee6-8b3e-fa3ce3b3583c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 1s 9ms/step\n",
            "41/41 [==============================] - 1s 9ms/step\n",
            "41/41 [==============================] - 1s 12ms/step\n",
            "41/41 [==============================] - 1s 13ms/step\n",
            "The best number of units is: 256.\n"
          ]
        }
      ],
      "source": [
        "# Storing best model.\n",
        "baseline_best_units, baseline_f1_scores, models[models_name[0]] = get_best_model(baseline_models, baseline_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vexOylzGJJE-",
        "outputId": "63f5e687-9a8e-4e60-fefa-7e09c82ebd93"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plotting losses and saving figure as .pdf file.\n",
        "plot_training_loss(models_name[0], baseline_units, baseline_model_histories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "emXLTTjTgy8_",
        "outputId": "71a9ebcf-9a57-4a7a-8049-03dba4f8d3ca"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plotting scores and saving figure as .pdf file.\n",
        "plot_f1_scores(models_name[0], baseline_units, baseline_f1_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPtlS40Jx9gR"
      },
      "source": [
        "### BiGRU Model ($m_1$)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3gJ7IKwOgHk",
        "outputId": "3bcffef2-ed00-4df3-8adb-3dbb5ce7ba58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid-search, m_1 model.\n",
            "\n",
            "Number of units: 32.\n",
            "\n",
            "Model: \"m_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_4 (Bidirectio  (None, 249, 64)          16128     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_4 (TimeDis  (None, 249, 46)          2990      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 19,118\n",
            "Trainable params: 19,118\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 4s 97ms/step - loss: 1.9700 - accuracy: 0.9153 - val_loss: 0.5253 - val_accuracy: 0.9415 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.4526 - accuracy: 0.9465 - val_loss: 0.3506 - val_accuracy: 0.9540 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.2798 - accuracy: 0.9610 - val_loss: 0.2081 - val_accuracy: 0.9642 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.1708 - accuracy: 0.9681 - val_loss: 0.1411 - val_accuracy: 0.9703 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.1249 - accuracy: 0.9730 - val_loss: 0.1153 - val_accuracy: 0.9740 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.1040 - accuracy: 0.9760 - val_loss: 0.1006 - val_accuracy: 0.9759 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0911 - accuracy: 0.9781 - val_loss: 0.0908 - val_accuracy: 0.9774 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0820 - accuracy: 0.9796 - val_loss: 0.0837 - val_accuracy: 0.9784 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0750 - accuracy: 0.9808 - val_loss: 0.0782 - val_accuracy: 0.9793 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0695 - accuracy: 0.9821 - val_loss: 0.0738 - val_accuracy: 0.9803 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0651 - accuracy: 0.9829 - val_loss: 0.0702 - val_accuracy: 0.9808 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0614 - accuracy: 0.9837 - val_loss: 0.0673 - val_accuracy: 0.9816 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0582 - accuracy: 0.9843 - val_loss: 0.0648 - val_accuracy: 0.9821 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0554 - accuracy: 0.9851 - val_loss: 0.0627 - val_accuracy: 0.9826 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0530 - accuracy: 0.9857 - val_loss: 0.0610 - val_accuracy: 0.9830 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0508 - accuracy: 0.9864 - val_loss: 0.0592 - val_accuracy: 0.9836 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0489 - accuracy: 0.9868 - val_loss: 0.0579 - val_accuracy: 0.9839 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0472 - accuracy: 0.9872 - val_loss: 0.0566 - val_accuracy: 0.9840 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0457 - accuracy: 0.9875 - val_loss: 0.0557 - val_accuracy: 0.9844 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0442 - accuracy: 0.9879 - val_loss: 0.0546 - val_accuracy: 0.9846 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0429 - accuracy: 0.9883 - val_loss: 0.0539 - val_accuracy: 0.9848 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0417 - accuracy: 0.9884 - val_loss: 0.0531 - val_accuracy: 0.9849 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0406 - accuracy: 0.9887 - val_loss: 0.0524 - val_accuracy: 0.9852 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0397 - accuracy: 0.9890 - val_loss: 0.0519 - val_accuracy: 0.9852 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0387 - accuracy: 0.9892 - val_loss: 0.0512 - val_accuracy: 0.9853 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0378 - accuracy: 0.9894 - val_loss: 0.0509 - val_accuracy: 0.9855 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0370 - accuracy: 0.9897 - val_loss: 0.0507 - val_accuracy: 0.9854 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0362 - accuracy: 0.9899 - val_loss: 0.0499 - val_accuracy: 0.9857 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0355 - accuracy: 0.9901 - val_loss: 0.0497 - val_accuracy: 0.9857 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0348 - accuracy: 0.9902 - val_loss: 0.0496 - val_accuracy: 0.9858 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0342 - accuracy: 0.9905 - val_loss: 0.0489 - val_accuracy: 0.9859 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0336 - accuracy: 0.9906 - val_loss: 0.0487 - val_accuracy: 0.9860 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0330 - accuracy: 0.9907 - val_loss: 0.0486 - val_accuracy: 0.9861 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0324 - accuracy: 0.9909 - val_loss: 0.0485 - val_accuracy: 0.9861 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0319 - accuracy: 0.9910 - val_loss: 0.0484 - val_accuracy: 0.9862 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0315 - accuracy: 0.9910 - val_loss: 0.0481 - val_accuracy: 0.9863 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0309 - accuracy: 0.9913 - val_loss: 0.0480 - val_accuracy: 0.9863 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0306 - accuracy: 0.9913 - val_loss: 0.0479 - val_accuracy: 0.9863 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0301 - accuracy: 0.9914 - val_loss: 0.0476 - val_accuracy: 0.9864 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0297 - accuracy: 0.9915 - val_loss: 0.0478 - val_accuracy: 0.9864 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0293 - accuracy: 0.9917 - val_loss: 0.0474 - val_accuracy: 0.9866 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0289 - accuracy: 0.9917 - val_loss: 0.0476 - val_accuracy: 0.9864 - lr: 0.0100\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0286 - accuracy: 0.9918 - val_loss: 0.0476 - val_accuracy: 0.9865 - lr: 0.0100\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0282 - accuracy: 0.9919 - val_loss: 0.0478 - val_accuracy: 0.9865 - lr: 0.0100\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0274 - accuracy: 0.9921 - val_loss: 0.0474 - val_accuracy: 0.9866 - lr: 1.0000e-03\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0272 - accuracy: 0.9922 - val_loss: 0.0473 - val_accuracy: 0.9866 - lr: 1.0000e-03\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0272 - accuracy: 0.9923 - val_loss: 0.0473 - val_accuracy: 0.9866 - lr: 1.0000e-03\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0271 - accuracy: 0.9923 - val_loss: 0.0473 - val_accuracy: 0.9866 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0271 - accuracy: 0.9923 - val_loss: 0.0473 - val_accuracy: 0.9866 - lr: 1.0000e-04\n",
            "Epoch 50/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0271 - accuracy: 0.9923 - val_loss: 0.0473 - val_accuracy: 0.9866 - lr: 1.0000e-04\n",
            "Epoch 51/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0271 - accuracy: 0.9923 - val_loss: 0.0473 - val_accuracy: 0.9866 - lr: 1.0000e-04\n",
            "Epoch 52/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0271 - accuracy: 0.9923 - val_loss: 0.0473 - val_accuracy: 0.9866 - lr: 1.0000e-04\n",
            "Epoch 53/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0270 - accuracy: 0.9923 - val_loss: 0.0473 - val_accuracy: 0.9866 - lr: 1.0000e-04\n",
            "Epoch 54/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0270 - accuracy: 0.9923 - val_loss: 0.0473 - val_accuracy: 0.9866 - lr: 1.0000e-05\n",
            "Epoch 55/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0270 - accuracy: 0.9923 - val_loss: 0.0473 - val_accuracy: 0.9866 - lr: 1.0000e-05\n",
            "Epoch 56/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0270 - accuracy: 0.9923 - val_loss: 0.0473 - val_accuracy: 0.9866 - lr: 1.0000e-05\n",
            "Epoch 57/100\n",
            "16/16 [==============================] - 1s 35ms/step - loss: 0.0270 - accuracy: 0.9923 - val_loss: 0.0473 - val_accuracy: 0.9866 - lr: 1.0000e-06\n",
            "Epoch 58/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0270 - accuracy: 0.9923 - val_loss: 0.0473 - val_accuracy: 0.9866 - lr: 1.0000e-06\n",
            "Epoch 59/100\n",
            "16/16 [==============================] - 1s 36ms/step - loss: 0.0270 - accuracy: 0.9923 - val_loss: 0.0473 - val_accuracy: 0.9866 - lr: 1.0000e-06\n",
            "\n",
            "Number of units: 64.\n",
            "\n",
            "Model: \"m_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_5 (Bidirectio  (None, 249, 128)         44544     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_5 (TimeDis  (None, 249, 46)          5934      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,478\n",
            "Trainable params: 50,478\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 5s 96ms/step - loss: 1.8111 - accuracy: 0.9209 - val_loss: 0.5528 - val_accuracy: 0.9477 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.4098 - accuracy: 0.9541 - val_loss: 0.2516 - val_accuracy: 0.9595 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.1857 - accuracy: 0.9653 - val_loss: 0.1400 - val_accuracy: 0.9679 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.1219 - accuracy: 0.9711 - val_loss: 0.1095 - val_accuracy: 0.9729 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0976 - accuracy: 0.9755 - val_loss: 0.0936 - val_accuracy: 0.9759 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0838 - accuracy: 0.9785 - val_loss: 0.0835 - val_accuracy: 0.9779 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0746 - accuracy: 0.9802 - val_loss: 0.0765 - val_accuracy: 0.9790 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0675 - accuracy: 0.9816 - val_loss: 0.0710 - val_accuracy: 0.9802 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0620 - accuracy: 0.9831 - val_loss: 0.0667 - val_accuracy: 0.9815 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0574 - accuracy: 0.9845 - val_loss: 0.0630 - val_accuracy: 0.9827 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0537 - accuracy: 0.9855 - val_loss: 0.0603 - val_accuracy: 0.9834 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0505 - accuracy: 0.9864 - val_loss: 0.0576 - val_accuracy: 0.9842 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0475 - accuracy: 0.9871 - val_loss: 0.0557 - val_accuracy: 0.9846 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0450 - accuracy: 0.9879 - val_loss: 0.0537 - val_accuracy: 0.9851 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0428 - accuracy: 0.9883 - val_loss: 0.0523 - val_accuracy: 0.9856 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0408 - accuracy: 0.9888 - val_loss: 0.0509 - val_accuracy: 0.9858 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 41ms/step - loss: 0.0390 - accuracy: 0.9893 - val_loss: 0.0499 - val_accuracy: 0.9858 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0373 - accuracy: 0.9898 - val_loss: 0.0489 - val_accuracy: 0.9863 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0358 - accuracy: 0.9902 - val_loss: 0.0480 - val_accuracy: 0.9864 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0345 - accuracy: 0.9905 - val_loss: 0.0472 - val_accuracy: 0.9866 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0330 - accuracy: 0.9908 - val_loss: 0.0466 - val_accuracy: 0.9867 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0319 - accuracy: 0.9912 - val_loss: 0.0457 - val_accuracy: 0.9869 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0307 - accuracy: 0.9916 - val_loss: 0.0453 - val_accuracy: 0.9871 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0297 - accuracy: 0.9918 - val_loss: 0.0448 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0287 - accuracy: 0.9921 - val_loss: 0.0443 - val_accuracy: 0.9875 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0278 - accuracy: 0.9924 - val_loss: 0.0440 - val_accuracy: 0.9875 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0269 - accuracy: 0.9926 - val_loss: 0.0440 - val_accuracy: 0.9875 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0261 - accuracy: 0.9928 - val_loss: 0.0432 - val_accuracy: 0.9879 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0253 - accuracy: 0.9929 - val_loss: 0.0434 - val_accuracy: 0.9878 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0246 - accuracy: 0.9932 - val_loss: 0.0431 - val_accuracy: 0.9879 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0238 - accuracy: 0.9934 - val_loss: 0.0425 - val_accuracy: 0.9881 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 1s 37ms/step - loss: 0.0233 - accuracy: 0.9936 - val_loss: 0.0430 - val_accuracy: 0.9879 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0226 - accuracy: 0.9938 - val_loss: 0.0426 - val_accuracy: 0.9881 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0219 - accuracy: 0.9940 - val_loss: 0.0424 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0214 - accuracy: 0.9941 - val_loss: 0.0426 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0208 - accuracy: 0.9943 - val_loss: 0.0424 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0203 - accuracy: 0.9944 - val_loss: 0.0423 - val_accuracy: 0.9883 - lr: 0.0100\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0198 - accuracy: 0.9945 - val_loss: 0.0425 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0194 - accuracy: 0.9946 - val_loss: 0.0424 - val_accuracy: 0.9884 - lr: 0.0100\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0188 - accuracy: 0.9949 - val_loss: 0.0424 - val_accuracy: 0.9884 - lr: 0.0100\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.0421 - val_accuracy: 0.9885 - lr: 1.0000e-03\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0176 - accuracy: 0.9952 - val_loss: 0.0419 - val_accuracy: 0.9884 - lr: 1.0000e-03\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 1s 40ms/step - loss: 0.0175 - accuracy: 0.9952 - val_loss: 0.0419 - val_accuracy: 0.9884 - lr: 1.0000e-03\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0174 - accuracy: 0.9953 - val_loss: 0.0419 - val_accuracy: 0.9884 - lr: 1.0000e-03\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0174 - accuracy: 0.9953 - val_loss: 0.0420 - val_accuracy: 0.9884 - lr: 1.0000e-03\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0173 - accuracy: 0.9953 - val_loss: 0.0419 - val_accuracy: 0.9885 - lr: 1.0000e-04\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0173 - accuracy: 0.9953 - val_loss: 0.0419 - val_accuracy: 0.9884 - lr: 1.0000e-04\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 1s 38ms/step - loss: 0.0173 - accuracy: 0.9953 - val_loss: 0.0419 - val_accuracy: 0.9884 - lr: 1.0000e-04\n",
            "Epoch 49/100\n",
            "16/16 [==============================] - 1s 39ms/step - loss: 0.0173 - accuracy: 0.9953 - val_loss: 0.0419 - val_accuracy: 0.9884 - lr: 1.0000e-05\n",
            "\n",
            "Number of units: 128.\n",
            "\n",
            "Model: \"m_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_6 (Bidirectio  (None, 249, 256)         138240    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_6 (TimeDis  (None, 249, 46)          11822     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 150,062\n",
            "Trainable params: 150,062\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 5s 109ms/step - loss: 1.8009 - accuracy: 0.9214 - val_loss: 0.4484 - val_accuracy: 0.9524 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.2956 - accuracy: 0.9584 - val_loss: 0.1831 - val_accuracy: 0.9638 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.1495 - accuracy: 0.9683 - val_loss: 0.1232 - val_accuracy: 0.9701 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.1069 - accuracy: 0.9734 - val_loss: 0.0986 - val_accuracy: 0.9747 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.0879 - accuracy: 0.9770 - val_loss: 0.0858 - val_accuracy: 0.9770 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.0766 - accuracy: 0.9793 - val_loss: 0.0773 - val_accuracy: 0.9788 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0684 - accuracy: 0.9814 - val_loss: 0.0712 - val_accuracy: 0.9801 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.0620 - accuracy: 0.9830 - val_loss: 0.0661 - val_accuracy: 0.9816 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0569 - accuracy: 0.9845 - val_loss: 0.0623 - val_accuracy: 0.9827 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.0526 - accuracy: 0.9857 - val_loss: 0.0590 - val_accuracy: 0.9835 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0491 - accuracy: 0.9865 - val_loss: 0.0565 - val_accuracy: 0.9841 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.0461 - accuracy: 0.9874 - val_loss: 0.0541 - val_accuracy: 0.9846 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.0434 - accuracy: 0.9882 - val_loss: 0.0523 - val_accuracy: 0.9850 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0409 - accuracy: 0.9889 - val_loss: 0.0505 - val_accuracy: 0.9854 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.0386 - accuracy: 0.9895 - val_loss: 0.0489 - val_accuracy: 0.9859 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0366 - accuracy: 0.9900 - val_loss: 0.0476 - val_accuracy: 0.9863 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.0348 - accuracy: 0.9906 - val_loss: 0.0468 - val_accuracy: 0.9865 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.0331 - accuracy: 0.9909 - val_loss: 0.0454 - val_accuracy: 0.9868 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0316 - accuracy: 0.9914 - val_loss: 0.0452 - val_accuracy: 0.9868 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.0302 - accuracy: 0.9916 - val_loss: 0.0440 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 53ms/step - loss: 0.0288 - accuracy: 0.9921 - val_loss: 0.0436 - val_accuracy: 0.9874 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0276 - accuracy: 0.9924 - val_loss: 0.0428 - val_accuracy: 0.9874 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0263 - accuracy: 0.9928 - val_loss: 0.0424 - val_accuracy: 0.9877 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0253 - accuracy: 0.9931 - val_loss: 0.0418 - val_accuracy: 0.9878 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.0241 - accuracy: 0.9934 - val_loss: 0.0413 - val_accuracy: 0.9881 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0231 - accuracy: 0.9937 - val_loss: 0.0410 - val_accuracy: 0.9883 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.0223 - accuracy: 0.9940 - val_loss: 0.0410 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0212 - accuracy: 0.9943 - val_loss: 0.0405 - val_accuracy: 0.9883 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.0204 - accuracy: 0.9946 - val_loss: 0.0406 - val_accuracy: 0.9883 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0196 - accuracy: 0.9948 - val_loss: 0.0401 - val_accuracy: 0.9885 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.0188 - accuracy: 0.9950 - val_loss: 0.0398 - val_accuracy: 0.9885 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0182 - accuracy: 0.9952 - val_loss: 0.0400 - val_accuracy: 0.9886 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0174 - accuracy: 0.9954 - val_loss: 0.0400 - val_accuracy: 0.9886 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.0167 - accuracy: 0.9956 - val_loss: 0.0398 - val_accuracy: 0.9886 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0155 - accuracy: 0.9960 - val_loss: 0.0392 - val_accuracy: 0.9887 - lr: 1.0000e-03\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0151 - accuracy: 0.9961 - val_loss: 0.0390 - val_accuracy: 0.9888 - lr: 1.0000e-03\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0150 - accuracy: 0.9961 - val_loss: 0.0390 - val_accuracy: 0.9888 - lr: 1.0000e-03\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0149 - accuracy: 0.9961 - val_loss: 0.0390 - val_accuracy: 0.9889 - lr: 1.0000e-03\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0149 - accuracy: 0.9962 - val_loss: 0.0390 - val_accuracy: 0.9888 - lr: 1.0000e-03\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0147 - accuracy: 0.9962 - val_loss: 0.0389 - val_accuracy: 0.9888 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0147 - accuracy: 0.9962 - val_loss: 0.0389 - val_accuracy: 0.9888 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0147 - accuracy: 0.9962 - val_loss: 0.0389 - val_accuracy: 0.9888 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 1s 50ms/step - loss: 0.0147 - accuracy: 0.9962 - val_loss: 0.0389 - val_accuracy: 0.9888 - lr: 1.0000e-05\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 1s 49ms/step - loss: 0.0147 - accuracy: 0.9962 - val_loss: 0.0389 - val_accuracy: 0.9888 - lr: 1.0000e-05\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0147 - accuracy: 0.9962 - val_loss: 0.0389 - val_accuracy: 0.9888 - lr: 1.0000e-05\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 0.0147 - accuracy: 0.9962 - val_loss: 0.0389 - val_accuracy: 0.9888 - lr: 1.0000e-06\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0147 - accuracy: 0.9962 - val_loss: 0.0389 - val_accuracy: 0.9888 - lr: 1.0000e-06\n",
            "Epoch 48/100\n",
            "16/16 [==============================] - 1s 52ms/step - loss: 0.0147 - accuracy: 0.9962 - val_loss: 0.0389 - val_accuracy: 0.9888 - lr: 1.0000e-06\n",
            "\n",
            "Number of units: 256.\n",
            "\n",
            "Model: \"m_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_7 (Bidirectio  (None, 249, 512)         473088    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_7 (TimeDis  (None, 249, 46)          23598     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 496,686\n",
            "Trainable params: 496,686\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 5s 138ms/step - loss: 3.3322 - accuracy: 0.8689 - val_loss: 1.7056 - val_accuracy: 0.9547 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 1.6915 - accuracy: 0.9600 - val_loss: 1.5203 - val_accuracy: 0.9651 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 1.2877 - accuracy: 0.9702 - val_loss: 1.0164 - val_accuracy: 0.9716 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.8358 - accuracy: 0.9753 - val_loss: 0.6602 - val_accuracy: 0.9755 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.5525 - accuracy: 0.9783 - val_loss: 0.4535 - val_accuracy: 0.9776 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.3864 - accuracy: 0.9803 - val_loss: 0.3291 - val_accuracy: 0.9791 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.2831 - accuracy: 0.9819 - val_loss: 0.2480 - val_accuracy: 0.9806 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.2139 - accuracy: 0.9836 - val_loss: 0.1925 - val_accuracy: 0.9817 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.1660 - accuracy: 0.9848 - val_loss: 0.1534 - val_accuracy: 0.9828 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.1315 - accuracy: 0.9861 - val_loss: 0.1249 - val_accuracy: 0.9838 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.1063 - accuracy: 0.9870 - val_loss: 0.1040 - val_accuracy: 0.9846 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0875 - accuracy: 0.9881 - val_loss: 0.0889 - val_accuracy: 0.9852 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0734 - accuracy: 0.9888 - val_loss: 0.0770 - val_accuracy: 0.9858 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0626 - accuracy: 0.9893 - val_loss: 0.0688 - val_accuracy: 0.9861 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0543 - accuracy: 0.9900 - val_loss: 0.0619 - val_accuracy: 0.9866 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0479 - accuracy: 0.9905 - val_loss: 0.0568 - val_accuracy: 0.9870 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0426 - accuracy: 0.9912 - val_loss: 0.0527 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0383 - accuracy: 0.9917 - val_loss: 0.0497 - val_accuracy: 0.9875 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0350 - accuracy: 0.9920 - val_loss: 0.0475 - val_accuracy: 0.9878 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0321 - accuracy: 0.9925 - val_loss: 0.0457 - val_accuracy: 0.9879 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0297 - accuracy: 0.9929 - val_loss: 0.0442 - val_accuracy: 0.9881 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0278 - accuracy: 0.9932 - val_loss: 0.0432 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0259 - accuracy: 0.9936 - val_loss: 0.0421 - val_accuracy: 0.9884 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0243 - accuracy: 0.9940 - val_loss: 0.0408 - val_accuracy: 0.9887 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0227 - accuracy: 0.9943 - val_loss: 0.0402 - val_accuracy: 0.9889 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0213 - accuracy: 0.9946 - val_loss: 0.0397 - val_accuracy: 0.9889 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0202 - accuracy: 0.9949 - val_loss: 0.0392 - val_accuracy: 0.9890 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0191 - accuracy: 0.9953 - val_loss: 0.0388 - val_accuracy: 0.9891 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0182 - accuracy: 0.9955 - val_loss: 0.0387 - val_accuracy: 0.9891 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0176 - accuracy: 0.9956 - val_loss: 0.0381 - val_accuracy: 0.9894 - lr: 0.0100\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0164 - accuracy: 0.9960 - val_loss: 0.0376 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0158 - accuracy: 0.9961 - val_loss: 0.0378 - val_accuracy: 0.9894 - lr: 0.0100\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0150 - accuracy: 0.9964 - val_loss: 0.0376 - val_accuracy: 0.9896 - lr: 0.0100\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0142 - accuracy: 0.9966 - val_loss: 0.0377 - val_accuracy: 0.9894 - lr: 0.0100\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0128 - accuracy: 0.9970 - val_loss: 0.0366 - val_accuracy: 0.9897 - lr: 1.0000e-03\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 1s 84ms/step - loss: 0.0123 - accuracy: 0.9970 - val_loss: 0.0364 - val_accuracy: 0.9897 - lr: 1.0000e-03\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0122 - accuracy: 0.9971 - val_loss: 0.0363 - val_accuracy: 0.9897 - lr: 1.0000e-03\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0121 - accuracy: 0.9972 - val_loss: 0.0363 - val_accuracy: 0.9897 - lr: 1.0000e-03\n",
            "Epoch 39/100\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0121 - accuracy: 0.9971 - val_loss: 0.0363 - val_accuracy: 0.9897 - lr: 1.0000e-03\n",
            "Epoch 40/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0119 - accuracy: 0.9972 - val_loss: 0.0363 - val_accuracy: 0.9897 - lr: 1.0000e-04\n",
            "Epoch 41/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0119 - accuracy: 0.9972 - val_loss: 0.0363 - val_accuracy: 0.9897 - lr: 1.0000e-04\n",
            "Epoch 42/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0119 - accuracy: 0.9972 - val_loss: 0.0363 - val_accuracy: 0.9897 - lr: 1.0000e-04\n",
            "Epoch 43/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0119 - accuracy: 0.9973 - val_loss: 0.0363 - val_accuracy: 0.9897 - lr: 1.0000e-04\n",
            "Epoch 44/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 0.0363 - val_accuracy: 0.9897 - lr: 1.0000e-05\n",
            "Epoch 45/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 0.0363 - val_accuracy: 0.9897 - lr: 1.0000e-05\n",
            "Epoch 46/100\n",
            "16/16 [==============================] - 1s 82ms/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 0.0363 - val_accuracy: 0.9897 - lr: 1.0000e-05\n",
            "Epoch 47/100\n",
            "16/16 [==============================] - 1s 83ms/step - loss: 0.0118 - accuracy: 0.9973 - val_loss: 0.0363 - val_accuracy: 0.9897 - lr: 1.0000e-06\n"
          ]
        }
      ],
      "source": [
        "# Possible units.\n",
        "gru_units = [32, 64, 128, 256]\n",
        "\n",
        "# Computing models and histories.\n",
        "gru_models, gru_model_histories = grid_search(models_name[1], gru_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ul1WbFDkOnYF",
        "outputId": "ace8109e-16d0-4b55-f400-97f9a53c83a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 1s 11ms/step\n",
            "41/41 [==============================] - 1s 9ms/step\n",
            "41/41 [==============================] - 1s 9ms/step\n",
            "41/41 [==============================] - 1s 12ms/step\n",
            "The best number of units is: 128.\n"
          ]
        }
      ],
      "source": [
        "# Storing best model.\n",
        "_, gru_f1_scores, models[models_name[1]] = get_best_model(gru_models, gru_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "LWsBxGmyc9PZ",
        "outputId": "d92e5674-625e-4255-d1a8-6f2d16a567cc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plotting losses and saving figure as .pdf file.\n",
        "plot_training_loss(models_name[1], gru_units, gru_model_histories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "10CECwq1lZHp",
        "outputId": "b740c01c-b76f-4739-9a6d-36c30a27e135"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARwAAAENCAYAAADdftreAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxV9Z3/8debsAURQlgUCAkoCYoFBaJWbUe0RXEZta11qc60zozYsXa6TKnitJ0pLrWly2iLrTijjnbUWlR+UXHiLtaVBARK2ELYEpA1AVkCIfn8/rgncIkgCeSec5fP8/HIw5zvPTf55CS++Z7zOYvMDOecC0OHqAtwzmUODxznXGg8cJxzofHAcc6FxgPHORcaDxznXGg6Rl1AovTp08cGDx4cdRnOZZzy8vJNZtb3YK+lbeAMHjyYsrKyqMtwLuNIWnWo13yXyjkXGg8c51xoPHCcc6HxwHHOhSZtDxo7dzRmzK1hSukS1tbtYkBONhMvHMYVowZGXVbK88BxroUZc2uY9MwCdjU0AlBTt4tJzywA8NA5Sr5L5VwLU0qX7AubZrsaGplSuiSiitKHB45zLayt23XQ8Zq6XXywYgv1LcLItV6ou1SSxgP3AlnAf5nZPS1e/w1wXrDYDehnZjnBa18HfhS8dqeZ/U84VbtM0z+nK2vr6g/62lUPvEvHDuKUAT0Yld+LMQWxjwE52SFXmZpCCxxJWcBUYBxQDcyWVGJmFc3rmNn34tb/NjAq+DwX+HegGDCgPHhvbVj1u8wxtqgvj3+w5oCx7E5Z/NslJ9O/Z1fKV9VSvqqWJ2ev5pF3VgJwfI+ujCnoxaj8HMYU9OKUAT3p3NF3IFoKc4ZzBlBpZlUAkp4ELgcqDrH+tcRCBuBC4GUz2xK892VgPPBEQit2GWfH7r28ungDg3KzaWwy1tXVf6JL9YWTjwOgobGJxes+pnzVFuasrqN8VS0vLFgHQOeOHRg5sCdjCnoxuqAXo/N70ffYLpH9XMkizMAZCMT/s1ENnHmwFSUVAEOA1z7lvZ9oF0iaAEwAyM/PP/qKXcZ54M3lrN+2m6f/+WzGFPT61HU7ZXVgRF5PRuT15BvnxMbWb6tnTjADmrO6loffXskDs6oAyM/tFgug/BxGF/Ri2HHH0jErs2ZBydoWvwaYbmZtOjpnZtOAaQDFxcV+d3jXJjV1u3hgVhV/e+qAw4bNoRzXoysXjejPRSP6A1Df0MjCtVuZsyo2A/pL5SaenVsDQLfOWZw2KCcIodjuWE63zu328ySjMAOnBhgUt5wXjB3MNcC3Wrx3bIv3vtGOtTnHz19cDMCt44e129fs2imLMQW5jCnI5UbAzKiu3cWc1ftnQfe/sZzGpti/j0P7dWd0/v4QOrFvdzp0ULvVE7UwA2c2UChpCLEAuQb4WsuVJJ0E9ALejRsuBe6W1PzPzgXApMSW6zJJ+apaSuat5dvnDyWvV7eEfR9JDMrtxqDcblx+WuyowM49e5m3Zuu+EHqpYj1PlVUD0KNrx33HgMYU9OLUQTl075KsOyaHF1rlZrZX0i3EwiMLeMjMFkqaDJSZWUmw6jXAkxb3wCwz2yLpDmKhBTC5+QCyc0erqcm44/kK+h3bhW+ee2Lo379b546cdWJvzjqxNxCbBVVt2sGcYAZUvqqWN5duxAw6CIYd34MxBTn7Qig/txtSasyClK4PwisuLja/AZdrjRlza/junz7kl189lSvH5EVdzkFt3dXAh2tix4Hmrq5l7uo6tu/eC0Cf7p0POCdoxMCedO2UFVmtksrNrPhgr6Xu3My5drBzz17ueXExIwb25MtJfJ1Uz+xOnFvUl3OLYnfubGwylq7/eP+xoFW1vFyxHoBOWWL4gJ6Mye/F6ILY8aD+PZPjxEQPHJfRps2q4qNt9dx37aiUOjib1UGc3L8HJ/fvwXVnFgCweftu5qyu2xdC//v+Kh56ewUA/Xt2ZXRBryCEejG8f49ITkz0wHEZa93WXfzhzeVcMqI/ZwzJjbqco9a7exfGDT+OccP3n5i4aN22fWdGz11dxwvzYycmdunYgVPzchhVkLMvhPp0T/yJiR44LmNN+b8lNBncdtFJUZeSEJ2yOjAyL4eReTnccM4QIBayc1btnwU99JcVPNAYOzGxoHc3xuT3YlQwExp2/LFkdVC73hvIA8dlpA/X1PHM3BpuHnsig3IT1wZPNv17ZnPJyGwuGbn/xMS/1mzdd07QrGWbeCY4MfGYzlkMyOnKik072RucJ3S09wbywHEZx8yY/NxC+nTvws3nDY26nEh17ZRF8eBcigfHdinNjDVb9p+Y+MQHq/eFTbPmewMdSeBk1oUczgHPzV/HnNV1TLywKKVPoksESeT37sYVowZyxxWf2XcGdEuHumfQ4XjguIxS39DIPTMXMbx/D64cM+jwb8hwh7rPz5He/8cDx2WUB2dVsXZrPT++dDhZKdQGj8rEC4eR3eIkwuxOWUy88MiuN/P5pMsY67fV8/s3lzP+lOP3XUbgPl3zcRrvUjnXRlNKl7C30Zh0cXq2wRPlilED2+1pFb5L5TLCguqtTC+v5obPDaag9zFRl5OxPHBc2jMzJj+/kN7HdOaWDG+DR80Dx6W9mQs+YvbKWv71gmEc27VT1OVkNA8cl9bqGxr52YuLOOn4Y7n6dG+DR80Dx6W1h95eQXXtLn7ibfCk4IHj0taGj+uZ+lol44Yfx9lD+0RdjsMDx6WxX5UuZU9jE7dffHLUpbiAB45LS3+t2cpT5Wv4+lmDGdLH2+DJwgPHpR2z2E3Rc7I78e0vFEZdjovjgePSTunC9by/Ygvfv2AYPbO9DZ5MPHBcWtm9t5G7Zy6i6LjuXOtt8KTjgePSyiNvr2T1lp38+NLhGffc7lTgvxGXNjZ+vJvfvlbJ+Sf14/OFfaMuxx2EB45LG79+eSn1DY3eBk9ioQaOpPGSlkiqlHTbIda5SlKFpIWSHo8b/7mkvwYfV4dXtUsFi9Zt40+zV/N3ZxUwtF/3qMtxhxDa/XAkZQFTgXFANTBbUomZVcStUwhMAs4xs1pJ/YLxS4DRwGlAF+ANSS+a2baw6nfJy8y484UKemR34jveBk9qYc5wzgAqzazKzPYATwKXt1jnRmCqmdUCmNmGYHw4MMvM9prZDmA+MD6kul2Se2XRBt6u3Mz3vlhETrfOUZfjPkWYgTMQWBO3XB2MxSsCiiS9Lek9Sc2hMg8YL6mbpD7AecAnep6SJkgqk1S2cePGBPwILtns2dvEXS9UMLRfd752Zn7U5bjDSLZbjHYECoGxQB4wS9IIM3tJ0unAO8BG4F2gseWbzWwaMA2guLj44M+3cGnl0XdXsnLzTh6+4XQ6eRs86YX5G6rhwFlJXjAWrxooMbMGM1sBLCUWQJjZXWZ2mpmNAxS85jLY5u27uffVZZxb1JfzhvWLuhzXCmEGzmygUNIQSZ2Ba4CSFuvMIDa7Idh1KgKqJGVJ6h2MjwRGAi+FVbhLTr95ZSk79zTyo0u8DZ4qQtulMrO9km4BSoEs4CEzWyhpMlBmZiXBaxdIqiC2yzTRzDZL6gq8JQlgG3C9me0Nq3aXfJZ89DGPv7+av/tsAYXHHRt1Oa6VZJaehzqKi4utrKws6jJcApgZf//QB8xbU8ebE8+j1zHemUomksrNrPhgr/lRNpdyXl+ygbeWbeK7XyzysEkxHjgupTQ0NnHn84s4oc8x/N1ZBVGX49rIA8ellMfeXUXVph382yUnexs8BflvzKWM2h17uPfVZXy+sA/nn+Rt8FTkgeNSxr2vLuPj+gZ+dMlwgo6lSzEeOC4lVG74mMfeW8XXzsxn2PHeBk9VHjguJdz5wiK6dc7ie18siroUdxQ8cFzSe33JBt5YspF/Ob+Q3t27RF2OOwoeOC6pNTQ2cdcLixjcuxtfP3tw1OW4o+SB45LaEx+spnLDdm6/+GQ6d/Q/11Tnv0GXtLbubODXLy/l7BN7M274cVGX49qBB45LWve+uoxtuxr48aXeBk8XHjguKS3fuJ1H313J1acP4uT+PaIux7UTDxyXlO5+YRFdO2Xx/XHDoi7FtSMPHJd03lq2kVcXb+CW84fS91hvg6cTDxyXVPYGV4Pn53bjhnMGR12Oa2ceOC6pPDl7DUvWf8ztF59El45ZUZfj2pkHjksaW3fF2uBnDsnlwlOOj7oclwAeOC5p/O61ZdTu3ONt8DTmgeOSwopNO3jknZV8dUwenxnYM+pyXIJ44LikcPfMRXTO6sAPLvA2eDrzwHGRe6dyEy9XrOfm84bSr0fXqMtxCeSB4yLV2GRMfr6CgTnZ/OPnhkRdjkswDxwXqafK1rD4o4+5/eKT6drJ2+DpLtTAkTRe0hJJlZJuO8Q6V0mqkLRQ0uNx478IxhZJuk/exkh52+ob+GXpEk4f3IuLR3gbPBOE9qhfSVnAVGAcUA3MllRiZhVx6xQCk4BzzKxWUr9g/GzgHGLPFAf4C3Au8EZY9bv2N/X1Sjbv2MPDN5zubfAMEeYM5wyg0syqzGwP8CRweYt1bgSmmlktgJltCMYN6Ap0BroAnYD1oVTtEmL15p08/JeVfGV0HiPzcqIux4UkzMAZCKyJW64OxuIVAUWS3pb0nqTxAGb2LvA6sC74KDWzRSHU7BLkZy8uIquD+OF4b4NnktB2qVqpI1AIjAXygFmSRgB9gJODMYCXJX3ezN6Kf7OkCcAEgPz8/LBqdm30XtVmXvzrR/zruCKO8zZ4RglzhlMDDIpbzgvG4lUDJWbWYGYrgKXEAuhLwHtmtt3MtgMvAme1/AZmNs3Mis2suG/fvgn5IdzRaWwy7ni+ggE9u3Lj35wQdTkuZGEGzmygUNIQSZ2Ba4CSFuvMIDa7QVIfYrtYVcBq4FxJHSV1InbA2HepUtDT5dUsXLuNWy86ydvgGSi0wDGzvcAtQCmxsHjKzBZKmizpsmC1UmCzpApix2wmmtlmYDqwHFgAzAPmmdlzYdXu2sf23Xv5RekSRuXncNmpA6Iux0Ug1GM4ZjYTmNli7Cdxnxvw/eAjfp1G4KYwanSJ8/s3Ktm0fTcP/v0Yb4NnKD/T2IVizZadPPjWCr40aiCj8ntFXY6LiAeOC8U9/7eYDsLb4BnOA8cl3OyVW3hh/jpu+psT6d8zO+pyXIRaHTiKuV7ST4LlfElnJK40lw6amozJz1VwfI+u3HSut8EzXVtmOPcTO/fl2mD5Y2LXRjl3SM/MrWFBzVZuvWgY3Ton23mmLmxt+Qs408xGS5oLEFxc2TlBdbk0sGP3XqaULubUQTlcfmrLq1hcJmrLDKchuOLbACT1BZoSUpVLCw+8uZz123bzk0uH06GDt8Fd2wLnPuBZoJ+ku4jdIuLuhFTlUl5N3S4emFXFZacOYEyBt8FdTKt3qczsfyWVA18ABFzhV2y7Q/n5i4sBuPWikyKuxCWTVgVOcHe9PDNbDCxObEku1ZWv2kLJvLV8+/yhDMzxNrjbr1W7VMElBzMPu6LLeE1NxuTnF9Hv2C5889wToy7HJZm2HMOZI+n0hFXi0kLJvLXMW1PHD8efxDFdvA3uDtSmtjhwnaRVwA5ix3HMzEZ++ttcpti5Zy/3vLiYEQN78uVR3gZ3n9SWwLkwYVW4tDBtVhUfbavnvmtHeRvcHVSrd6nMbBWQA/xt8JETjDnHuq27+MOby7lkRH/OGJIbdTkuSbXlWqrvAP8L9As+/ijp24kqzKWWX/zfEpoMbvM2uPsUbdml+kdilzfsAJD0c+Bd4LeJKMyljg/X1PHs3BpuHnsig3K7RV2OS2Jt6VIJaIxbbgzGXAYzMyY/t5A+3btw83lDoy7HJbm2zHAeBt6X9GywfAXwUPuX5FLJc/PXMWd1Hb/4yki6exvcHUZbLm34taQ3gM8FQzeY2dyEVOVSQn1DI/fMXMTw/j34ypi8w7/BZbxWB46k/wG+Y2ZzguVekh4ys39IWHUuqT04q4q1W+v51VWnkeVtcNcKbTmGM9LM6poXgud/j2r/klwqWL+tnvvfWM74U47nrBN7R12OSxFtCZwOkvbdZ0BSLsn3qGAXkimlS2hsMiZd7G1w13ptCYxfAe9K+jOx7tSVwF0JqcoltQXVW5leXs1N555AQe9joi7HpZC2HDR+VFIZcD6xu/59ye+Hk3nMjMnPL6RP987c4m1w10ZtOdP4q8AaM/sdkAvcJWl0W76ZpPGSlkiqlHTbIda5SlKFpIWSHg/GzpP0YdxHvaQr2vK9XfuYueAjZq+s5fvjhnFs105Rl+NSTFt2qX5sZn+W9Dlis5xfAr8ndhX5YQX3Q54KjAOqgdmSSsysIm6dQmAScE5wk/Z+AGb2OnBasE4uUAm81IbaXTuob2jk7pmLOOn4Y7n69EFRl+NSUFsOGjefZXwJ8KCZvQC05akNZwCVZlZlZnuAJ4HLW6xzIzA16IBhZhsO8nWuBF40s51t+N6uHfz3X1ZQU7eLn1w63Nvg7oi0JXBqJD0AXA3MlNSlje8fCKyJW64OxuIVAUWS3pb0nqTxB/k61wBPtOH7unaw4eN67n+9knHDj+PsoX2iLselqLYExlVAKXBhcD5OLjCxnevpCBQCY4k9cO9BSTnNL0rqD4wI6vgESRMklUkq27hxYzuXltl+VbqUPY1N3H7xyVGX4lJYW+6Hs9PMnjGzZZKON7N1ZtaW4yg1QPyOf14wFq8aKDGzBjNbASwlFkDNrgKeNbOGQ9Q4zcyKzay4b9++bSjNfZq/1mzlqfI1fOPswQzp421wd+TaMsOJdyQ3VJ8NFEoaEjyx8xqgpMU6M4jNbpDUh9guVlXc69fiu1OhMjPueL6CXt06c8v5hYd/g3Of4kgDp81HDM1sL3ALsd2hRcBTZrZQ0mRJlwWrlQKbJVUArwMTzWwzgKTBxGZIbx5hze4IlC78iPdXbOF744rome1tcHd0jvTShAeP5E1mNpMWsyMz+0nc5wZ8P/ho+d6VfPIgs0ug3XsbuXvmYoqO68613gZ37eCIZjhmdn97F+KSzyNvr2T1lp38+NLhdMw60smwc/sd9V+RpFvboxCXXDZ+vJvfvlbJF07qx+cL/QC8ax9t3qWS9FT8IrEzgH/ebhW5pPDrl5dS39DI7Zd4G9y1nyM5hrPNzP6peUHS79uxHpcEKtZu40+zV/P1swdzYt/uUZfj0shhd6kkPdpiqOUtKf6t/cpxUTMz7nyhgh7ZnfjOF7wN7tpXa2Y4I5o/kfSSmV0Q/6KZbWn3qlzoZsytYUrpEmrqdgHw5dEDyenWlkvlnDu81hw0trjP/ehhGpoxt4ZJzyzYFzYAMxesY8bclieCO3d0WhM4x0v6hqRR+HOo0tKU0iXsamg8YKy+oYkppUsiqsilq9bsUv0HMAa4AciTtABYGHxUmNnTiSvPhWFt3MymNePOHanDBo6ZTYtflpRH7LjOSGIPw/PASXF9j+3Cho93f2J8QE52BNW4dNbmtriZVRO7qvvF9i/HhW3z9t3sbWr6xHh2pywmXjgsgopcOvPz1TNYfUMjNz5axo7djXz3i4UMzMlGwMCcbH725RFcMcovXXPty58rlaGamowf/Hkec1bXcf91o7l4RH+++8WiqMtyac5nOBnq1y8v5fn567h1/ElcPKJ/1OW4DOGBk4H+XLaG371eyTWnD+Kb554QdTkug3jgZJh3lm9i0jML+NzQPtxxxWeQ/NQqFx4PnAxSuWE733ysnCF9jmHqdaPp5Pe4cSHzv7gMsXn7bv7hkdl07tiBh75xut8u1EXCu1QZoL6hkQmPlbN+Wz1PTvgsg3K7RV2Sy1AeOGmuuf1dvqqW+68bzaj8XlGX5DKY71KlOW9/u2TigZPGmtvfVxd7+9slBw+cNPXO8k3c/uwCzhnamzu/5O1vlxw8cNJQc/t7cO9juP+6Md7+dknD/xLTTHP7u1OWt79d8gk1cCSNl7REUqWk2w6xzlWSKiQtlPR43Hi+pJckLQpeHxxW3akivv394NeLvf3tkk5obXFJWcBUYByx++nMllRiZhVx6xQCk4BzzKxWUr+4L/EocJeZvSypO/DJm7hksKYmY+L0+fva36O9/e2SUJgznDOASjOrMrM9wJPA5S3WuRGYama1AGa2AUDScKCjmb0cjG83s53hlZ78fvPKUp6bt5Yfjh/m7W+XtMIMnIHAmrjl6mAsXhFQJOltSe9JGh83XifpGUlzJU0JZkwHkDRBUpmkso0bNybkh0hG08ur+e1rsfb3P597YtTlOHdIyXbQuCNQCIwFrgUelJQTjH8e+AFwOnAC8I2WbzazaWZWbGbFfftmxhNt3l2+mUnPzPf2t0sJYQZODTAobjkvGItXDZSYWYOZrQCWEgugauDDYHdsLzADGB1CzUlt+cbtfPOP5RR4+9uliDD/QmcDhZKGSOoMXAOUtFhnBrHZDZL6ENuVqgremyOpedpyPlBBBtu8fTc3PDybjh3Ew97+dikitMAJZia3AKXAIuApM1soabKky4LVSoHNkiqA14GJZrbZzBqJ7U69GjwXS8CDYdWebLz97VKVzOzwa6Wg4uJiKysri7qMdmdmfOfJDymZt5apXxvNJSO9I+WSi6RyMys+2Gu+059ifvPyUkqC9reHjUs1HjgpZHp5Nfd5+9ulMA+cFOHtb5cOPHBSgLe/Xbrwv9wkt2XHHv7hEW9/u/Tg9zROYvUNjUx4tIyPttbzhN/83KUBD5wkZWb8cPp8ylbVMvVrfvW3Sw++S5WkmtvfEy/09rdLHx44SejpoP19VXEeN4/19rdLHx44Sebd5Zu57Zn5nH1ib+760ghvf7u04oGTRJrb3/m53fi9t79dGvK/6CRxYPv7DHp28/a3Sz/epUoCze3vdVvreeLGz5Lf29vfLj35DCdiZsatT8fa37++6lTGFHj726UvD5yI/eaVZfy/D2Pt70tHDoi6HOcSygMnQk+XV3Pfq8u8/e0yhgdORN6r2t/+vvMKb3+7zOCBE4HlG7dz02P729+dO/qvwWUG/0sPmbe/XSbztniIdu9t5KbHvP3tMpfPcELSfPX37JXe/naZywMnJN7+ds4DJxTPzIm1v786xtvfLrN54CTY+1WbufXp+Zx1gl/97ZwHTgJVbdzOhKD9/Yfrvf3tXKj/B0gaL2mJpEpJtx1inaskVUhaKOnxuPFGSR8GHy2fSZ50vP3t3CeF1haXlAVMBcYB1cBsSSVmVhG3TiEwCTjHzGol9Yv7ErvM7LSw6j0aze3vtd7+du4AYc5wzgAqzazKzPYATwKXt1jnRmCqmdUCmNmGEOtrF/Ht71991dvfzsULM3AGAmvilquDsXhFQJGktyW9J2l83GtdJZUF41cc7BtImhCsU7Zx48b2rb6V/jOu/f23p3r727l4yXamcUegEBgL5AGzJI0wszqgwMxqJJ0AvCZpgZktj3+zmU0DpgEUFxdbuKXDs3OruffVZVzp7W/nDirMGU4NMChuOS8Yi1cNlJhZg5mtAJYSCyDMrCb4bxXwBjAq0QW3xftVm/nh9Fj7+25vfzt3UGEGzmygUNIQSZ2Ba4CW3aYZxGY3SOpDbBerSlIvSV3ixs8BKkgSVRu3c9Mfvf3t3OGEtktlZnsl3QKUAlnAQ2a2UNJkoMzMSoLXLpBUATQCE81ss6SzgQckNRELyXviu1tRam5/d5C3v507HJmFfqgjFMXFxVZWVpbQ77F7byPX/9f7zKveyhM3nsmYgtyEfj/nUoGkcjMrPthrPvc/QmbGrQe0vz1snDscD5wj9J+vLGPGh2v5wQVF3v52rpU8cI5AfPv7W+cNjboc51KGB04bvV+1mVunL/D2t3NHwAOnDVZs2sFNfywnLzfb29/OHQH/P6aVanfs4YaHP6CDxCPe/nbuiCTbpQ1JKXb1d3lw9feZfvW3c0fIZziHYWbc9vQCPli5hV96+9u5o+KBcxj3vrqMZ+fW8IMLirjM29/OHRUPnE/x7Nxq/vOVZXxltLe/nWsPHjiH8MGKLdw6fQGfPSGXn33Z29/OtQcPnINYsWkHEx4rIy83mweuL/b2t3PtxP9PaqH2gKu/T/f2t3PtyNvicZrb3zV1u3j8n86koPcxUZfkXFrxGU6gZfu7eLC3v51rbx44gftereTZuTX86zhvfzuXKBm7SzVjbg1TSpewtm4XOd06Ubuzga+MzuOW87397VyiZGTgzJhbw6RnFrCroRGA2p0NdBCcdUKut7+dS6CM3KWaUrpkX9g0azL4zSvLIqrIucyQkYGztm5Xm8adc+0jIwNnQE52m8adc+0jIwNn4oXDyO6UdcBYdqcsJl44LKKKnMsMGXnQ+IpRsUeaN3epBuRkM/HCYfvGnXOJkZGBA7HQ8YBxLlwZuUvlnItGqIEjabykJZIqJd12iHWuklQhaaGkx1u81kNStaTfhVOxc649hbZLJSkLmAqMA6qB2ZJK4p8RLqkQmAScY2a1kvq1+DJ3ALPCqtk5177CnOGcAVSaWZWZ7QGeBC5vsc6NwFQzqwUwsw3NL0gaAxwHvBRSvc65dhZm4AwE1sQtVwdj8YqAIklvS3pP0ngASR2AXwE/+LRvIGmCpDJJZRs3bmzH0p1z7SHZulQdgUJgLJAHzJI0ArgemGlm1Z92rZOZTQOmAUjaKGlVK75nH2DTUdadTnx7HMi3x36t3RYFh3ohzMCpAQbFLecFY/GqgffNrAFYIWkpsQA6C/i8pJuB7kBnSdvN7KAHngHMrG9ripJUZmbFbfg50ppvjwP59tivPbZFmLtUs4FCSUMkdQauAUparDOD2OwGSX2I7WJVmdl1ZpZvZoOJ7VY9+mlh45xLTqEFjpntBW4BSoFFwFNmtlDSZEmXBauVApslVQCvAxPNbHNYNTrnEktmFnUNkZI0ITj24/Dt0ZJvj/3aY1tkfOA458LjlzY450LjgeOcC40HjnMuNB44cSSdIOm/JU2PupZkIOkKSQ9K+pOkC6KuJ2qSTpb0B0nTJf1z1PVETdIxwZn9l7b6PX7Q+JMkTTezK6OuI1lI6gX80sz+MepakkFwqc2jZnZ91LVESdJkYDtQYWbPt+Y9PsNxrfEjYlf6Z7zgnLEXgJlR1xIlSeOACvl1GqwAAAMASURBVGDD4daNl2zXUiWMpD8D64HTiF1icR1wE3Am8Fam/evdmu2h2IVr9wAvmtmcyIoNQWv/PsysBCiR9ALw+CG+XEpr5bYYCxwDDAd2SZppZk2H/eJmlhEfwGLg+8HntwNLgP7EQvcjoAvQG/gDsByYFHXNSbA9/gUoD7bJN6OuOQm2x1jgPuAB4FtR1xzltohb9xvApa392hlxDEdSV2AlMMDMmiRNAhrN7BfB6zVAnmXCxsC3R0u+PfZL9LbIlGM4pwBzbP+U71TgfQBJecDaTPhjiuPb40C+PfZL6LbIlMAZAcyLWx4JzA8+PxWYn2Etcd8eB/LtsV9Ct0UmBc6HsG/KmG3BbUwJNqjFbn2aKQeOfXscyLfHfgndFhlxDKct/BycA/n2OJBvj/2OZFtkygzHOZcEPHACknpL+gMwKjgyn9F8exzIt8d+R7MtfJfKORcan+E450LjgeOcC40HjnMuNB44zrnQeOA450LjgeOcC40HjksoSSbpj3HLHYPnvrfqDnFx71sZPI31qNZx0fLAcYm2A/iMpOxgeRyffKa8yxAeOC4MM4FLgs+vBZ5ofkFSrqQZkuZLek/SyGC8t6SXJC2U9F+A4t5zvaQPJH0o6QFJWWH+MO7IeeC4MDwJXBNcfTyS4P4qgZ8Cc81sJLG7yz0ajP878BczOwV4FsiH2JMTgKuBc8zsNKCR2C0wXQrImHsau+iY2XxJg4nNblrefPxzwFeC9V4LZjY9gL8BvhyMvyCp+RYJXwDGALNjt1wmmzbeyNtFxwPHhaUE+CWx+wL3PoqvI+B/zCyjL6BMVb5L5cLyEPBTM1vQYvwtgl0iSWOBTWa2DZgFfC0YvwjoFaz/KnClpH7Ba7mSChJfvmsPPsNxoTCzamJPPGjpP4CHJM0HdgJfD8Z/CjwhaSHwDrA6+DoVkn4EvBQ8kK4B+BawKrE/gWsPfnsK51xofJfKORcaDxznXGg8cJxzofHAcc6FxgPHORcaDxznXGg8cJxzofHAcc6F5v8DXqJYHVpX1HgAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plotting scores and saving figure as .pdf file.\n",
        "plot_f1_scores(models_name[1], gru_units, gru_f1_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVqtTIGn9qUo"
      },
      "source": [
        "### Additional BiLSTM Model ($m_2$)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsv40lpYOzy2",
        "outputId": "e528b74a-a4eb-456e-a33c-11cdf572963c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid-search, m_2 model.\n",
            "\n",
            "Number of units: 32.\n",
            "\n",
            "Model: \"m_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_8 (Bidirectio  (None, 249, 512)         628736    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_9 (Bidirectio  (None, 249, 64)          139520    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_8 (TimeDis  (None, 249, 46)          2990      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 771,246\n",
            "Trainable params: 771,246\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 9s 220ms/step - loss: 2.4449 - accuracy: 0.8893 - val_loss: 0.7415 - val_accuracy: 0.9222 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 2s 121ms/step - loss: 0.5043 - accuracy: 0.9268 - val_loss: 0.3450 - val_accuracy: 0.9339 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.2852 - accuracy: 0.9389 - val_loss: 0.2345 - val_accuracy: 0.9455 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.2048 - accuracy: 0.9499 - val_loss: 0.1792 - val_accuracy: 0.9543 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.1594 - accuracy: 0.9585 - val_loss: 0.1447 - val_accuracy: 0.9621 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.1286 - accuracy: 0.9666 - val_loss: 0.1187 - val_accuracy: 0.9691 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.1051 - accuracy: 0.9736 - val_loss: 0.0994 - val_accuracy: 0.9748 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0873 - accuracy: 0.9779 - val_loss: 0.0861 - val_accuracy: 0.9777 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0747 - accuracy: 0.9809 - val_loss: 0.0750 - val_accuracy: 0.9801 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.0647 - accuracy: 0.9834 - val_loss: 0.0673 - val_accuracy: 0.9821 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.0570 - accuracy: 0.9852 - val_loss: 0.0621 - val_accuracy: 0.9833 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.0505 - accuracy: 0.9870 - val_loss: 0.0564 - val_accuracy: 0.9845 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.0443 - accuracy: 0.9887 - val_loss: 0.0521 - val_accuracy: 0.9859 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.0395 - accuracy: 0.9899 - val_loss: 0.0496 - val_accuracy: 0.9864 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 2s 130ms/step - loss: 0.0355 - accuracy: 0.9910 - val_loss: 0.0477 - val_accuracy: 0.9872 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 2s 134ms/step - loss: 0.0322 - accuracy: 0.9920 - val_loss: 0.0447 - val_accuracy: 0.9881 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 2s 127ms/step - loss: 0.0296 - accuracy: 0.9927 - val_loss: 0.0442 - val_accuracy: 0.9881 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.0270 - accuracy: 0.9935 - val_loss: 0.0415 - val_accuracy: 0.9890 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.0239 - accuracy: 0.9944 - val_loss: 0.0402 - val_accuracy: 0.9892 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.0217 - accuracy: 0.9948 - val_loss: 0.0394 - val_accuracy: 0.9894 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0197 - accuracy: 0.9955 - val_loss: 0.0386 - val_accuracy: 0.9897 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.0185 - accuracy: 0.9958 - val_loss: 0.0392 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 2s 125ms/step - loss: 0.0170 - accuracy: 0.9962 - val_loss: 0.0384 - val_accuracy: 0.9898 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 2s 126ms/step - loss: 0.0152 - accuracy: 0.9968 - val_loss: 0.0377 - val_accuracy: 0.9900 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0144 - accuracy: 0.9969 - val_loss: 0.0371 - val_accuracy: 0.9901 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0131 - accuracy: 0.9973 - val_loss: 0.0374 - val_accuracy: 0.9900 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0120 - accuracy: 0.9975 - val_loss: 0.0372 - val_accuracy: 0.9901 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0110 - accuracy: 0.9978 - val_loss: 0.0372 - val_accuracy: 0.9900 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0095 - accuracy: 0.9981 - val_loss: 0.0352 - val_accuracy: 0.9904 - lr: 1.0000e-03\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.0351 - val_accuracy: 0.9905 - lr: 1.0000e-03\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0086 - accuracy: 0.9983 - val_loss: 0.0351 - val_accuracy: 0.9905 - lr: 1.0000e-03\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0085 - accuracy: 0.9983 - val_loss: 0.0350 - val_accuracy: 0.9905 - lr: 1.0000e-03\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.0084 - accuracy: 0.9984 - val_loss: 0.0351 - val_accuracy: 0.9905 - lr: 1.0000e-03\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 2s 122ms/step - loss: 0.0083 - accuracy: 0.9984 - val_loss: 0.0351 - val_accuracy: 0.9905 - lr: 1.0000e-03\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0082 - accuracy: 0.9984 - val_loss: 0.0352 - val_accuracy: 0.9905 - lr: 1.0000e-03\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 2s 123ms/step - loss: 0.0081 - accuracy: 0.9984 - val_loss: 0.0351 - val_accuracy: 0.9905 - lr: 1.0000e-04\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 2s 124ms/step - loss: 0.0080 - accuracy: 0.9985 - val_loss: 0.0351 - val_accuracy: 0.9905 - lr: 1.0000e-04\n",
            "\n",
            "Number of units: 64.\n",
            "\n",
            "Model: \"m_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_10 (Bidirecti  (None, 249, 512)         628736    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_11 (Bidirecti  (None, 249, 128)         295424    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_9 (TimeDis  (None, 249, 46)          5934      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 930,094\n",
            "Trainable params: 930,094\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 10s 279ms/step - loss: 2.4786 - accuracy: 0.8920 - val_loss: 0.7566 - val_accuracy: 0.9242 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 2s 135ms/step - loss: 0.4913 - accuracy: 0.9330 - val_loss: 0.3008 - val_accuracy: 0.9448 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 2s 136ms/step - loss: 0.2260 - accuracy: 0.9538 - val_loss: 0.1663 - val_accuracy: 0.9601 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 2s 136ms/step - loss: 0.1353 - accuracy: 0.9665 - val_loss: 0.1141 - val_accuracy: 0.9700 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 2s 136ms/step - loss: 0.0986 - accuracy: 0.9734 - val_loss: 0.0909 - val_accuracy: 0.9751 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 2s 136ms/step - loss: 0.0792 - accuracy: 0.9781 - val_loss: 0.0770 - val_accuracy: 0.9783 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 0.0661 - accuracy: 0.9817 - val_loss: 0.0673 - val_accuracy: 0.9811 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 0.0560 - accuracy: 0.9846 - val_loss: 0.0596 - val_accuracy: 0.9834 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.0490 - accuracy: 0.9866 - val_loss: 0.0549 - val_accuracy: 0.9847 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.0435 - accuracy: 0.9880 - val_loss: 0.0520 - val_accuracy: 0.9856 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 2s 138ms/step - loss: 0.0386 - accuracy: 0.9894 - val_loss: 0.0464 - val_accuracy: 0.9872 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 2s 138ms/step - loss: 0.0341 - accuracy: 0.9908 - val_loss: 0.0425 - val_accuracy: 0.9880 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.0301 - accuracy: 0.9920 - val_loss: 0.0417 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.0271 - accuracy: 0.9929 - val_loss: 0.0408 - val_accuracy: 0.9886 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.0241 - accuracy: 0.9937 - val_loss: 0.0383 - val_accuracy: 0.9892 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.0214 - accuracy: 0.9946 - val_loss: 0.0369 - val_accuracy: 0.9896 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.0194 - accuracy: 0.9951 - val_loss: 0.0368 - val_accuracy: 0.9897 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.0172 - accuracy: 0.9958 - val_loss: 0.0355 - val_accuracy: 0.9903 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.0158 - accuracy: 0.9962 - val_loss: 0.0362 - val_accuracy: 0.9899 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.0149 - accuracy: 0.9964 - val_loss: 0.0373 - val_accuracy: 0.9899 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.0134 - accuracy: 0.9969 - val_loss: 0.0356 - val_accuracy: 0.9902 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 2s 140ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.0331 - val_accuracy: 0.9908 - lr: 1.0000e-03\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 2s 139ms/step - loss: 0.0099 - accuracy: 0.9977 - val_loss: 0.0331 - val_accuracy: 0.9908 - lr: 1.0000e-03\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 2s 138ms/step - loss: 0.0096 - accuracy: 0.9978 - val_loss: 0.0331 - val_accuracy: 0.9908 - lr: 1.0000e-03\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 0.0094 - accuracy: 0.9978 - val_loss: 0.0331 - val_accuracy: 0.9907 - lr: 1.0000e-03\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 2s 138ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 0.0330 - val_accuracy: 0.9907 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.0330 - val_accuracy: 0.9907 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.0330 - val_accuracy: 0.9907 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.0330 - val_accuracy: 0.9907 - lr: 1.0000e-04\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 2s 137ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.0330 - val_accuracy: 0.9907 - lr: 1.0000e-05\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 2s 136ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.0330 - val_accuracy: 0.9907 - lr: 1.0000e-05\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 2s 138ms/step - loss: 0.0092 - accuracy: 0.9979 - val_loss: 0.0330 - val_accuracy: 0.9907 - lr: 1.0000e-05\n",
            "\n",
            "Number of units: 128.\n",
            "\n",
            "Model: \"m_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_12 (Bidirecti  (None, 249, 512)         628736    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_13 (Bidirecti  (None, 249, 256)         656384    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_10 (TimeDi  (None, 249, 46)          11822     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,296,942\n",
            "Trainable params: 1,296,942\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 9s 259ms/step - loss: 2.9735 - accuracy: 0.8910 - val_loss: 1.0715 - val_accuracy: 0.9284 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.6378 - accuracy: 0.9350 - val_loss: 0.3446 - val_accuracy: 0.9475 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 3s 167ms/step - loss: 0.2502 - accuracy: 0.9528 - val_loss: 0.1755 - val_accuracy: 0.9598 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 3s 168ms/step - loss: 0.1423 - accuracy: 0.9657 - val_loss: 0.1192 - val_accuracy: 0.9690 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 0.1018 - accuracy: 0.9726 - val_loss: 0.0938 - val_accuracy: 0.9739 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.0806 - accuracy: 0.9772 - val_loss: 0.0773 - val_accuracy: 0.9777 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.0670 - accuracy: 0.9811 - val_loss: 0.0682 - val_accuracy: 0.9803 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.0564 - accuracy: 0.9843 - val_loss: 0.0591 - val_accuracy: 0.9833 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.0486 - accuracy: 0.9865 - val_loss: 0.0538 - val_accuracy: 0.9848 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 3s 173ms/step - loss: 0.0431 - accuracy: 0.9879 - val_loss: 0.0506 - val_accuracy: 0.9853 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 3s 173ms/step - loss: 0.0394 - accuracy: 0.9890 - val_loss: 0.0471 - val_accuracy: 0.9864 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 3s 173ms/step - loss: 0.0347 - accuracy: 0.9904 - val_loss: 0.0424 - val_accuracy: 0.9876 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 3s 175ms/step - loss: 0.0309 - accuracy: 0.9915 - val_loss: 0.0410 - val_accuracy: 0.9881 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 3s 177ms/step - loss: 0.0280 - accuracy: 0.9925 - val_loss: 0.0401 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 3s 177ms/step - loss: 0.0253 - accuracy: 0.9931 - val_loss: 0.0389 - val_accuracy: 0.9887 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 3s 174ms/step - loss: 0.0226 - accuracy: 0.9939 - val_loss: 0.0373 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 3s 174ms/step - loss: 0.0206 - accuracy: 0.9945 - val_loss: 0.0358 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 3s 172ms/step - loss: 0.0184 - accuracy: 0.9953 - val_loss: 0.0359 - val_accuracy: 0.9898 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 3s 173ms/step - loss: 0.0163 - accuracy: 0.9959 - val_loss: 0.0366 - val_accuracy: 0.9897 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 3s 173ms/step - loss: 0.0151 - accuracy: 0.9962 - val_loss: 0.0348 - val_accuracy: 0.9902 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 3s 172ms/step - loss: 0.0131 - accuracy: 0.9969 - val_loss: 0.0347 - val_accuracy: 0.9903 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.0122 - accuracy: 0.9972 - val_loss: 0.0350 - val_accuracy: 0.9903 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.0107 - accuracy: 0.9976 - val_loss: 0.0366 - val_accuracy: 0.9903 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.0101 - accuracy: 0.9978 - val_loss: 0.0350 - val_accuracy: 0.9903 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.0080 - accuracy: 0.9983 - val_loss: 0.0333 - val_accuracy: 0.9907 - lr: 1.0000e-03\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.0072 - accuracy: 0.9985 - val_loss: 0.0332 - val_accuracy: 0.9908 - lr: 1.0000e-03\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.0332 - val_accuracy: 0.9909 - lr: 1.0000e-03\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.0068 - accuracy: 0.9986 - val_loss: 0.0331 - val_accuracy: 0.9909 - lr: 1.0000e-03\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.0067 - accuracy: 0.9987 - val_loss: 0.0332 - val_accuracy: 0.9908 - lr: 1.0000e-03\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 3s 169ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.0332 - val_accuracy: 0.9908 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.0332 - val_accuracy: 0.9908 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 3s 170ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.0332 - val_accuracy: 0.9909 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 3s 171ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.0332 - val_accuracy: 0.9909 - lr: 1.0000e-05\n",
            "\n",
            "Number of units: 256.\n",
            "\n",
            "Model: \"m_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_14 (Bidirecti  (None, 249, 512)         628736    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_15 (Bidirecti  (None, 249, 512)         1574912   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_11 (TimeDi  (None, 249, 46)          23598     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,227,246\n",
            "Trainable params: 2,227,246\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 10s 326ms/step - loss: 4.5027 - accuracy: 0.8690 - val_loss: 3.0409 - val_accuracy: 0.8747 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 4s 226ms/step - loss: 1.9730 - accuracy: 0.9237 - val_loss: 1.1732 - val_accuracy: 0.9352 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 4s 225ms/step - loss: 0.7464 - accuracy: 0.9421 - val_loss: 0.4167 - val_accuracy: 0.9498 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 4s 227ms/step - loss: 0.2991 - accuracy: 0.9557 - val_loss: 0.2063 - val_accuracy: 0.9598 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 4s 228ms/step - loss: 0.1637 - accuracy: 0.9664 - val_loss: 0.1328 - val_accuracy: 0.9689 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 4s 230ms/step - loss: 0.1132 - accuracy: 0.9725 - val_loss: 0.1021 - val_accuracy: 0.9739 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 4s 231ms/step - loss: 0.0894 - accuracy: 0.9768 - val_loss: 0.0863 - val_accuracy: 0.9771 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 4s 233ms/step - loss: 0.0749 - accuracy: 0.9800 - val_loss: 0.0758 - val_accuracy: 0.9791 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 4s 233ms/step - loss: 0.0641 - accuracy: 0.9827 - val_loss: 0.0656 - val_accuracy: 0.9822 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 4s 235ms/step - loss: 0.0566 - accuracy: 0.9847 - val_loss: 0.0634 - val_accuracy: 0.9822 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 4s 234ms/step - loss: 0.0514 - accuracy: 0.9859 - val_loss: 0.0555 - val_accuracy: 0.9847 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 4s 234ms/step - loss: 0.0459 - accuracy: 0.9875 - val_loss: 0.0510 - val_accuracy: 0.9859 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 4s 233ms/step - loss: 0.0413 - accuracy: 0.9887 - val_loss: 0.0479 - val_accuracy: 0.9864 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 4s 231ms/step - loss: 0.0371 - accuracy: 0.9898 - val_loss: 0.0460 - val_accuracy: 0.9871 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 4s 230ms/step - loss: 0.0331 - accuracy: 0.9909 - val_loss: 0.0440 - val_accuracy: 0.9878 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 4s 229ms/step - loss: 0.0302 - accuracy: 0.9917 - val_loss: 0.0417 - val_accuracy: 0.9883 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 4s 230ms/step - loss: 0.0277 - accuracy: 0.9925 - val_loss: 0.0417 - val_accuracy: 0.9883 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 4s 229ms/step - loss: 0.0264 - accuracy: 0.9930 - val_loss: 0.0395 - val_accuracy: 0.9890 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 4s 229ms/step - loss: 0.0235 - accuracy: 0.9938 - val_loss: 0.0383 - val_accuracy: 0.9894 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 4s 226ms/step - loss: 0.0218 - accuracy: 0.9943 - val_loss: 0.0388 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 4s 227ms/step - loss: 0.0205 - accuracy: 0.9947 - val_loss: 0.0370 - val_accuracy: 0.9897 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 4s 225ms/step - loss: 0.0183 - accuracy: 0.9953 - val_loss: 0.0384 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 4s 226ms/step - loss: 0.0167 - accuracy: 0.9958 - val_loss: 0.0377 - val_accuracy: 0.9897 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 4s 226ms/step - loss: 0.0154 - accuracy: 0.9962 - val_loss: 0.0367 - val_accuracy: 0.9900 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 4s 226ms/step - loss: 0.0138 - accuracy: 0.9967 - val_loss: 0.0367 - val_accuracy: 0.9901 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 4s 228ms/step - loss: 0.0125 - accuracy: 0.9971 - val_loss: 0.0360 - val_accuracy: 0.9903 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 4s 227ms/step - loss: 0.0116 - accuracy: 0.9973 - val_loss: 0.0368 - val_accuracy: 0.9901 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 4s 227ms/step - loss: 0.0109 - accuracy: 0.9975 - val_loss: 0.0404 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 4s 227ms/step - loss: 0.0109 - accuracy: 0.9975 - val_loss: 0.0370 - val_accuracy: 0.9904 - lr: 0.0100\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 4s 229ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.0351 - val_accuracy: 0.9907 - lr: 1.0000e-03\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 4s 229ms/step - loss: 0.0075 - accuracy: 0.9984 - val_loss: 0.0347 - val_accuracy: 0.9908 - lr: 1.0000e-03\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 4s 229ms/step - loss: 0.0073 - accuracy: 0.9985 - val_loss: 0.0347 - val_accuracy: 0.9907 - lr: 1.0000e-03\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 4s 229ms/step - loss: 0.0071 - accuracy: 0.9985 - val_loss: 0.0346 - val_accuracy: 0.9907 - lr: 1.0000e-03\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 4s 229ms/step - loss: 0.0071 - accuracy: 0.9986 - val_loss: 0.0347 - val_accuracy: 0.9907 - lr: 1.0000e-03\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 4s 227ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 0.0350 - val_accuracy: 0.9908 - lr: 1.0000e-03\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 4s 228ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.0349 - val_accuracy: 0.9908 - lr: 1.0000e-03\n",
            "Epoch 37/100\n",
            "16/16 [==============================] - 4s 227ms/step - loss: 0.0067 - accuracy: 0.9987 - val_loss: 0.0349 - val_accuracy: 0.9907 - lr: 1.0000e-04\n",
            "Epoch 38/100\n",
            "16/16 [==============================] - 4s 228ms/step - loss: 0.0067 - accuracy: 0.9987 - val_loss: 0.0349 - val_accuracy: 0.9907 - lr: 1.0000e-04\n"
          ]
        }
      ],
      "source": [
        "# Possible units.\n",
        "double_lstm_units = [32, 64, 128, 256]\n",
        "\n",
        "# Computing models and histories.\n",
        "double_lstm_models, double_lstm_model_histories = grid_search(models_name[2], double_lstm_units, baseline_best_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-HZGh7gPCZ3",
        "outputId": "6c715b89-78b3-41ec-ad75-25cbe19b8f64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 2s 22ms/step\n",
            "41/41 [==============================] - 3s 25ms/step\n",
            "41/41 [==============================] - 2s 25ms/step\n",
            "41/41 [==============================] - 2s 25ms/step\n",
            "The best number of units is: 128.\n"
          ]
        }
      ],
      "source": [
        "# Storing best model.\n",
        "_, double_lstm_f1_scores, models[models_name[2]] = get_best_model(double_lstm_models, double_lstm_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nXa5naV_dDPV",
        "outputId": "96a7f9fb-5aee-4821-9050-9a237fb5251d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plotting losses and saving figure as .pdf file.\n",
        "plot_training_loss(models_name[2], double_lstm_units, double_lstm_model_histories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zm-3dM5PldPF",
        "outputId": "7cff80a6-dc21-4fcc-d956-964a29981308"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plotting scores and saving figure as .pdf file.\n",
        "plot_f1_scores(models_name[2], double_lstm_units, double_lstm_f1_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIOxs5nNC3yG"
      },
      "source": [
        "### Additional Dense Layer Model ($m_3$)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wPBLVr5PeUE",
        "outputId": "6ead0d77-d57c-4e38-ed8d-40227017a8cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid-search, m_3 model.\n",
            "\n",
            "Number of units: 32.\n",
            "\n",
            "Model: \"m_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_16 (Bidirecti  (None, 249, 512)         628736    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_12 (TimeDi  (None, 249, 32)          16416     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 249, 32)           0         \n",
            "                                                                 \n",
            " time_distributed_13 (TimeDi  (None, 249, 46)          1518      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 646,670\n",
            "Trainable params: 646,670\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 5s 152ms/step - loss: 2.4843 - accuracy: 0.8873 - val_loss: 0.9946 - val_accuracy: 0.9308 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.6011 - accuracy: 0.9414 - val_loss: 0.3142 - val_accuracy: 0.9487 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.2293 - accuracy: 0.9539 - val_loss: 0.1647 - val_accuracy: 0.9612 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.1337 - accuracy: 0.9672 - val_loss: 0.1136 - val_accuracy: 0.9700 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0972 - accuracy: 0.9738 - val_loss: 0.0907 - val_accuracy: 0.9749 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0782 - accuracy: 0.9781 - val_loss: 0.0766 - val_accuracy: 0.9782 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0661 - accuracy: 0.9815 - val_loss: 0.0685 - val_accuracy: 0.9806 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0572 - accuracy: 0.9841 - val_loss: 0.0607 - val_accuracy: 0.9827 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0501 - accuracy: 0.9860 - val_loss: 0.0566 - val_accuracy: 0.9837 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0447 - accuracy: 0.9875 - val_loss: 0.0534 - val_accuracy: 0.9846 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0412 - accuracy: 0.9883 - val_loss: 0.0492 - val_accuracy: 0.9858 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0366 - accuracy: 0.9897 - val_loss: 0.0469 - val_accuracy: 0.9864 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0339 - accuracy: 0.9904 - val_loss: 0.0472 - val_accuracy: 0.9865 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0318 - accuracy: 0.9911 - val_loss: 0.0465 - val_accuracy: 0.9866 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0283 - accuracy: 0.9921 - val_loss: 0.0432 - val_accuracy: 0.9874 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0258 - accuracy: 0.9928 - val_loss: 0.0405 - val_accuracy: 0.9883 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0239 - accuracy: 0.9934 - val_loss: 0.0392 - val_accuracy: 0.9889 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0215 - accuracy: 0.9943 - val_loss: 0.0388 - val_accuracy: 0.9891 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 94ms/step - loss: 0.0194 - accuracy: 0.9948 - val_loss: 0.0385 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0182 - accuracy: 0.9952 - val_loss: 0.0383 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0165 - accuracy: 0.9957 - val_loss: 0.0377 - val_accuracy: 0.9897 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0154 - accuracy: 0.9961 - val_loss: 0.0384 - val_accuracy: 0.9897 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0141 - accuracy: 0.9964 - val_loss: 0.0393 - val_accuracy: 0.9897 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0131 - accuracy: 0.9968 - val_loss: 0.0384 - val_accuracy: 0.9897 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0110 - accuracy: 0.9974 - val_loss: 0.0364 - val_accuracy: 0.9902 - lr: 1.0000e-03\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.0362 - val_accuracy: 0.9901 - lr: 1.0000e-03\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 0.0363 - val_accuracy: 0.9902 - lr: 1.0000e-03\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0097 - accuracy: 0.9978 - val_loss: 0.0362 - val_accuracy: 0.9901 - lr: 1.0000e-03\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0096 - accuracy: 0.9977 - val_loss: 0.0362 - val_accuracy: 0.9902 - lr: 1.0000e-03\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0094 - accuracy: 0.9978 - val_loss: 0.0362 - val_accuracy: 0.9902 - lr: 1.0000e-04\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0094 - accuracy: 0.9978 - val_loss: 0.0363 - val_accuracy: 0.9902 - lr: 1.0000e-04\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 1s 91ms/step - loss: 0.0093 - accuracy: 0.9978 - val_loss: 0.0362 - val_accuracy: 0.9901 - lr: 1.0000e-04\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0093 - accuracy: 0.9978 - val_loss: 0.0362 - val_accuracy: 0.9901 - lr: 1.0000e-05\n",
            "\n",
            "Number of units: 64.\n",
            "\n",
            "Model: \"m_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_17 (Bidirecti  (None, 249, 512)         628736    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_14 (TimeDi  (None, 249, 64)          32832     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 249, 64)           0         \n",
            "                                                                 \n",
            " time_distributed_15 (TimeDi  (None, 249, 46)          2990      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 664,558\n",
            "Trainable params: 664,558\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 5s 154ms/step - loss: 2.9070 - accuracy: 0.8857 - val_loss: 1.5277 - val_accuracy: 0.9260 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 1.0050 - accuracy: 0.9416 - val_loss: 0.5767 - val_accuracy: 0.9497 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.3936 - accuracy: 0.9552 - val_loss: 0.2425 - val_accuracy: 0.9625 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.1796 - accuracy: 0.9676 - val_loss: 0.1340 - val_accuracy: 0.9704 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.1114 - accuracy: 0.9731 - val_loss: 0.1005 - val_accuracy: 0.9738 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0862 - accuracy: 0.9765 - val_loss: 0.0832 - val_accuracy: 0.9770 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0725 - accuracy: 0.9798 - val_loss: 0.0731 - val_accuracy: 0.9792 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0629 - accuracy: 0.9824 - val_loss: 0.0675 - val_accuracy: 0.9809 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0559 - accuracy: 0.9843 - val_loss: 0.0613 - val_accuracy: 0.9826 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0507 - accuracy: 0.9857 - val_loss: 0.0576 - val_accuracy: 0.9836 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0468 - accuracy: 0.9866 - val_loss: 0.0537 - val_accuracy: 0.9848 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0422 - accuracy: 0.9880 - val_loss: 0.0515 - val_accuracy: 0.9852 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0398 - accuracy: 0.9886 - val_loss: 0.0502 - val_accuracy: 0.9855 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0365 - accuracy: 0.9897 - val_loss: 0.0473 - val_accuracy: 0.9866 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0334 - accuracy: 0.9906 - val_loss: 0.0467 - val_accuracy: 0.9865 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0311 - accuracy: 0.9912 - val_loss: 0.0436 - val_accuracy: 0.9875 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0287 - accuracy: 0.9920 - val_loss: 0.0421 - val_accuracy: 0.9880 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0272 - accuracy: 0.9923 - val_loss: 0.0427 - val_accuracy: 0.9880 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0249 - accuracy: 0.9931 - val_loss: 0.0414 - val_accuracy: 0.9883 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0232 - accuracy: 0.9936 - val_loss: 0.0407 - val_accuracy: 0.9887 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0215 - accuracy: 0.9940 - val_loss: 0.0401 - val_accuracy: 0.9889 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0202 - accuracy: 0.9944 - val_loss: 0.0394 - val_accuracy: 0.9890 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 1s 94ms/step - loss: 0.0192 - accuracy: 0.9947 - val_loss: 0.0399 - val_accuracy: 0.9891 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 2s 98ms/step - loss: 0.0179 - accuracy: 0.9951 - val_loss: 0.0391 - val_accuracy: 0.9892 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 1s 94ms/step - loss: 0.0164 - accuracy: 0.9957 - val_loss: 0.0409 - val_accuracy: 0.9892 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0153 - accuracy: 0.9960 - val_loss: 0.0400 - val_accuracy: 0.9894 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0143 - accuracy: 0.9963 - val_loss: 0.0416 - val_accuracy: 0.9891 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 1s 94ms/step - loss: 0.0126 - accuracy: 0.9967 - val_loss: 0.0381 - val_accuracy: 0.9896 - lr: 1.0000e-03\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0115 - accuracy: 0.9971 - val_loss: 0.0378 - val_accuracy: 0.9898 - lr: 1.0000e-03\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0113 - accuracy: 0.9972 - val_loss: 0.0380 - val_accuracy: 0.9897 - lr: 1.0000e-03\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 1s 92ms/step - loss: 0.0112 - accuracy: 0.9972 - val_loss: 0.0378 - val_accuracy: 0.9898 - lr: 1.0000e-03\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0111 - accuracy: 0.9973 - val_loss: 0.0378 - val_accuracy: 0.9898 - lr: 1.0000e-03\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0109 - accuracy: 0.9973 - val_loss: 0.0378 - val_accuracy: 0.9898 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 0.0108 - accuracy: 0.9973 - val_loss: 0.0378 - val_accuracy: 0.9898 - lr: 1.0000e-04\n",
            "\n",
            "Number of units: 128.\n",
            "\n",
            "Model: \"m_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_18 (Bidirecti  (None, 249, 512)         628736    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_16 (TimeDi  (None, 249, 128)         65664     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_16 (Activation)  (None, 249, 128)          0         \n",
            "                                                                 \n",
            " time_distributed_17 (TimeDi  (None, 249, 46)          5934      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_17 (Activation)  (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 700,334\n",
            "Trainable params: 700,334\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 5s 156ms/step - loss: 3.9125 - accuracy: 0.7833 - val_loss: 2.7849 - val_accuracy: 0.9235 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 1s 93ms/step - loss: 2.3353 - accuracy: 0.9351 - val_loss: 1.4523 - val_accuracy: 0.9462 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 1s 94ms/step - loss: 0.9524 - accuracy: 0.9517 - val_loss: 0.5507 - val_accuracy: 0.9571 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 1s 94ms/step - loss: 0.4033 - accuracy: 0.9634 - val_loss: 0.2839 - val_accuracy: 0.9666 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 1s 95ms/step - loss: 0.2265 - accuracy: 0.9706 - val_loss: 0.1822 - val_accuracy: 0.9720 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 1s 95ms/step - loss: 0.1519 - accuracy: 0.9755 - val_loss: 0.1318 - val_accuracy: 0.9763 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 1s 95ms/step - loss: 0.1127 - accuracy: 0.9795 - val_loss: 0.1040 - val_accuracy: 0.9793 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 1s 94ms/step - loss: 0.0890 - accuracy: 0.9823 - val_loss: 0.0871 - val_accuracy: 0.9812 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 1s 94ms/step - loss: 0.0736 - accuracy: 0.9844 - val_loss: 0.0750 - val_accuracy: 0.9829 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 1s 95ms/step - loss: 0.0624 - accuracy: 0.9860 - val_loss: 0.0662 - val_accuracy: 0.9846 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 1s 95ms/step - loss: 0.0543 - accuracy: 0.9873 - val_loss: 0.0607 - val_accuracy: 0.9852 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 0.0481 - accuracy: 0.9883 - val_loss: 0.0553 - val_accuracy: 0.9859 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 1s 95ms/step - loss: 0.0425 - accuracy: 0.9895 - val_loss: 0.0514 - val_accuracy: 0.9864 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 2s 95ms/step - loss: 0.0381 - accuracy: 0.9904 - val_loss: 0.0490 - val_accuracy: 0.9867 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 1s 95ms/step - loss: 0.0344 - accuracy: 0.9912 - val_loss: 0.0460 - val_accuracy: 0.9872 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 0.0312 - accuracy: 0.9920 - val_loss: 0.0444 - val_accuracy: 0.9876 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 2s 95ms/step - loss: 0.0288 - accuracy: 0.9925 - val_loss: 0.0423 - val_accuracy: 0.9881 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 0.0265 - accuracy: 0.9930 - val_loss: 0.0423 - val_accuracy: 0.9879 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 0.0249 - accuracy: 0.9933 - val_loss: 0.0417 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 0.0228 - accuracy: 0.9939 - val_loss: 0.0410 - val_accuracy: 0.9884 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 0.0205 - accuracy: 0.9945 - val_loss: 0.0384 - val_accuracy: 0.9890 - lr: 0.0100\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 0.0193 - accuracy: 0.9948 - val_loss: 0.0402 - val_accuracy: 0.9886 - lr: 0.0100\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 0.0183 - accuracy: 0.9950 - val_loss: 0.0388 - val_accuracy: 0.9892 - lr: 0.0100\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 0.0166 - accuracy: 0.9956 - val_loss: 0.0375 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 2s 97ms/step - loss: 0.0150 - accuracy: 0.9960 - val_loss: 0.0379 - val_accuracy: 0.9896 - lr: 0.0100\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 0.0377 - val_accuracy: 0.9897 - lr: 0.0100\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 0.0127 - accuracy: 0.9967 - val_loss: 0.0393 - val_accuracy: 0.9893 - lr: 0.0100\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 0.0113 - accuracy: 0.9971 - val_loss: 0.0375 - val_accuracy: 0.9898 - lr: 1.0000e-03\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 0.0105 - accuracy: 0.9974 - val_loss: 0.0372 - val_accuracy: 0.9899 - lr: 1.0000e-03\n",
            "Epoch 30/100\n",
            "16/16 [==============================] - 2s 96ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 0.0372 - val_accuracy: 0.9899 - lr: 1.0000e-03\n",
            "Epoch 31/100\n",
            "16/16 [==============================] - 2s 95ms/step - loss: 0.0102 - accuracy: 0.9975 - val_loss: 0.0371 - val_accuracy: 0.9899 - lr: 1.0000e-03\n",
            "Epoch 32/100\n",
            "16/16 [==============================] - 1s 95ms/step - loss: 0.0101 - accuracy: 0.9975 - val_loss: 0.0372 - val_accuracy: 0.9899 - lr: 1.0000e-03\n",
            "Epoch 33/100\n",
            "16/16 [==============================] - 1s 95ms/step - loss: 0.0100 - accuracy: 0.9976 - val_loss: 0.0372 - val_accuracy: 0.9899 - lr: 1.0000e-04\n",
            "Epoch 34/100\n",
            "16/16 [==============================] - 1s 95ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.0372 - val_accuracy: 0.9899 - lr: 1.0000e-04\n",
            "Epoch 35/100\n",
            "16/16 [==============================] - 1s 95ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.0372 - val_accuracy: 0.9899 - lr: 1.0000e-04\n",
            "Epoch 36/100\n",
            "16/16 [==============================] - 1s 95ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.0372 - val_accuracy: 0.9899 - lr: 1.0000e-05\n",
            "\n",
            "Number of units: 256.\n",
            "\n",
            "Model: \"m_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_19 (Bidirecti  (None, 249, 512)         628736    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_18 (TimeDi  (None, 249, 256)         131328    \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_18 (Activation)  (None, 249, 256)          0         \n",
            "                                                                 \n",
            " time_distributed_19 (TimeDi  (None, 249, 46)          11822     \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " activation_19 (Activation)  (None, 249, 46)           0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 771,886\n",
            "Trainable params: 771,886\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "16/16 [==============================] - 5s 160ms/step - loss: 2.3975 - accuracy: 0.8982 - val_loss: 1.0967 - val_accuracy: 0.9385 - lr: 0.0100\n",
            "Epoch 2/100\n",
            "16/16 [==============================] - 2s 98ms/step - loss: 0.6633 - accuracy: 0.9488 - val_loss: 0.3293 - val_accuracy: 0.9604 - lr: 0.0100\n",
            "Epoch 3/100\n",
            "16/16 [==============================] - 2s 98ms/step - loss: 0.2166 - accuracy: 0.9671 - val_loss: 0.1374 - val_accuracy: 0.9700 - lr: 0.0100\n",
            "Epoch 4/100\n",
            "16/16 [==============================] - 2s 99ms/step - loss: 0.1049 - accuracy: 0.9748 - val_loss: 0.0871 - val_accuracy: 0.9769 - lr: 0.0100\n",
            "Epoch 5/100\n",
            "16/16 [==============================] - 2s 98ms/step - loss: 0.0715 - accuracy: 0.9800 - val_loss: 0.0689 - val_accuracy: 0.9805 - lr: 0.0100\n",
            "Epoch 6/100\n",
            "16/16 [==============================] - 2s 99ms/step - loss: 0.0565 - accuracy: 0.9835 - val_loss: 0.0586 - val_accuracy: 0.9832 - lr: 0.0100\n",
            "Epoch 7/100\n",
            "16/16 [==============================] - 2s 99ms/step - loss: 0.0487 - accuracy: 0.9858 - val_loss: 0.0528 - val_accuracy: 0.9847 - lr: 0.0100\n",
            "Epoch 8/100\n",
            "16/16 [==============================] - 2s 99ms/step - loss: 0.0425 - accuracy: 0.9875 - val_loss: 0.0495 - val_accuracy: 0.9853 - lr: 0.0100\n",
            "Epoch 9/100\n",
            "16/16 [==============================] - 2s 100ms/step - loss: 0.0370 - accuracy: 0.9891 - val_loss: 0.0457 - val_accuracy: 0.9867 - lr: 0.0100\n",
            "Epoch 10/100\n",
            "16/16 [==============================] - 2s 99ms/step - loss: 0.0337 - accuracy: 0.9900 - val_loss: 0.0447 - val_accuracy: 0.9870 - lr: 0.0100\n",
            "Epoch 11/100\n",
            "16/16 [==============================] - 2s 100ms/step - loss: 0.0307 - accuracy: 0.9909 - val_loss: 0.0413 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 12/100\n",
            "16/16 [==============================] - 2s 99ms/step - loss: 0.0270 - accuracy: 0.9922 - val_loss: 0.0408 - val_accuracy: 0.9886 - lr: 0.0100\n",
            "Epoch 13/100\n",
            "16/16 [==============================] - 2s 101ms/step - loss: 0.0250 - accuracy: 0.9928 - val_loss: 0.0401 - val_accuracy: 0.9887 - lr: 0.0100\n",
            "Epoch 14/100\n",
            "16/16 [==============================] - 2s 100ms/step - loss: 0.0226 - accuracy: 0.9935 - val_loss: 0.0423 - val_accuracy: 0.9882 - lr: 0.0100\n",
            "Epoch 15/100\n",
            "16/16 [==============================] - 2s 101ms/step - loss: 0.0212 - accuracy: 0.9938 - val_loss: 0.0420 - val_accuracy: 0.9883 - lr: 0.0100\n",
            "Epoch 16/100\n",
            "16/16 [==============================] - 2s 101ms/step - loss: 0.0190 - accuracy: 0.9945 - val_loss: 0.0379 - val_accuracy: 0.9898 - lr: 0.0100\n",
            "Epoch 17/100\n",
            "16/16 [==============================] - 2s 101ms/step - loss: 0.0165 - accuracy: 0.9953 - val_loss: 0.0375 - val_accuracy: 0.9897 - lr: 0.0100\n",
            "Epoch 18/100\n",
            "16/16 [==============================] - 2s 100ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.0389 - val_accuracy: 0.9896 - lr: 0.0100\n",
            "Epoch 19/100\n",
            "16/16 [==============================] - 2s 101ms/step - loss: 0.0136 - accuracy: 0.9962 - val_loss: 0.0390 - val_accuracy: 0.9897 - lr: 0.0100\n",
            "Epoch 20/100\n",
            "16/16 [==============================] - 2s 101ms/step - loss: 0.0125 - accuracy: 0.9966 - val_loss: 0.0405 - val_accuracy: 0.9895 - lr: 0.0100\n",
            "Epoch 21/100\n",
            "16/16 [==============================] - 2s 101ms/step - loss: 0.0101 - accuracy: 0.9974 - val_loss: 0.0374 - val_accuracy: 0.9901 - lr: 1.0000e-03\n",
            "Epoch 22/100\n",
            "16/16 [==============================] - 2s 102ms/step - loss: 0.0090 - accuracy: 0.9977 - val_loss: 0.0367 - val_accuracy: 0.9903 - lr: 1.0000e-03\n",
            "Epoch 23/100\n",
            "16/16 [==============================] - 2s 101ms/step - loss: 0.0086 - accuracy: 0.9978 - val_loss: 0.0367 - val_accuracy: 0.9903 - lr: 1.0000e-03\n",
            "Epoch 24/100\n",
            "16/16 [==============================] - 2s 102ms/step - loss: 0.0085 - accuracy: 0.9979 - val_loss: 0.0367 - val_accuracy: 0.9903 - lr: 1.0000e-03\n",
            "Epoch 25/100\n",
            "16/16 [==============================] - 2s 104ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.0368 - val_accuracy: 0.9903 - lr: 1.0000e-03\n",
            "Epoch 26/100\n",
            "16/16 [==============================] - 2s 102ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 0.0367 - val_accuracy: 0.9904 - lr: 1.0000e-04\n",
            "Epoch 27/100\n",
            "16/16 [==============================] - 2s 101ms/step - loss: 0.0081 - accuracy: 0.9980 - val_loss: 0.0367 - val_accuracy: 0.9903 - lr: 1.0000e-04\n",
            "Epoch 28/100\n",
            "16/16 [==============================] - 2s 101ms/step - loss: 0.0080 - accuracy: 0.9980 - val_loss: 0.0368 - val_accuracy: 0.9903 - lr: 1.0000e-04\n",
            "Epoch 29/100\n",
            "16/16 [==============================] - 2s 102ms/step - loss: 0.0080 - accuracy: 0.9981 - val_loss: 0.0368 - val_accuracy: 0.9904 - lr: 1.0000e-05\n"
          ]
        }
      ],
      "source": [
        "# Possible units.\n",
        "double_dense_units = [32, 64, 128, 256]\n",
        "\n",
        "# Computing models and histories.\n",
        "double_dense_models, double_dense_model_histories = grid_search(models_name[3], double_dense_units, baseline_best_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSvZYbeoQTnv",
        "outputId": "261beb98-b8e3-48b0-e7c1-5296a951304b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 2s 16ms/step\n",
            "41/41 [==============================] - 1s 13ms/step\n",
            "41/41 [==============================] - 1s 13ms/step\n",
            "41/41 [==============================] - 1s 13ms/step\n",
            "The best number of units is: 256.\n"
          ]
        }
      ],
      "source": [
        "# Storing best model.\n",
        "_, double_dense_f1_scores, models[models_name[3]] = get_best_model(double_dense_models, double_dense_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2a2RUiMSdRca",
        "outputId": "2c971d7c-cdb5-4034-966f-831afd12095a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plotting losses and saving figure as .pdf file.\n",
        "plot_training_loss(models_name[3], double_dense_units, double_dense_model_histories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WW_w2k22livM",
        "outputId": "904ffb9f-a644-4de2-cab8-90f4b9c94157"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plotting scores and saving figure as .pdf file.\n",
        "plot_f1_scores(models_name[3], double_dense_units, double_dense_f1_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXJiM4jgQuAb"
      },
      "source": [
        "## Models Testing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best models validation macro F1-scores.\n",
        "models_val_score = {}\n",
        "\n",
        "# Best models validation predictions.\n",
        "best_val_pred = {}\n",
        "\n",
        "# Computing macro F1-scores on the four models selected with grid-search.\n",
        "for model in models:\n",
        "\n",
        "  # Printing the description of the two best models.\n",
        "  print(f\"{descriptions_dict[model]}\\n\")\n",
        "\n",
        "  # Computing macro F1-score.\n",
        "  models_val_score[model], best_val_pred[model] = compute_F1_score(models[model], validation_features, validation_tags, tag_to_index)\n",
        "\n",
        "  # Computing and printing macro F1-score.\n",
        "  print(f\"The macro F1-score for model {model} is: {models_val_score[model]}.\\n\")\n",
        "\n",
        "# Storing the two best models.\n",
        "best_models = sorted(models_val_score, key = models_val_score.get, reverse = True)[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIJo6bN2wPVm",
        "outputId": "d96c0dbc-9425-42dd-d39a-b0e3edbf8aaa"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline model (m_0): \n",
            " - Bi-directional LSTM layer. \n",
            " - Time-distributed dense layer. \n",
            " - Softmax activation function.\n",
            "\n",
            "41/41 [==============================] - 1s 13ms/step\n",
            "The macro F1-score for model m_0 is: 0.7273296529644282.\n",
            "\n",
            "BiGRU model (m_1): \n",
            " - Bi-directional GRU layer. \n",
            " - Time-distributed dense layer. \n",
            " - Softmax activation function.\n",
            "\n",
            "41/41 [==============================] - 0s 9ms/step\n",
            "The macro F1-score for model m_1 is: 0.7011445949744699.\n",
            "\n",
            "Additional bi-directional LSTM model (m_2): \n",
            " - Bi-directional LSTM layer. \n",
            " - Bi-directional LSTM layer. \n",
            " - Time-distributed dense layer. \n",
            " - Softmax activation function.\n",
            "\n",
            "41/41 [==============================] - 1s 24ms/step\n",
            "The macro F1-score for model m_2 is: 0.7115136937136046.\n",
            "\n",
            "Additional dense layer model (m_3): \n",
            " - Bi-directional LSTM layer. \n",
            " - Time-distributed dense layer. \n",
            " - ReLU activation function. \n",
            " - Time-distributed dense layer. \n",
            " - Softmax activation function.\n",
            "\n",
            "41/41 [==============================] - 1s 14ms/step\n",
            "The macro F1-score for model m_3 is: 0.6998095528849744.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2BQysorQxR3",
        "outputId": "9f6925af-4f5d-4552-aa6f-aa42b0f1daa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline model (m_0): \n",
            " - Bi-directional LSTM layer. \n",
            " - Time-distributed dense layer. \n",
            " - Softmax activation function.\n",
            "\n",
            "21/21 [==============================] - 0s 13ms/step\n",
            "The macro F1-score, on the test set, for model m_0 is: 0.7219506363115593.\n",
            "\n",
            "Additional bi-directional LSTM model (m_2): \n",
            " - Bi-directional LSTM layer. \n",
            " - Bi-directional LSTM layer. \n",
            " - Time-distributed dense layer. \n",
            " - Softmax activation function.\n",
            "\n",
            "21/21 [==============================] - 1s 25ms/step\n",
            "The macro F1-score, on the test set, for model m_2 is: 0.7179347411594584.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Best models test macro F1-scores.\n",
        "models_test_score = {}\n",
        "\n",
        "# Best models test predictions.\n",
        "best_test_pred = {}\n",
        "\n",
        "# Testing the two best models.\n",
        "for model in best_models:\n",
        "\n",
        "  # Printing the description of the two best models.\n",
        "  print(f\"{descriptions_dict[model]}\\n\")\n",
        "\n",
        "  # Computing predictions and f1-score.\n",
        "  models_test_score[model], best_test_pred[model] = compute_F1_score(models[model], test_features, test_tags, tag_to_index)\n",
        "\n",
        "  # Printing macro F1-score.\n",
        "  print(f\"The macro F1-score, on the test set, for model {model} is: {models_test_score[model]}.\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Error Analysis"
      ],
      "metadata": {
        "id": "mzcYbRABcNfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function used to compute % of miss-classification.\n",
        "def get_missclassification_percentage(true_labels, pred_labels, tag_to_index, punctuation_tag_list):\n",
        "\n",
        "  # Computing punctuation tags indexes.\n",
        "  punctuation_indexes = [tag_to_index[tag] for tag in punctuation_tag_list]\n",
        "\n",
        "  # Computing labels mask. Only non-punctuation tags are set to True.\n",
        "  mask = np.isin(true_labels, punctuation_indexes)\n",
        "\n",
        "  # Deleting true labels corresponding to punctuation classes.\n",
        "  true = np.delete(true_labels, mask)\n",
        "\n",
        "  # Deleting pred labels corresponding to punctuation classes.\n",
        "  pred = np.delete(pred_labels, mask)\n",
        "\n",
        "  # Returning missclassification percentage.\n",
        "  return np.sum(true != pred) / len(true)\n",
        "\n",
        "# Plotting test distribution for each best model.\n",
        "for model in best_models:\n",
        "\n",
        "  # Flattening val prediction.\n",
        "  model_val_pred = np.argmax(best_val_pred[model], axis = 2).flatten()\n",
        "\n",
        "  # Printing validation missclassification percentage.\n",
        "  print(\"{}, miss-classification percentage on the validation set: {}%.\".format(model,\n",
        "                                                                                get_missclassification_percentage(validation_tags.flatten(),\n",
        "                                                                                                                  model_val_pred,\n",
        "                                                                                                                  tag_to_index,\n",
        "                                                                                                                  punctuation_tag_list) * 100))\n",
        "\n",
        "  # Flattening test predictions.\n",
        "  model_test_pred = np.argmax(best_test_pred[model], axis = 2).flatten()\n",
        "\n",
        "  # Printing test missclassification percentage.\n",
        "  print(\"{}, miss-classification percentage on the test set: {}%.\".format(model,\n",
        "                                                                          get_missclassification_percentage(test_tags.flatten(),\n",
        "                                                                                                            model_test_pred,\n",
        "                                                                                                            tag_to_index,\n",
        "                                                                                                            punctuation_tag_list) * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnfyPX5NN1Z1",
        "outputId": "6df3554f-bcbc-46b4-a620-68d81a979c5d"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "m_0, miss-classification percentage on the validation set: 10.711820064677882%.\n",
            "m_0, miss-classification percentage on the test set: 9.750583430571762%.\n",
            "m_2, miss-classification percentage on the validation set: 10.690018531303368%.\n",
            "m_2, miss-classification percentage on the test set: 9.422403733955658%.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: count how many classes (except punctuation classes) have zero support in both validation and test set."
      ],
      "metadata": {
        "id": "--zAEdCQ1K2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: confusion matrices, recall, precision."
      ],
      "metadata": {
        "id": "YiEit8vQcTpr"
      },
      "execution_count": 41,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "t4YdLEyuxPuH",
        "jPtlS40Jx9gR",
        "JVqtTIGn9qUo",
        "GIOxs5nNC3yG"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}