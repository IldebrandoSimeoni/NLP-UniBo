{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "    <h1> Natural Language Processing</h1>\n",
        "    <h2> Style Change Detection </h2>\n",
        "    <a href=\"mailto:ildebrando.simeoni@studio.unibo.it\">Ildebrando Simeoni</a>, <a href=\"mailto:diego.biagini2@studio.unibo.it\">Diego Biagini</a>, <a href=\"mailto:matteo.donati10@studio.unibo.it\">Matteo Donati</a>\n",
        "</center>\n",
        "\n",
        "<br>"
      ],
      "metadata": {
        "id": "9IJs9RzkNb34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{array}{clccc}\n",
        "\\hline\n",
        "\\textbf{Model} & \\textbf{Layers} & \\boldsymbol{F_1} \\textbf{ subtask 1} & \\boldsymbol{F_1} \\textbf{ subtask 2} & \\boldsymbol{F_1} \\textbf{ subtask 3} \\\\\n",
        "\\hline\n",
        "m_1^1 & \\text{BERT, global max-pooling, classification head} & 0.72 & \\dots & \\dots \\\\\n",
        "m_2^1 & \\text{BERT, global avg-pooling, classification head} & 0.71 & \\dots & \\dots \\\\\n",
        "m_3^1 & \\text{BERT, global max-pooling, dense layer, classification head} & 0.71 & \\dots & \\dots \\\\\n",
        "m_4^1 & \\text{BERT, (conv1D layer, max-pooling) $\\times$ 3, flatten, classification head} & 0.68 & \\dots & \\dots \\\\\n",
        "\\hline\n",
        "\\end{array}"
      ],
      "metadata": {
        "id": "vdtRHLFzgZ2Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "TacL2tusBXSN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZByUAoB2orL",
        "outputId": "b74957de-e797-4d6b-d7da-86375ec0a004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 14.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 50.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 74.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EyXoZqvy2yfi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "from pandas import json_normalize\n",
        "import re\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/content/drive\")\n",
        "!unzip /content/drive/MyDrive/pan22.zip\n",
        "#!unzip /content/drive/MyDrive/Magistrale/Second_year/NLP/Progetto/pan22.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E04i7_aLLc7q",
        "outputId": "605b4945-00b1-46e1-c982-a075fba9ffa6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mOutput streaming troncato alle ultime 5000 righe.\u001b[0m\n",
            "  inflating: dataset3/train/truth-problem-5500.json  \n",
            "  inflating: dataset3/train/truth-problem-5501.json  \n",
            "  inflating: dataset3/train/truth-problem-5502.json  \n",
            "  inflating: dataset3/train/truth-problem-5503.json  \n",
            "  inflating: dataset3/train/truth-problem-5504.json  \n",
            "  inflating: dataset3/train/truth-problem-5505.json  \n",
            "  inflating: dataset3/train/truth-problem-5506.json  \n",
            "  inflating: dataset3/train/truth-problem-5507.json  \n",
            "  inflating: dataset3/train/truth-problem-5508.json  \n",
            "  inflating: dataset3/train/truth-problem-5509.json  \n",
            "  inflating: dataset3/train/truth-problem-551.json  \n",
            "  inflating: dataset3/train/truth-problem-5510.json  \n",
            "  inflating: dataset3/train/truth-problem-5511.json  \n",
            "  inflating: dataset3/train/truth-problem-5512.json  \n",
            "  inflating: dataset3/train/truth-problem-5513.json  \n",
            "  inflating: dataset3/train/truth-problem-5514.json  \n",
            "  inflating: dataset3/train/truth-problem-5515.json  \n",
            "  inflating: dataset3/train/truth-problem-5516.json  \n",
            "  inflating: dataset3/train/truth-problem-5517.json  \n",
            "  inflating: dataset3/train/truth-problem-5518.json  \n",
            "  inflating: dataset3/train/truth-problem-5519.json  \n",
            "  inflating: dataset3/train/truth-problem-552.json  \n",
            "  inflating: dataset3/train/truth-problem-5520.json  \n",
            "  inflating: dataset3/train/truth-problem-5521.json  \n",
            "  inflating: dataset3/train/truth-problem-5522.json  \n",
            "  inflating: dataset3/train/truth-problem-5523.json  \n",
            "  inflating: dataset3/train/truth-problem-5524.json  \n",
            "  inflating: dataset3/train/truth-problem-5525.json  \n",
            "  inflating: dataset3/train/truth-problem-5526.json  \n",
            "  inflating: dataset3/train/truth-problem-5527.json  \n",
            "  inflating: dataset3/train/truth-problem-5528.json  \n",
            "  inflating: dataset3/train/truth-problem-5529.json  \n",
            "  inflating: dataset3/train/truth-problem-553.json  \n",
            "  inflating: dataset3/train/truth-problem-5530.json  \n",
            "  inflating: dataset3/train/truth-problem-5531.json  \n",
            "  inflating: dataset3/train/truth-problem-5532.json  \n",
            "  inflating: dataset3/train/truth-problem-5533.json  \n",
            "  inflating: dataset3/train/truth-problem-5534.json  \n",
            "  inflating: dataset3/train/truth-problem-5535.json  \n",
            "  inflating: dataset3/train/truth-problem-5536.json  \n",
            "  inflating: dataset3/train/truth-problem-5537.json  \n",
            "  inflating: dataset3/train/truth-problem-5538.json  \n",
            "  inflating: dataset3/train/truth-problem-5539.json  \n",
            "  inflating: dataset3/train/truth-problem-554.json  \n",
            "  inflating: dataset3/train/truth-problem-5540.json  \n",
            "  inflating: dataset3/train/truth-problem-5541.json  \n",
            "  inflating: dataset3/train/truth-problem-5542.json  \n",
            "  inflating: dataset3/train/truth-problem-5543.json  \n",
            "  inflating: dataset3/train/truth-problem-5544.json  \n",
            "  inflating: dataset3/train/truth-problem-5545.json  \n",
            "  inflating: dataset3/train/truth-problem-5546.json  \n",
            "  inflating: dataset3/train/truth-problem-5547.json  \n",
            "  inflating: dataset3/train/truth-problem-5548.json  \n",
            "  inflating: dataset3/train/truth-problem-5549.json  \n",
            "  inflating: dataset3/train/truth-problem-555.json  \n",
            "  inflating: dataset3/train/truth-problem-5550.json  \n",
            "  inflating: dataset3/train/truth-problem-5551.json  \n",
            "  inflating: dataset3/train/truth-problem-5552.json  \n",
            "  inflating: dataset3/train/truth-problem-5553.json  \n",
            "  inflating: dataset3/train/truth-problem-5554.json  \n",
            "  inflating: dataset3/train/truth-problem-5555.json  \n",
            "  inflating: dataset3/train/truth-problem-5556.json  \n",
            "  inflating: dataset3/train/truth-problem-5557.json  \n",
            "  inflating: dataset3/train/truth-problem-5558.json  \n",
            "  inflating: dataset3/train/truth-problem-5559.json  \n",
            "  inflating: dataset3/train/truth-problem-556.json  \n",
            "  inflating: dataset3/train/truth-problem-5560.json  \n",
            "  inflating: dataset3/train/truth-problem-5561.json  \n",
            "  inflating: dataset3/train/truth-problem-5562.json  \n",
            "  inflating: dataset3/train/truth-problem-5563.json  \n",
            "  inflating: dataset3/train/truth-problem-5564.json  \n",
            "  inflating: dataset3/train/truth-problem-5565.json  \n",
            "  inflating: dataset3/train/truth-problem-5566.json  \n",
            "  inflating: dataset3/train/truth-problem-5567.json  \n",
            "  inflating: dataset3/train/truth-problem-5568.json  \n",
            "  inflating: dataset3/train/truth-problem-5569.json  \n",
            "  inflating: dataset3/train/truth-problem-557.json  \n",
            "  inflating: dataset3/train/truth-problem-5570.json  \n",
            "  inflating: dataset3/train/truth-problem-5571.json  \n",
            "  inflating: dataset3/train/truth-problem-5572.json  \n",
            "  inflating: dataset3/train/truth-problem-5573.json  \n",
            "  inflating: dataset3/train/truth-problem-5574.json  \n",
            "  inflating: dataset3/train/truth-problem-5575.json  \n",
            "  inflating: dataset3/train/truth-problem-5576.json  \n",
            "  inflating: dataset3/train/truth-problem-5577.json  \n",
            "  inflating: dataset3/train/truth-problem-5578.json  \n",
            "  inflating: dataset3/train/truth-problem-5579.json  \n",
            "  inflating: dataset3/train/truth-problem-558.json  \n",
            "  inflating: dataset3/train/truth-problem-5580.json  \n",
            "  inflating: dataset3/train/truth-problem-5581.json  \n",
            "  inflating: dataset3/train/truth-problem-5582.json  \n",
            "  inflating: dataset3/train/truth-problem-5583.json  \n",
            "  inflating: dataset3/train/truth-problem-5584.json  \n",
            "  inflating: dataset3/train/truth-problem-5585.json  \n",
            "  inflating: dataset3/train/truth-problem-5586.json  \n",
            "  inflating: dataset3/train/truth-problem-5587.json  \n",
            "  inflating: dataset3/train/truth-problem-5588.json  \n",
            "  inflating: dataset3/train/truth-problem-5589.json  \n",
            "  inflating: dataset3/train/truth-problem-559.json  \n",
            "  inflating: dataset3/train/truth-problem-5590.json  \n",
            "  inflating: dataset3/train/truth-problem-5591.json  \n",
            "  inflating: dataset3/train/truth-problem-5592.json  \n",
            "  inflating: dataset3/train/truth-problem-5593.json  \n",
            "  inflating: dataset3/train/truth-problem-5594.json  \n",
            "  inflating: dataset3/train/truth-problem-5595.json  \n",
            "  inflating: dataset3/train/truth-problem-5596.json  \n",
            "  inflating: dataset3/train/truth-problem-5597.json  \n",
            "  inflating: dataset3/train/truth-problem-5598.json  \n",
            "  inflating: dataset3/train/truth-problem-5599.json  \n",
            "  inflating: dataset3/train/truth-problem-56.json  \n",
            "  inflating: dataset3/train/truth-problem-560.json  \n",
            "  inflating: dataset3/train/truth-problem-5600.json  \n",
            "  inflating: dataset3/train/truth-problem-5601.json  \n",
            "  inflating: dataset3/train/truth-problem-5602.json  \n",
            "  inflating: dataset3/train/truth-problem-5603.json  \n",
            "  inflating: dataset3/train/truth-problem-5604.json  \n",
            "  inflating: dataset3/train/truth-problem-5605.json  \n",
            "  inflating: dataset3/train/truth-problem-5606.json  \n",
            "  inflating: dataset3/train/truth-problem-5607.json  \n",
            "  inflating: dataset3/train/truth-problem-5608.json  \n",
            "  inflating: dataset3/train/truth-problem-5609.json  \n",
            "  inflating: dataset3/train/truth-problem-561.json  \n",
            "  inflating: dataset3/train/truth-problem-5610.json  \n",
            "  inflating: dataset3/train/truth-problem-5611.json  \n",
            "  inflating: dataset3/train/truth-problem-5612.json  \n",
            "  inflating: dataset3/train/truth-problem-5613.json  \n",
            "  inflating: dataset3/train/truth-problem-5614.json  \n",
            "  inflating: dataset3/train/truth-problem-5615.json  \n",
            "  inflating: dataset3/train/truth-problem-5616.json  \n",
            "  inflating: dataset3/train/truth-problem-5617.json  \n",
            "  inflating: dataset3/train/truth-problem-5618.json  \n",
            "  inflating: dataset3/train/truth-problem-5619.json  \n",
            "  inflating: dataset3/train/truth-problem-562.json  \n",
            "  inflating: dataset3/train/truth-problem-5620.json  \n",
            "  inflating: dataset3/train/truth-problem-5621.json  \n",
            "  inflating: dataset3/train/truth-problem-5622.json  \n",
            "  inflating: dataset3/train/truth-problem-5623.json  \n",
            "  inflating: dataset3/train/truth-problem-5624.json  \n",
            "  inflating: dataset3/train/truth-problem-5625.json  \n",
            "  inflating: dataset3/train/truth-problem-5626.json  \n",
            "  inflating: dataset3/train/truth-problem-5627.json  \n",
            "  inflating: dataset3/train/truth-problem-5628.json  \n",
            "  inflating: dataset3/train/truth-problem-5629.json  \n",
            "  inflating: dataset3/train/truth-problem-563.json  \n",
            "  inflating: dataset3/train/truth-problem-5630.json  \n",
            "  inflating: dataset3/train/truth-problem-5631.json  \n",
            "  inflating: dataset3/train/truth-problem-5632.json  \n",
            "  inflating: dataset3/train/truth-problem-5633.json  \n",
            "  inflating: dataset3/train/truth-problem-5634.json  \n",
            "  inflating: dataset3/train/truth-problem-5635.json  \n",
            "  inflating: dataset3/train/truth-problem-5636.json  \n",
            "  inflating: dataset3/train/truth-problem-5637.json  \n",
            "  inflating: dataset3/train/truth-problem-5638.json  \n",
            "  inflating: dataset3/train/truth-problem-5639.json  \n",
            "  inflating: dataset3/train/truth-problem-564.json  \n",
            "  inflating: dataset3/train/truth-problem-5640.json  \n",
            "  inflating: dataset3/train/truth-problem-5641.json  \n",
            "  inflating: dataset3/train/truth-problem-5642.json  \n",
            "  inflating: dataset3/train/truth-problem-5643.json  \n",
            "  inflating: dataset3/train/truth-problem-5644.json  \n",
            "  inflating: dataset3/train/truth-problem-5645.json  \n",
            "  inflating: dataset3/train/truth-problem-5646.json  \n",
            "  inflating: dataset3/train/truth-problem-5647.json  \n",
            "  inflating: dataset3/train/truth-problem-5648.json  \n",
            "  inflating: dataset3/train/truth-problem-5649.json  \n",
            "  inflating: dataset3/train/truth-problem-565.json  \n",
            "  inflating: dataset3/train/truth-problem-5650.json  \n",
            "  inflating: dataset3/train/truth-problem-5651.json  \n",
            "  inflating: dataset3/train/truth-problem-5652.json  \n",
            "  inflating: dataset3/train/truth-problem-5653.json  \n",
            "  inflating: dataset3/train/truth-problem-5654.json  \n",
            "  inflating: dataset3/train/truth-problem-5655.json  \n",
            "  inflating: dataset3/train/truth-problem-5656.json  \n",
            "  inflating: dataset3/train/truth-problem-5657.json  \n",
            "  inflating: dataset3/train/truth-problem-5658.json  \n",
            "  inflating: dataset3/train/truth-problem-5659.json  \n",
            "  inflating: dataset3/train/truth-problem-566.json  \n",
            "  inflating: dataset3/train/truth-problem-5660.json  \n",
            "  inflating: dataset3/train/truth-problem-5661.json  \n",
            "  inflating: dataset3/train/truth-problem-5662.json  \n",
            "  inflating: dataset3/train/truth-problem-5663.json  \n",
            "  inflating: dataset3/train/truth-problem-5664.json  \n",
            "  inflating: dataset3/train/truth-problem-5665.json  \n",
            "  inflating: dataset3/train/truth-problem-5666.json  \n",
            "  inflating: dataset3/train/truth-problem-5667.json  \n",
            "  inflating: dataset3/train/truth-problem-5668.json  \n",
            "  inflating: dataset3/train/truth-problem-5669.json  \n",
            "  inflating: dataset3/train/truth-problem-567.json  \n",
            "  inflating: dataset3/train/truth-problem-5670.json  \n",
            "  inflating: dataset3/train/truth-problem-5671.json  \n",
            "  inflating: dataset3/train/truth-problem-5672.json  \n",
            "  inflating: dataset3/train/truth-problem-5673.json  \n",
            "  inflating: dataset3/train/truth-problem-5674.json  \n",
            "  inflating: dataset3/train/truth-problem-5675.json  \n",
            "  inflating: dataset3/train/truth-problem-5676.json  \n",
            "  inflating: dataset3/train/truth-problem-5677.json  \n",
            "  inflating: dataset3/train/truth-problem-5678.json  \n",
            "  inflating: dataset3/train/truth-problem-5679.json  \n",
            "  inflating: dataset3/train/truth-problem-568.json  \n",
            "  inflating: dataset3/train/truth-problem-5680.json  \n",
            "  inflating: dataset3/train/truth-problem-5681.json  \n",
            "  inflating: dataset3/train/truth-problem-5682.json  \n",
            "  inflating: dataset3/train/truth-problem-5683.json  \n",
            "  inflating: dataset3/train/truth-problem-5684.json  \n",
            "  inflating: dataset3/train/truth-problem-5685.json  \n",
            "  inflating: dataset3/train/truth-problem-5686.json  \n",
            "  inflating: dataset3/train/truth-problem-5687.json  \n",
            "  inflating: dataset3/train/truth-problem-5688.json  \n",
            "  inflating: dataset3/train/truth-problem-5689.json  \n",
            "  inflating: dataset3/train/truth-problem-569.json  \n",
            "  inflating: dataset3/train/truth-problem-5690.json  \n",
            "  inflating: dataset3/train/truth-problem-5691.json  \n",
            "  inflating: dataset3/train/truth-problem-5692.json  \n",
            "  inflating: dataset3/train/truth-problem-5693.json  \n",
            "  inflating: dataset3/train/truth-problem-5694.json  \n",
            "  inflating: dataset3/train/truth-problem-5695.json  \n",
            "  inflating: dataset3/train/truth-problem-5696.json  \n",
            "  inflating: dataset3/train/truth-problem-5697.json  \n",
            "  inflating: dataset3/train/truth-problem-5698.json  \n",
            "  inflating: dataset3/train/truth-problem-5699.json  \n",
            "  inflating: dataset3/train/truth-problem-57.json  \n",
            "  inflating: dataset3/train/truth-problem-570.json  \n",
            "  inflating: dataset3/train/truth-problem-5700.json  \n",
            "  inflating: dataset3/train/truth-problem-5701.json  \n",
            "  inflating: dataset3/train/truth-problem-5702.json  \n",
            "  inflating: dataset3/train/truth-problem-5703.json  \n",
            "  inflating: dataset3/train/truth-problem-5704.json  \n",
            "  inflating: dataset3/train/truth-problem-5705.json  \n",
            "  inflating: dataset3/train/truth-problem-5706.json  \n",
            "  inflating: dataset3/train/truth-problem-5707.json  \n",
            "  inflating: dataset3/train/truth-problem-5708.json  \n",
            "  inflating: dataset3/train/truth-problem-5709.json  \n",
            "  inflating: dataset3/train/truth-problem-571.json  \n",
            "  inflating: dataset3/train/truth-problem-5710.json  \n",
            "  inflating: dataset3/train/truth-problem-5711.json  \n",
            "  inflating: dataset3/train/truth-problem-5712.json  \n",
            "  inflating: dataset3/train/truth-problem-5713.json  \n",
            "  inflating: dataset3/train/truth-problem-5714.json  \n",
            "  inflating: dataset3/train/truth-problem-5715.json  \n",
            "  inflating: dataset3/train/truth-problem-5716.json  \n",
            "  inflating: dataset3/train/truth-problem-5717.json  \n",
            "  inflating: dataset3/train/truth-problem-5718.json  \n",
            "  inflating: dataset3/train/truth-problem-5719.json  \n",
            "  inflating: dataset3/train/truth-problem-572.json  \n",
            "  inflating: dataset3/train/truth-problem-5720.json  \n",
            "  inflating: dataset3/train/truth-problem-5721.json  \n",
            "  inflating: dataset3/train/truth-problem-5722.json  \n",
            "  inflating: dataset3/train/truth-problem-5723.json  \n",
            "  inflating: dataset3/train/truth-problem-5724.json  \n",
            "  inflating: dataset3/train/truth-problem-5725.json  \n",
            "  inflating: dataset3/train/truth-problem-5726.json  \n",
            "  inflating: dataset3/train/truth-problem-5727.json  \n",
            "  inflating: dataset3/train/truth-problem-5728.json  \n",
            "  inflating: dataset3/train/truth-problem-5729.json  \n",
            "  inflating: dataset3/train/truth-problem-573.json  \n",
            "  inflating: dataset3/train/truth-problem-5730.json  \n",
            "  inflating: dataset3/train/truth-problem-5731.json  \n",
            "  inflating: dataset3/train/truth-problem-5732.json  \n",
            "  inflating: dataset3/train/truth-problem-5733.json  \n",
            "  inflating: dataset3/train/truth-problem-5734.json  \n",
            "  inflating: dataset3/train/truth-problem-5735.json  \n",
            "  inflating: dataset3/train/truth-problem-5736.json  \n",
            "  inflating: dataset3/train/truth-problem-5737.json  \n",
            "  inflating: dataset3/train/truth-problem-5738.json  \n",
            "  inflating: dataset3/train/truth-problem-5739.json  \n",
            "  inflating: dataset3/train/truth-problem-574.json  \n",
            "  inflating: dataset3/train/truth-problem-5740.json  \n",
            "  inflating: dataset3/train/truth-problem-5741.json  \n",
            "  inflating: dataset3/train/truth-problem-5742.json  \n",
            "  inflating: dataset3/train/truth-problem-5743.json  \n",
            "  inflating: dataset3/train/truth-problem-5744.json  \n",
            "  inflating: dataset3/train/truth-problem-5745.json  \n",
            "  inflating: dataset3/train/truth-problem-5746.json  \n",
            "  inflating: dataset3/train/truth-problem-5747.json  \n",
            "  inflating: dataset3/train/truth-problem-5748.json  \n",
            "  inflating: dataset3/train/truth-problem-5749.json  \n",
            "  inflating: dataset3/train/truth-problem-575.json  \n",
            "  inflating: dataset3/train/truth-problem-5750.json  \n",
            "  inflating: dataset3/train/truth-problem-5751.json  \n",
            "  inflating: dataset3/train/truth-problem-5752.json  \n",
            "  inflating: dataset3/train/truth-problem-5753.json  \n",
            "  inflating: dataset3/train/truth-problem-5754.json  \n",
            "  inflating: dataset3/train/truth-problem-5755.json  \n",
            "  inflating: dataset3/train/truth-problem-5756.json  \n",
            "  inflating: dataset3/train/truth-problem-5757.json  \n",
            "  inflating: dataset3/train/truth-problem-5758.json  \n",
            "  inflating: dataset3/train/truth-problem-5759.json  \n",
            "  inflating: dataset3/train/truth-problem-576.json  \n",
            "  inflating: dataset3/train/truth-problem-5760.json  \n",
            "  inflating: dataset3/train/truth-problem-5761.json  \n",
            "  inflating: dataset3/train/truth-problem-5762.json  \n",
            "  inflating: dataset3/train/truth-problem-5763.json  \n",
            "  inflating: dataset3/train/truth-problem-5764.json  \n",
            "  inflating: dataset3/train/truth-problem-5765.json  \n",
            "  inflating: dataset3/train/truth-problem-5766.json  \n",
            "  inflating: dataset3/train/truth-problem-5767.json  \n",
            "  inflating: dataset3/train/truth-problem-5768.json  \n",
            "  inflating: dataset3/train/truth-problem-5769.json  \n",
            "  inflating: dataset3/train/truth-problem-577.json  \n",
            "  inflating: dataset3/train/truth-problem-5770.json  \n",
            "  inflating: dataset3/train/truth-problem-5771.json  \n",
            "  inflating: dataset3/train/truth-problem-5772.json  \n",
            "  inflating: dataset3/train/truth-problem-5773.json  \n",
            "  inflating: dataset3/train/truth-problem-5774.json  \n",
            "  inflating: dataset3/train/truth-problem-5775.json  \n",
            "  inflating: dataset3/train/truth-problem-5776.json  \n",
            "  inflating: dataset3/train/truth-problem-5777.json  \n",
            "  inflating: dataset3/train/truth-problem-5778.json  \n",
            "  inflating: dataset3/train/truth-problem-5779.json  \n",
            "  inflating: dataset3/train/truth-problem-578.json  \n",
            "  inflating: dataset3/train/truth-problem-5780.json  \n",
            "  inflating: dataset3/train/truth-problem-5781.json  \n",
            "  inflating: dataset3/train/truth-problem-5782.json  \n",
            "  inflating: dataset3/train/truth-problem-5783.json  \n",
            "  inflating: dataset3/train/truth-problem-5784.json  \n",
            "  inflating: dataset3/train/truth-problem-5785.json  \n",
            "  inflating: dataset3/train/truth-problem-5786.json  \n",
            "  inflating: dataset3/train/truth-problem-5787.json  \n",
            "  inflating: dataset3/train/truth-problem-5788.json  \n",
            "  inflating: dataset3/train/truth-problem-5789.json  \n",
            "  inflating: dataset3/train/truth-problem-579.json  \n",
            "  inflating: dataset3/train/truth-problem-5790.json  \n",
            "  inflating: dataset3/train/truth-problem-5791.json  \n",
            "  inflating: dataset3/train/truth-problem-5792.json  \n",
            "  inflating: dataset3/train/truth-problem-5793.json  \n",
            "  inflating: dataset3/train/truth-problem-5794.json  \n",
            "  inflating: dataset3/train/truth-problem-5795.json  \n",
            "  inflating: dataset3/train/truth-problem-5796.json  \n",
            "  inflating: dataset3/train/truth-problem-5797.json  \n",
            "  inflating: dataset3/train/truth-problem-5798.json  \n",
            "  inflating: dataset3/train/truth-problem-5799.json  \n",
            "  inflating: dataset3/train/truth-problem-58.json  \n",
            "  inflating: dataset3/train/truth-problem-580.json  \n",
            "  inflating: dataset3/train/truth-problem-5800.json  \n",
            "  inflating: dataset3/train/truth-problem-5801.json  \n",
            "  inflating: dataset3/train/truth-problem-5802.json  \n",
            "  inflating: dataset3/train/truth-problem-5803.json  \n",
            "  inflating: dataset3/train/truth-problem-5804.json  \n",
            "  inflating: dataset3/train/truth-problem-5805.json  \n",
            "  inflating: dataset3/train/truth-problem-5806.json  \n",
            "  inflating: dataset3/train/truth-problem-5807.json  \n",
            "  inflating: dataset3/train/truth-problem-5808.json  \n",
            "  inflating: dataset3/train/truth-problem-5809.json  \n",
            "  inflating: dataset3/train/truth-problem-581.json  \n",
            "  inflating: dataset3/train/truth-problem-5810.json  \n",
            "  inflating: dataset3/train/truth-problem-5811.json  \n",
            "  inflating: dataset3/train/truth-problem-5812.json  \n",
            "  inflating: dataset3/train/truth-problem-5813.json  \n",
            "  inflating: dataset3/train/truth-problem-5814.json  \n",
            "  inflating: dataset3/train/truth-problem-5815.json  \n",
            "  inflating: dataset3/train/truth-problem-5816.json  \n",
            "  inflating: dataset3/train/truth-problem-5817.json  \n",
            "  inflating: dataset3/train/truth-problem-5818.json  \n",
            "  inflating: dataset3/train/truth-problem-5819.json  \n",
            "  inflating: dataset3/train/truth-problem-582.json  \n",
            "  inflating: dataset3/train/truth-problem-5820.json  \n",
            "  inflating: dataset3/train/truth-problem-5821.json  \n",
            "  inflating: dataset3/train/truth-problem-5822.json  \n",
            "  inflating: dataset3/train/truth-problem-5823.json  \n",
            "  inflating: dataset3/train/truth-problem-5824.json  \n",
            "  inflating: dataset3/train/truth-problem-5825.json  \n",
            "  inflating: dataset3/train/truth-problem-5826.json  \n",
            "  inflating: dataset3/train/truth-problem-5827.json  \n",
            "  inflating: dataset3/train/truth-problem-5828.json  \n",
            "  inflating: dataset3/train/truth-problem-5829.json  \n",
            "  inflating: dataset3/train/truth-problem-583.json  \n",
            "  inflating: dataset3/train/truth-problem-5830.json  \n",
            "  inflating: dataset3/train/truth-problem-5831.json  \n",
            "  inflating: dataset3/train/truth-problem-5832.json  \n",
            "  inflating: dataset3/train/truth-problem-5833.json  \n",
            "  inflating: dataset3/train/truth-problem-5834.json  \n",
            "  inflating: dataset3/train/truth-problem-5835.json  \n",
            "  inflating: dataset3/train/truth-problem-5836.json  \n",
            "  inflating: dataset3/train/truth-problem-5837.json  \n",
            "  inflating: dataset3/train/truth-problem-5838.json  \n",
            "  inflating: dataset3/train/truth-problem-5839.json  \n",
            "  inflating: dataset3/train/truth-problem-584.json  \n",
            "  inflating: dataset3/train/truth-problem-5840.json  \n",
            "  inflating: dataset3/train/truth-problem-5841.json  \n",
            "  inflating: dataset3/train/truth-problem-5842.json  \n",
            "  inflating: dataset3/train/truth-problem-5843.json  \n",
            "  inflating: dataset3/train/truth-problem-5844.json  \n",
            "  inflating: dataset3/train/truth-problem-5845.json  \n",
            "  inflating: dataset3/train/truth-problem-5846.json  \n",
            "  inflating: dataset3/train/truth-problem-5847.json  \n",
            "  inflating: dataset3/train/truth-problem-5848.json  \n",
            "  inflating: dataset3/train/truth-problem-5849.json  \n",
            "  inflating: dataset3/train/truth-problem-585.json  \n",
            "  inflating: dataset3/train/truth-problem-5850.json  \n",
            "  inflating: dataset3/train/truth-problem-5851.json  \n",
            "  inflating: dataset3/train/truth-problem-5852.json  \n",
            "  inflating: dataset3/train/truth-problem-5853.json  \n",
            "  inflating: dataset3/train/truth-problem-5854.json  \n",
            "  inflating: dataset3/train/truth-problem-5855.json  \n",
            "  inflating: dataset3/train/truth-problem-5856.json  \n",
            "  inflating: dataset3/train/truth-problem-5857.json  \n",
            "  inflating: dataset3/train/truth-problem-5858.json  \n",
            "  inflating: dataset3/train/truth-problem-5859.json  \n",
            "  inflating: dataset3/train/truth-problem-586.json  \n",
            "  inflating: dataset3/train/truth-problem-5860.json  \n",
            "  inflating: dataset3/train/truth-problem-5861.json  \n",
            "  inflating: dataset3/train/truth-problem-5862.json  \n",
            "  inflating: dataset3/train/truth-problem-5863.json  \n",
            "  inflating: dataset3/train/truth-problem-5864.json  \n",
            "  inflating: dataset3/train/truth-problem-5865.json  \n",
            "  inflating: dataset3/train/truth-problem-5866.json  \n",
            "  inflating: dataset3/train/truth-problem-5867.json  \n",
            "  inflating: dataset3/train/truth-problem-5868.json  \n",
            "  inflating: dataset3/train/truth-problem-5869.json  \n",
            "  inflating: dataset3/train/truth-problem-587.json  \n",
            "  inflating: dataset3/train/truth-problem-5870.json  \n",
            "  inflating: dataset3/train/truth-problem-5871.json  \n",
            "  inflating: dataset3/train/truth-problem-5872.json  \n",
            "  inflating: dataset3/train/truth-problem-5873.json  \n",
            "  inflating: dataset3/train/truth-problem-5874.json  \n",
            "  inflating: dataset3/train/truth-problem-5875.json  \n",
            "  inflating: dataset3/train/truth-problem-5876.json  \n",
            "  inflating: dataset3/train/truth-problem-5877.json  \n",
            "  inflating: dataset3/train/truth-problem-5878.json  \n",
            "  inflating: dataset3/train/truth-problem-5879.json  \n",
            "  inflating: dataset3/train/truth-problem-588.json  \n",
            "  inflating: dataset3/train/truth-problem-5880.json  \n",
            "  inflating: dataset3/train/truth-problem-5881.json  \n",
            "  inflating: dataset3/train/truth-problem-5882.json  \n",
            "  inflating: dataset3/train/truth-problem-5883.json  \n",
            "  inflating: dataset3/train/truth-problem-5884.json  \n",
            "  inflating: dataset3/train/truth-problem-5885.json  \n",
            "  inflating: dataset3/train/truth-problem-5886.json  \n",
            "  inflating: dataset3/train/truth-problem-5887.json  \n",
            "  inflating: dataset3/train/truth-problem-5888.json  \n",
            "  inflating: dataset3/train/truth-problem-5889.json  \n",
            "  inflating: dataset3/train/truth-problem-589.json  \n",
            "  inflating: dataset3/train/truth-problem-5890.json  \n",
            "  inflating: dataset3/train/truth-problem-5891.json  \n",
            "  inflating: dataset3/train/truth-problem-5892.json  \n",
            "  inflating: dataset3/train/truth-problem-5893.json  \n",
            "  inflating: dataset3/train/truth-problem-5894.json  \n",
            "  inflating: dataset3/train/truth-problem-5895.json  \n",
            "  inflating: dataset3/train/truth-problem-5896.json  \n",
            "  inflating: dataset3/train/truth-problem-5897.json  \n",
            "  inflating: dataset3/train/truth-problem-5898.json  \n",
            "  inflating: dataset3/train/truth-problem-5899.json  \n",
            "  inflating: dataset3/train/truth-problem-59.json  \n",
            "  inflating: dataset3/train/truth-problem-590.json  \n",
            "  inflating: dataset3/train/truth-problem-5900.json  \n",
            "  inflating: dataset3/train/truth-problem-5901.json  \n",
            "  inflating: dataset3/train/truth-problem-5902.json  \n",
            "  inflating: dataset3/train/truth-problem-5903.json  \n",
            "  inflating: dataset3/train/truth-problem-5904.json  \n",
            "  inflating: dataset3/train/truth-problem-5905.json  \n",
            "  inflating: dataset3/train/truth-problem-5906.json  \n",
            "  inflating: dataset3/train/truth-problem-5907.json  \n",
            "  inflating: dataset3/train/truth-problem-5908.json  \n",
            "  inflating: dataset3/train/truth-problem-5909.json  \n",
            "  inflating: dataset3/train/truth-problem-591.json  \n",
            "  inflating: dataset3/train/truth-problem-5910.json  \n",
            "  inflating: dataset3/train/truth-problem-5911.json  \n",
            "  inflating: dataset3/train/truth-problem-5912.json  \n",
            "  inflating: dataset3/train/truth-problem-5913.json  \n",
            "  inflating: dataset3/train/truth-problem-5914.json  \n",
            "  inflating: dataset3/train/truth-problem-5915.json  \n",
            "  inflating: dataset3/train/truth-problem-5916.json  \n",
            "  inflating: dataset3/train/truth-problem-5917.json  \n",
            "  inflating: dataset3/train/truth-problem-5918.json  \n",
            "  inflating: dataset3/train/truth-problem-5919.json  \n",
            "  inflating: dataset3/train/truth-problem-592.json  \n",
            "  inflating: dataset3/train/truth-problem-5920.json  \n",
            "  inflating: dataset3/train/truth-problem-5921.json  \n",
            "  inflating: dataset3/train/truth-problem-5922.json  \n",
            "  inflating: dataset3/train/truth-problem-5923.json  \n",
            "  inflating: dataset3/train/truth-problem-5924.json  \n",
            "  inflating: dataset3/train/truth-problem-5925.json  \n",
            "  inflating: dataset3/train/truth-problem-5926.json  \n",
            "  inflating: dataset3/train/truth-problem-5927.json  \n",
            "  inflating: dataset3/train/truth-problem-5928.json  \n",
            "  inflating: dataset3/train/truth-problem-5929.json  \n",
            "  inflating: dataset3/train/truth-problem-593.json  \n",
            "  inflating: dataset3/train/truth-problem-5930.json  \n",
            "  inflating: dataset3/train/truth-problem-5931.json  \n",
            "  inflating: dataset3/train/truth-problem-5932.json  \n",
            "  inflating: dataset3/train/truth-problem-5933.json  \n",
            "  inflating: dataset3/train/truth-problem-5934.json  \n",
            "  inflating: dataset3/train/truth-problem-5935.json  \n",
            "  inflating: dataset3/train/truth-problem-5936.json  \n",
            "  inflating: dataset3/train/truth-problem-5937.json  \n",
            "  inflating: dataset3/train/truth-problem-5938.json  \n",
            "  inflating: dataset3/train/truth-problem-5939.json  \n",
            "  inflating: dataset3/train/truth-problem-594.json  \n",
            "  inflating: dataset3/train/truth-problem-5940.json  \n",
            "  inflating: dataset3/train/truth-problem-5941.json  \n",
            "  inflating: dataset3/train/truth-problem-5942.json  \n",
            "  inflating: dataset3/train/truth-problem-5943.json  \n",
            "  inflating: dataset3/train/truth-problem-5944.json  \n",
            "  inflating: dataset3/train/truth-problem-5945.json  \n",
            "  inflating: dataset3/train/truth-problem-5946.json  \n",
            "  inflating: dataset3/train/truth-problem-5947.json  \n",
            "  inflating: dataset3/train/truth-problem-5948.json  \n",
            "  inflating: dataset3/train/truth-problem-5949.json  \n",
            "  inflating: dataset3/train/truth-problem-595.json  \n",
            "  inflating: dataset3/train/truth-problem-5950.json  \n",
            "  inflating: dataset3/train/truth-problem-5951.json  \n",
            "  inflating: dataset3/train/truth-problem-5952.json  \n",
            "  inflating: dataset3/train/truth-problem-5953.json  \n",
            "  inflating: dataset3/train/truth-problem-5954.json  \n",
            "  inflating: dataset3/train/truth-problem-5955.json  \n",
            "  inflating: dataset3/train/truth-problem-5956.json  \n",
            "  inflating: dataset3/train/truth-problem-5957.json  \n",
            "  inflating: dataset3/train/truth-problem-5958.json  \n",
            "  inflating: dataset3/train/truth-problem-5959.json  \n",
            "  inflating: dataset3/train/truth-problem-596.json  \n",
            "  inflating: dataset3/train/truth-problem-5960.json  \n",
            "  inflating: dataset3/train/truth-problem-5961.json  \n",
            "  inflating: dataset3/train/truth-problem-5962.json  \n",
            "  inflating: dataset3/train/truth-problem-5963.json  \n",
            "  inflating: dataset3/train/truth-problem-5964.json  \n",
            "  inflating: dataset3/train/truth-problem-5965.json  \n",
            "  inflating: dataset3/train/truth-problem-5966.json  \n",
            "  inflating: dataset3/train/truth-problem-5967.json  \n",
            "  inflating: dataset3/train/truth-problem-5968.json  \n",
            "  inflating: dataset3/train/truth-problem-5969.json  \n",
            "  inflating: dataset3/train/truth-problem-597.json  \n",
            "  inflating: dataset3/train/truth-problem-5970.json  \n",
            "  inflating: dataset3/train/truth-problem-5971.json  \n",
            "  inflating: dataset3/train/truth-problem-5972.json  \n",
            "  inflating: dataset3/train/truth-problem-5973.json  \n",
            "  inflating: dataset3/train/truth-problem-5974.json  \n",
            "  inflating: dataset3/train/truth-problem-5975.json  \n",
            "  inflating: dataset3/train/truth-problem-5976.json  \n",
            "  inflating: dataset3/train/truth-problem-5977.json  \n",
            "  inflating: dataset3/train/truth-problem-5978.json  \n",
            "  inflating: dataset3/train/truth-problem-5979.json  \n",
            "  inflating: dataset3/train/truth-problem-598.json  \n",
            "  inflating: dataset3/train/truth-problem-5980.json  \n",
            "  inflating: dataset3/train/truth-problem-5981.json  \n",
            "  inflating: dataset3/train/truth-problem-5982.json  \n",
            "  inflating: dataset3/train/truth-problem-5983.json  \n",
            "  inflating: dataset3/train/truth-problem-5984.json  \n",
            "  inflating: dataset3/train/truth-problem-5985.json  \n",
            "  inflating: dataset3/train/truth-problem-5986.json  \n",
            "  inflating: dataset3/train/truth-problem-5987.json  \n",
            "  inflating: dataset3/train/truth-problem-5988.json  \n",
            "  inflating: dataset3/train/truth-problem-5989.json  \n",
            "  inflating: dataset3/train/truth-problem-599.json  \n",
            "  inflating: dataset3/train/truth-problem-5990.json  \n",
            "  inflating: dataset3/train/truth-problem-5991.json  \n",
            "  inflating: dataset3/train/truth-problem-5992.json  \n",
            "  inflating: dataset3/train/truth-problem-5993.json  \n",
            "  inflating: dataset3/train/truth-problem-5994.json  \n",
            "  inflating: dataset3/train/truth-problem-5995.json  \n",
            "  inflating: dataset3/train/truth-problem-5996.json  \n",
            "  inflating: dataset3/train/truth-problem-5997.json  \n",
            "  inflating: dataset3/train/truth-problem-5998.json  \n",
            "  inflating: dataset3/train/truth-problem-5999.json  \n",
            "  inflating: dataset3/train/truth-problem-6.json  \n",
            "  inflating: dataset3/train/truth-problem-60.json  \n",
            "  inflating: dataset3/train/truth-problem-600.json  \n",
            "  inflating: dataset3/train/truth-problem-6000.json  \n",
            "  inflating: dataset3/train/truth-problem-6001.json  \n",
            "  inflating: dataset3/train/truth-problem-6002.json  \n",
            "  inflating: dataset3/train/truth-problem-6003.json  \n",
            "  inflating: dataset3/train/truth-problem-6004.json  \n",
            "  inflating: dataset3/train/truth-problem-6005.json  \n",
            "  inflating: dataset3/train/truth-problem-6006.json  \n",
            "  inflating: dataset3/train/truth-problem-6007.json  \n",
            "  inflating: dataset3/train/truth-problem-6008.json  \n",
            "  inflating: dataset3/train/truth-problem-6009.json  \n",
            "  inflating: dataset3/train/truth-problem-601.json  \n",
            "  inflating: dataset3/train/truth-problem-6010.json  \n",
            "  inflating: dataset3/train/truth-problem-6011.json  \n",
            "  inflating: dataset3/train/truth-problem-6012.json  \n",
            "  inflating: dataset3/train/truth-problem-6013.json  \n",
            "  inflating: dataset3/train/truth-problem-6014.json  \n",
            "  inflating: dataset3/train/truth-problem-6015.json  \n",
            "  inflating: dataset3/train/truth-problem-6016.json  \n",
            "  inflating: dataset3/train/truth-problem-6017.json  \n",
            "  inflating: dataset3/train/truth-problem-6018.json  \n",
            "  inflating: dataset3/train/truth-problem-6019.json  \n",
            "  inflating: dataset3/train/truth-problem-602.json  \n",
            "  inflating: dataset3/train/truth-problem-6020.json  \n",
            "  inflating: dataset3/train/truth-problem-6021.json  \n",
            "  inflating: dataset3/train/truth-problem-6022.json  \n",
            "  inflating: dataset3/train/truth-problem-6023.json  \n",
            "  inflating: dataset3/train/truth-problem-6024.json  \n",
            "  inflating: dataset3/train/truth-problem-6025.json  \n",
            "  inflating: dataset3/train/truth-problem-6026.json  \n",
            "  inflating: dataset3/train/truth-problem-6027.json  \n",
            "  inflating: dataset3/train/truth-problem-6028.json  \n",
            "  inflating: dataset3/train/truth-problem-6029.json  \n",
            "  inflating: dataset3/train/truth-problem-603.json  \n",
            "  inflating: dataset3/train/truth-problem-6030.json  \n",
            "  inflating: dataset3/train/truth-problem-6031.json  \n",
            "  inflating: dataset3/train/truth-problem-6032.json  \n",
            "  inflating: dataset3/train/truth-problem-6033.json  \n",
            "  inflating: dataset3/train/truth-problem-6034.json  \n",
            "  inflating: dataset3/train/truth-problem-6035.json  \n",
            "  inflating: dataset3/train/truth-problem-6036.json  \n",
            "  inflating: dataset3/train/truth-problem-6037.json  \n",
            "  inflating: dataset3/train/truth-problem-6038.json  \n",
            "  inflating: dataset3/train/truth-problem-6039.json  \n",
            "  inflating: dataset3/train/truth-problem-604.json  \n",
            "  inflating: dataset3/train/truth-problem-6040.json  \n",
            "  inflating: dataset3/train/truth-problem-6041.json  \n",
            "  inflating: dataset3/train/truth-problem-6042.json  \n",
            "  inflating: dataset3/train/truth-problem-6043.json  \n",
            "  inflating: dataset3/train/truth-problem-6044.json  \n",
            "  inflating: dataset3/train/truth-problem-6045.json  \n",
            "  inflating: dataset3/train/truth-problem-6046.json  \n",
            "  inflating: dataset3/train/truth-problem-6047.json  \n",
            "  inflating: dataset3/train/truth-problem-6048.json  \n",
            "  inflating: dataset3/train/truth-problem-6049.json  \n",
            "  inflating: dataset3/train/truth-problem-605.json  \n",
            "  inflating: dataset3/train/truth-problem-6050.json  \n",
            "  inflating: dataset3/train/truth-problem-6051.json  \n",
            "  inflating: dataset3/train/truth-problem-6052.json  \n",
            "  inflating: dataset3/train/truth-problem-6053.json  \n",
            "  inflating: dataset3/train/truth-problem-6054.json  \n",
            "  inflating: dataset3/train/truth-problem-6055.json  \n",
            "  inflating: dataset3/train/truth-problem-6056.json  \n",
            "  inflating: dataset3/train/truth-problem-6057.json  \n",
            "  inflating: dataset3/train/truth-problem-6058.json  \n",
            "  inflating: dataset3/train/truth-problem-6059.json  \n",
            "  inflating: dataset3/train/truth-problem-606.json  \n",
            "  inflating: dataset3/train/truth-problem-6060.json  \n",
            "  inflating: dataset3/train/truth-problem-6061.json  \n",
            "  inflating: dataset3/train/truth-problem-6062.json  \n",
            "  inflating: dataset3/train/truth-problem-6063.json  \n",
            "  inflating: dataset3/train/truth-problem-6064.json  \n",
            "  inflating: dataset3/train/truth-problem-6065.json  \n",
            "  inflating: dataset3/train/truth-problem-6066.json  \n",
            "  inflating: dataset3/train/truth-problem-6067.json  \n",
            "  inflating: dataset3/train/truth-problem-6068.json  \n",
            "  inflating: dataset3/train/truth-problem-6069.json  \n",
            "  inflating: dataset3/train/truth-problem-607.json  \n",
            "  inflating: dataset3/train/truth-problem-6070.json  \n",
            "  inflating: dataset3/train/truth-problem-6071.json  \n",
            "  inflating: dataset3/train/truth-problem-6072.json  \n",
            "  inflating: dataset3/train/truth-problem-6073.json  \n",
            "  inflating: dataset3/train/truth-problem-6074.json  \n",
            "  inflating: dataset3/train/truth-problem-6075.json  \n",
            "  inflating: dataset3/train/truth-problem-6076.json  \n",
            "  inflating: dataset3/train/truth-problem-6077.json  \n",
            "  inflating: dataset3/train/truth-problem-6078.json  \n",
            "  inflating: dataset3/train/truth-problem-6079.json  \n",
            "  inflating: dataset3/train/truth-problem-608.json  \n",
            "  inflating: dataset3/train/truth-problem-6080.json  \n",
            "  inflating: dataset3/train/truth-problem-6081.json  \n",
            "  inflating: dataset3/train/truth-problem-6082.json  \n",
            "  inflating: dataset3/train/truth-problem-6083.json  \n",
            "  inflating: dataset3/train/truth-problem-6084.json  \n",
            "  inflating: dataset3/train/truth-problem-6085.json  \n",
            "  inflating: dataset3/train/truth-problem-6086.json  \n",
            "  inflating: dataset3/train/truth-problem-6087.json  \n",
            "  inflating: dataset3/train/truth-problem-6088.json  \n",
            "  inflating: dataset3/train/truth-problem-6089.json  \n",
            "  inflating: dataset3/train/truth-problem-609.json  \n",
            "  inflating: dataset3/train/truth-problem-6090.json  \n",
            "  inflating: dataset3/train/truth-problem-6091.json  \n",
            "  inflating: dataset3/train/truth-problem-6092.json  \n",
            "  inflating: dataset3/train/truth-problem-6093.json  \n",
            "  inflating: dataset3/train/truth-problem-6094.json  \n",
            "  inflating: dataset3/train/truth-problem-6095.json  \n",
            "  inflating: dataset3/train/truth-problem-6096.json  \n",
            "  inflating: dataset3/train/truth-problem-6097.json  \n",
            "  inflating: dataset3/train/truth-problem-6098.json  \n",
            "  inflating: dataset3/train/truth-problem-6099.json  \n",
            "  inflating: dataset3/train/truth-problem-61.json  \n",
            "  inflating: dataset3/train/truth-problem-610.json  \n",
            "  inflating: dataset3/train/truth-problem-6100.json  \n",
            "  inflating: dataset3/train/truth-problem-6101.json  \n",
            "  inflating: dataset3/train/truth-problem-6102.json  \n",
            "  inflating: dataset3/train/truth-problem-6103.json  \n",
            "  inflating: dataset3/train/truth-problem-6104.json  \n",
            "  inflating: dataset3/train/truth-problem-6105.json  \n",
            "  inflating: dataset3/train/truth-problem-6106.json  \n",
            "  inflating: dataset3/train/truth-problem-6107.json  \n",
            "  inflating: dataset3/train/truth-problem-6108.json  \n",
            "  inflating: dataset3/train/truth-problem-6109.json  \n",
            "  inflating: dataset3/train/truth-problem-611.json  \n",
            "  inflating: dataset3/train/truth-problem-6110.json  \n",
            "  inflating: dataset3/train/truth-problem-6111.json  \n",
            "  inflating: dataset3/train/truth-problem-6112.json  \n",
            "  inflating: dataset3/train/truth-problem-6113.json  \n",
            "  inflating: dataset3/train/truth-problem-6114.json  \n",
            "  inflating: dataset3/train/truth-problem-6115.json  \n",
            "  inflating: dataset3/train/truth-problem-6116.json  \n",
            "  inflating: dataset3/train/truth-problem-6117.json  \n",
            "  inflating: dataset3/train/truth-problem-6118.json  \n",
            "  inflating: dataset3/train/truth-problem-6119.json  \n",
            "  inflating: dataset3/train/truth-problem-612.json  \n",
            "  inflating: dataset3/train/truth-problem-6120.json  \n",
            "  inflating: dataset3/train/truth-problem-6121.json  \n",
            "  inflating: dataset3/train/truth-problem-6122.json  \n",
            "  inflating: dataset3/train/truth-problem-6123.json  \n",
            "  inflating: dataset3/train/truth-problem-6124.json  \n",
            "  inflating: dataset3/train/truth-problem-6125.json  \n",
            "  inflating: dataset3/train/truth-problem-6126.json  \n",
            "  inflating: dataset3/train/truth-problem-6127.json  \n",
            "  inflating: dataset3/train/truth-problem-6128.json  \n",
            "  inflating: dataset3/train/truth-problem-6129.json  \n",
            "  inflating: dataset3/train/truth-problem-613.json  \n",
            "  inflating: dataset3/train/truth-problem-6130.json  \n",
            "  inflating: dataset3/train/truth-problem-6131.json  \n",
            "  inflating: dataset3/train/truth-problem-6132.json  \n",
            "  inflating: dataset3/train/truth-problem-6133.json  \n",
            "  inflating: dataset3/train/truth-problem-6134.json  \n",
            "  inflating: dataset3/train/truth-problem-6135.json  \n",
            "  inflating: dataset3/train/truth-problem-6136.json  \n",
            "  inflating: dataset3/train/truth-problem-6137.json  \n",
            "  inflating: dataset3/train/truth-problem-6138.json  \n",
            "  inflating: dataset3/train/truth-problem-6139.json  \n",
            "  inflating: dataset3/train/truth-problem-614.json  \n",
            "  inflating: dataset3/train/truth-problem-6140.json  \n",
            "  inflating: dataset3/train/truth-problem-6141.json  \n",
            "  inflating: dataset3/train/truth-problem-6142.json  \n",
            "  inflating: dataset3/train/truth-problem-6143.json  \n",
            "  inflating: dataset3/train/truth-problem-6144.json  \n",
            "  inflating: dataset3/train/truth-problem-6145.json  \n",
            "  inflating: dataset3/train/truth-problem-6146.json  \n",
            "  inflating: dataset3/train/truth-problem-6147.json  \n",
            "  inflating: dataset3/train/truth-problem-6148.json  \n",
            "  inflating: dataset3/train/truth-problem-6149.json  \n",
            "  inflating: dataset3/train/truth-problem-615.json  \n",
            "  inflating: dataset3/train/truth-problem-6150.json  \n",
            "  inflating: dataset3/train/truth-problem-6151.json  \n",
            "  inflating: dataset3/train/truth-problem-6152.json  \n",
            "  inflating: dataset3/train/truth-problem-6153.json  \n",
            "  inflating: dataset3/train/truth-problem-6154.json  \n",
            "  inflating: dataset3/train/truth-problem-6155.json  \n",
            "  inflating: dataset3/train/truth-problem-6156.json  \n",
            "  inflating: dataset3/train/truth-problem-6157.json  \n",
            "  inflating: dataset3/train/truth-problem-6158.json  \n",
            "  inflating: dataset3/train/truth-problem-6159.json  \n",
            "  inflating: dataset3/train/truth-problem-616.json  \n",
            "  inflating: dataset3/train/truth-problem-6160.json  \n",
            "  inflating: dataset3/train/truth-problem-6161.json  \n",
            "  inflating: dataset3/train/truth-problem-6162.json  \n",
            "  inflating: dataset3/train/truth-problem-6163.json  \n",
            "  inflating: dataset3/train/truth-problem-6164.json  \n",
            "  inflating: dataset3/train/truth-problem-6165.json  \n",
            "  inflating: dataset3/train/truth-problem-6166.json  \n",
            "  inflating: dataset3/train/truth-problem-6167.json  \n",
            "  inflating: dataset3/train/truth-problem-6168.json  \n",
            "  inflating: dataset3/train/truth-problem-6169.json  \n",
            "  inflating: dataset3/train/truth-problem-617.json  \n",
            "  inflating: dataset3/train/truth-problem-6170.json  \n",
            "  inflating: dataset3/train/truth-problem-6171.json  \n",
            "  inflating: dataset3/train/truth-problem-6172.json  \n",
            "  inflating: dataset3/train/truth-problem-6173.json  \n",
            "  inflating: dataset3/train/truth-problem-6174.json  \n",
            "  inflating: dataset3/train/truth-problem-6175.json  \n",
            "  inflating: dataset3/train/truth-problem-6176.json  \n",
            "  inflating: dataset3/train/truth-problem-6177.json  \n",
            "  inflating: dataset3/train/truth-problem-6178.json  \n",
            "  inflating: dataset3/train/truth-problem-6179.json  \n",
            "  inflating: dataset3/train/truth-problem-618.json  \n",
            "  inflating: dataset3/train/truth-problem-6180.json  \n",
            "  inflating: dataset3/train/truth-problem-6181.json  \n",
            "  inflating: dataset3/train/truth-problem-6182.json  \n",
            "  inflating: dataset3/train/truth-problem-6183.json  \n",
            "  inflating: dataset3/train/truth-problem-6184.json  \n",
            "  inflating: dataset3/train/truth-problem-6185.json  \n",
            "  inflating: dataset3/train/truth-problem-6186.json  \n",
            "  inflating: dataset3/train/truth-problem-6187.json  \n",
            "  inflating: dataset3/train/truth-problem-6188.json  \n",
            "  inflating: dataset3/train/truth-problem-6189.json  \n",
            "  inflating: dataset3/train/truth-problem-619.json  \n",
            "  inflating: dataset3/train/truth-problem-6190.json  \n",
            "  inflating: dataset3/train/truth-problem-6191.json  \n",
            "  inflating: dataset3/train/truth-problem-6192.json  \n",
            "  inflating: dataset3/train/truth-problem-6193.json  \n",
            "  inflating: dataset3/train/truth-problem-6194.json  \n",
            "  inflating: dataset3/train/truth-problem-6195.json  \n",
            "  inflating: dataset3/train/truth-problem-6196.json  \n",
            "  inflating: dataset3/train/truth-problem-6197.json  \n",
            "  inflating: dataset3/train/truth-problem-6198.json  \n",
            "  inflating: dataset3/train/truth-problem-6199.json  \n",
            "  inflating: dataset3/train/truth-problem-62.json  \n",
            "  inflating: dataset3/train/truth-problem-620.json  \n",
            "  inflating: dataset3/train/truth-problem-6200.json  \n",
            "  inflating: dataset3/train/truth-problem-6201.json  \n",
            "  inflating: dataset3/train/truth-problem-6202.json  \n",
            "  inflating: dataset3/train/truth-problem-6203.json  \n",
            "  inflating: dataset3/train/truth-problem-6204.json  \n",
            "  inflating: dataset3/train/truth-problem-6205.json  \n",
            "  inflating: dataset3/train/truth-problem-6206.json  \n",
            "  inflating: dataset3/train/truth-problem-6207.json  \n",
            "  inflating: dataset3/train/truth-problem-6208.json  \n",
            "  inflating: dataset3/train/truth-problem-6209.json  \n",
            "  inflating: dataset3/train/truth-problem-621.json  \n",
            "  inflating: dataset3/train/truth-problem-6210.json  \n",
            "  inflating: dataset3/train/truth-problem-6211.json  \n",
            "  inflating: dataset3/train/truth-problem-6212.json  \n",
            "  inflating: dataset3/train/truth-problem-6213.json  \n",
            "  inflating: dataset3/train/truth-problem-6214.json  \n",
            "  inflating: dataset3/train/truth-problem-6215.json  \n",
            "  inflating: dataset3/train/truth-problem-6216.json  \n",
            "  inflating: dataset3/train/truth-problem-6217.json  \n",
            "  inflating: dataset3/train/truth-problem-6218.json  \n",
            "  inflating: dataset3/train/truth-problem-6219.json  \n",
            "  inflating: dataset3/train/truth-problem-622.json  \n",
            "  inflating: dataset3/train/truth-problem-6220.json  \n",
            "  inflating: dataset3/train/truth-problem-6221.json  \n",
            "  inflating: dataset3/train/truth-problem-6222.json  \n",
            "  inflating: dataset3/train/truth-problem-6223.json  \n",
            "  inflating: dataset3/train/truth-problem-6224.json  \n",
            "  inflating: dataset3/train/truth-problem-6225.json  \n",
            "  inflating: dataset3/train/truth-problem-6226.json  \n",
            "  inflating: dataset3/train/truth-problem-6227.json  \n",
            "  inflating: dataset3/train/truth-problem-6228.json  \n",
            "  inflating: dataset3/train/truth-problem-6229.json  \n",
            "  inflating: dataset3/train/truth-problem-623.json  \n",
            "  inflating: dataset3/train/truth-problem-6230.json  \n",
            "  inflating: dataset3/train/truth-problem-6231.json  \n",
            "  inflating: dataset3/train/truth-problem-6232.json  \n",
            "  inflating: dataset3/train/truth-problem-6233.json  \n",
            "  inflating: dataset3/train/truth-problem-6234.json  \n",
            "  inflating: dataset3/train/truth-problem-6235.json  \n",
            "  inflating: dataset3/train/truth-problem-6236.json  \n",
            "  inflating: dataset3/train/truth-problem-6237.json  \n",
            "  inflating: dataset3/train/truth-problem-6238.json  \n",
            "  inflating: dataset3/train/truth-problem-6239.json  \n",
            "  inflating: dataset3/train/truth-problem-624.json  \n",
            "  inflating: dataset3/train/truth-problem-6240.json  \n",
            "  inflating: dataset3/train/truth-problem-6241.json  \n",
            "  inflating: dataset3/train/truth-problem-6242.json  \n",
            "  inflating: dataset3/train/truth-problem-6243.json  \n",
            "  inflating: dataset3/train/truth-problem-6244.json  \n",
            "  inflating: dataset3/train/truth-problem-6245.json  \n",
            "  inflating: dataset3/train/truth-problem-6246.json  \n",
            "  inflating: dataset3/train/truth-problem-6247.json  \n",
            "  inflating: dataset3/train/truth-problem-6248.json  \n",
            "  inflating: dataset3/train/truth-problem-6249.json  \n",
            "  inflating: dataset3/train/truth-problem-625.json  \n",
            "  inflating: dataset3/train/truth-problem-6250.json  \n",
            "  inflating: dataset3/train/truth-problem-6251.json  \n",
            "  inflating: dataset3/train/truth-problem-6252.json  \n",
            "  inflating: dataset3/train/truth-problem-6253.json  \n",
            "  inflating: dataset3/train/truth-problem-6254.json  \n",
            "  inflating: dataset3/train/truth-problem-6255.json  \n",
            "  inflating: dataset3/train/truth-problem-6256.json  \n",
            "  inflating: dataset3/train/truth-problem-6257.json  \n",
            "  inflating: dataset3/train/truth-problem-6258.json  \n",
            "  inflating: dataset3/train/truth-problem-6259.json  \n",
            "  inflating: dataset3/train/truth-problem-626.json  \n",
            "  inflating: dataset3/train/truth-problem-6260.json  \n",
            "  inflating: dataset3/train/truth-problem-6261.json  \n",
            "  inflating: dataset3/train/truth-problem-6262.json  \n",
            "  inflating: dataset3/train/truth-problem-6263.json  \n",
            "  inflating: dataset3/train/truth-problem-6264.json  \n",
            "  inflating: dataset3/train/truth-problem-6265.json  \n",
            "  inflating: dataset3/train/truth-problem-6266.json  \n",
            "  inflating: dataset3/train/truth-problem-6267.json  \n",
            "  inflating: dataset3/train/truth-problem-6268.json  \n",
            "  inflating: dataset3/train/truth-problem-6269.json  \n",
            "  inflating: dataset3/train/truth-problem-627.json  \n",
            "  inflating: dataset3/train/truth-problem-6270.json  \n",
            "  inflating: dataset3/train/truth-problem-6271.json  \n",
            "  inflating: dataset3/train/truth-problem-6272.json  \n",
            "  inflating: dataset3/train/truth-problem-6273.json  \n",
            "  inflating: dataset3/train/truth-problem-6274.json  \n",
            "  inflating: dataset3/train/truth-problem-6275.json  \n",
            "  inflating: dataset3/train/truth-problem-6276.json  \n",
            "  inflating: dataset3/train/truth-problem-6277.json  \n",
            "  inflating: dataset3/train/truth-problem-6278.json  \n",
            "  inflating: dataset3/train/truth-problem-6279.json  \n",
            "  inflating: dataset3/train/truth-problem-628.json  \n",
            "  inflating: dataset3/train/truth-problem-6280.json  \n",
            "  inflating: dataset3/train/truth-problem-6281.json  \n",
            "  inflating: dataset3/train/truth-problem-6282.json  \n",
            "  inflating: dataset3/train/truth-problem-6283.json  \n",
            "  inflating: dataset3/train/truth-problem-6284.json  \n",
            "  inflating: dataset3/train/truth-problem-6285.json  \n",
            "  inflating: dataset3/train/truth-problem-6286.json  \n",
            "  inflating: dataset3/train/truth-problem-6287.json  \n",
            "  inflating: dataset3/train/truth-problem-6288.json  \n",
            "  inflating: dataset3/train/truth-problem-6289.json  \n",
            "  inflating: dataset3/train/truth-problem-629.json  \n",
            "  inflating: dataset3/train/truth-problem-6290.json  \n",
            "  inflating: dataset3/train/truth-problem-6291.json  \n",
            "  inflating: dataset3/train/truth-problem-6292.json  \n",
            "  inflating: dataset3/train/truth-problem-6293.json  \n",
            "  inflating: dataset3/train/truth-problem-6294.json  \n",
            "  inflating: dataset3/train/truth-problem-6295.json  \n",
            "  inflating: dataset3/train/truth-problem-6296.json  \n",
            "  inflating: dataset3/train/truth-problem-6297.json  \n",
            "  inflating: dataset3/train/truth-problem-6298.json  \n",
            "  inflating: dataset3/train/truth-problem-6299.json  \n",
            "  inflating: dataset3/train/truth-problem-63.json  \n",
            "  inflating: dataset3/train/truth-problem-630.json  \n",
            "  inflating: dataset3/train/truth-problem-6300.json  \n",
            "  inflating: dataset3/train/truth-problem-6301.json  \n",
            "  inflating: dataset3/train/truth-problem-6302.json  \n",
            "  inflating: dataset3/train/truth-problem-6303.json  \n",
            "  inflating: dataset3/train/truth-problem-6304.json  \n",
            "  inflating: dataset3/train/truth-problem-6305.json  \n",
            "  inflating: dataset3/train/truth-problem-6306.json  \n",
            "  inflating: dataset3/train/truth-problem-6307.json  \n",
            "  inflating: dataset3/train/truth-problem-6308.json  \n",
            "  inflating: dataset3/train/truth-problem-6309.json  \n",
            "  inflating: dataset3/train/truth-problem-631.json  \n",
            "  inflating: dataset3/train/truth-problem-6310.json  \n",
            "  inflating: dataset3/train/truth-problem-6311.json  \n",
            "  inflating: dataset3/train/truth-problem-6312.json  \n",
            "  inflating: dataset3/train/truth-problem-6313.json  \n",
            "  inflating: dataset3/train/truth-problem-6314.json  \n",
            "  inflating: dataset3/train/truth-problem-6315.json  \n",
            "  inflating: dataset3/train/truth-problem-6316.json  \n",
            "  inflating: dataset3/train/truth-problem-6317.json  \n",
            "  inflating: dataset3/train/truth-problem-6318.json  \n",
            "  inflating: dataset3/train/truth-problem-6319.json  \n",
            "  inflating: dataset3/train/truth-problem-632.json  \n",
            "  inflating: dataset3/train/truth-problem-6320.json  \n",
            "  inflating: dataset3/train/truth-problem-6321.json  \n",
            "  inflating: dataset3/train/truth-problem-6322.json  \n",
            "  inflating: dataset3/train/truth-problem-6323.json  \n",
            "  inflating: dataset3/train/truth-problem-6324.json  \n",
            "  inflating: dataset3/train/truth-problem-6325.json  \n",
            "  inflating: dataset3/train/truth-problem-6326.json  \n",
            "  inflating: dataset3/train/truth-problem-6327.json  \n",
            "  inflating: dataset3/train/truth-problem-6328.json  \n",
            "  inflating: dataset3/train/truth-problem-6329.json  \n",
            "  inflating: dataset3/train/truth-problem-633.json  \n",
            "  inflating: dataset3/train/truth-problem-6330.json  \n",
            "  inflating: dataset3/train/truth-problem-6331.json  \n",
            "  inflating: dataset3/train/truth-problem-6332.json  \n",
            "  inflating: dataset3/train/truth-problem-6333.json  \n",
            "  inflating: dataset3/train/truth-problem-6334.json  \n",
            "  inflating: dataset3/train/truth-problem-6335.json  \n",
            "  inflating: dataset3/train/truth-problem-6336.json  \n",
            "  inflating: dataset3/train/truth-problem-6337.json  \n",
            "  inflating: dataset3/train/truth-problem-6338.json  \n",
            "  inflating: dataset3/train/truth-problem-6339.json  \n",
            "  inflating: dataset3/train/truth-problem-634.json  \n",
            "  inflating: dataset3/train/truth-problem-6340.json  \n",
            "  inflating: dataset3/train/truth-problem-6341.json  \n",
            "  inflating: dataset3/train/truth-problem-6342.json  \n",
            "  inflating: dataset3/train/truth-problem-6343.json  \n",
            "  inflating: dataset3/train/truth-problem-6344.json  \n",
            "  inflating: dataset3/train/truth-problem-6345.json  \n",
            "  inflating: dataset3/train/truth-problem-6346.json  \n",
            "  inflating: dataset3/train/truth-problem-6347.json  \n",
            "  inflating: dataset3/train/truth-problem-6348.json  \n",
            "  inflating: dataset3/train/truth-problem-6349.json  \n",
            "  inflating: dataset3/train/truth-problem-635.json  \n",
            "  inflating: dataset3/train/truth-problem-6350.json  \n",
            "  inflating: dataset3/train/truth-problem-6351.json  \n",
            "  inflating: dataset3/train/truth-problem-6352.json  \n",
            "  inflating: dataset3/train/truth-problem-6353.json  \n",
            "  inflating: dataset3/train/truth-problem-6354.json  \n",
            "  inflating: dataset3/train/truth-problem-6355.json  \n",
            "  inflating: dataset3/train/truth-problem-6356.json  \n",
            "  inflating: dataset3/train/truth-problem-6357.json  \n",
            "  inflating: dataset3/train/truth-problem-6358.json  \n",
            "  inflating: dataset3/train/truth-problem-6359.json  \n",
            "  inflating: dataset3/train/truth-problem-636.json  \n",
            "  inflating: dataset3/train/truth-problem-6360.json  \n",
            "  inflating: dataset3/train/truth-problem-6361.json  \n",
            "  inflating: dataset3/train/truth-problem-6362.json  \n",
            "  inflating: dataset3/train/truth-problem-6363.json  \n",
            "  inflating: dataset3/train/truth-problem-6364.json  \n",
            "  inflating: dataset3/train/truth-problem-6365.json  \n",
            "  inflating: dataset3/train/truth-problem-6366.json  \n",
            "  inflating: dataset3/train/truth-problem-6367.json  \n",
            "  inflating: dataset3/train/truth-problem-6368.json  \n",
            "  inflating: dataset3/train/truth-problem-6369.json  \n",
            "  inflating: dataset3/train/truth-problem-637.json  \n",
            "  inflating: dataset3/train/truth-problem-6370.json  \n",
            "  inflating: dataset3/train/truth-problem-6371.json  \n",
            "  inflating: dataset3/train/truth-problem-6372.json  \n",
            "  inflating: dataset3/train/truth-problem-6373.json  \n",
            "  inflating: dataset3/train/truth-problem-6374.json  \n",
            "  inflating: dataset3/train/truth-problem-6375.json  \n",
            "  inflating: dataset3/train/truth-problem-6376.json  \n",
            "  inflating: dataset3/train/truth-problem-6377.json  \n",
            "  inflating: dataset3/train/truth-problem-6378.json  \n",
            "  inflating: dataset3/train/truth-problem-6379.json  \n",
            "  inflating: dataset3/train/truth-problem-638.json  \n",
            "  inflating: dataset3/train/truth-problem-6380.json  \n",
            "  inflating: dataset3/train/truth-problem-6381.json  \n",
            "  inflating: dataset3/train/truth-problem-6382.json  \n",
            "  inflating: dataset3/train/truth-problem-6383.json  \n",
            "  inflating: dataset3/train/truth-problem-6384.json  \n",
            "  inflating: dataset3/train/truth-problem-6385.json  \n",
            "  inflating: dataset3/train/truth-problem-6386.json  \n",
            "  inflating: dataset3/train/truth-problem-6387.json  \n",
            "  inflating: dataset3/train/truth-problem-6388.json  \n",
            "  inflating: dataset3/train/truth-problem-6389.json  \n",
            "  inflating: dataset3/train/truth-problem-639.json  \n",
            "  inflating: dataset3/train/truth-problem-6390.json  \n",
            "  inflating: dataset3/train/truth-problem-6391.json  \n",
            "  inflating: dataset3/train/truth-problem-6392.json  \n",
            "  inflating: dataset3/train/truth-problem-6393.json  \n",
            "  inflating: dataset3/train/truth-problem-6394.json  \n",
            "  inflating: dataset3/train/truth-problem-6395.json  \n",
            "  inflating: dataset3/train/truth-problem-6396.json  \n",
            "  inflating: dataset3/train/truth-problem-6397.json  \n",
            "  inflating: dataset3/train/truth-problem-6398.json  \n",
            "  inflating: dataset3/train/truth-problem-6399.json  \n",
            "  inflating: dataset3/train/truth-problem-64.json  \n",
            "  inflating: dataset3/train/truth-problem-640.json  \n",
            "  inflating: dataset3/train/truth-problem-6400.json  \n",
            "  inflating: dataset3/train/truth-problem-6401.json  \n",
            "  inflating: dataset3/train/truth-problem-6402.json  \n",
            "  inflating: dataset3/train/truth-problem-6403.json  \n",
            "  inflating: dataset3/train/truth-problem-6404.json  \n",
            "  inflating: dataset3/train/truth-problem-6405.json  \n",
            "  inflating: dataset3/train/truth-problem-6406.json  \n",
            "  inflating: dataset3/train/truth-problem-6407.json  \n",
            "  inflating: dataset3/train/truth-problem-6408.json  \n",
            "  inflating: dataset3/train/truth-problem-6409.json  \n",
            "  inflating: dataset3/train/truth-problem-641.json  \n",
            "  inflating: dataset3/train/truth-problem-6410.json  \n",
            "  inflating: dataset3/train/truth-problem-6411.json  \n",
            "  inflating: dataset3/train/truth-problem-6412.json  \n",
            "  inflating: dataset3/train/truth-problem-6413.json  \n",
            "  inflating: dataset3/train/truth-problem-6414.json  \n",
            "  inflating: dataset3/train/truth-problem-6415.json  \n",
            "  inflating: dataset3/train/truth-problem-6416.json  \n",
            "  inflating: dataset3/train/truth-problem-6417.json  \n",
            "  inflating: dataset3/train/truth-problem-6418.json  \n",
            "  inflating: dataset3/train/truth-problem-6419.json  \n",
            "  inflating: dataset3/train/truth-problem-642.json  \n",
            "  inflating: dataset3/train/truth-problem-6420.json  \n",
            "  inflating: dataset3/train/truth-problem-6421.json  \n",
            "  inflating: dataset3/train/truth-problem-6422.json  \n",
            "  inflating: dataset3/train/truth-problem-6423.json  \n",
            "  inflating: dataset3/train/truth-problem-6424.json  \n",
            "  inflating: dataset3/train/truth-problem-6425.json  \n",
            "  inflating: dataset3/train/truth-problem-6426.json  \n",
            "  inflating: dataset3/train/truth-problem-6427.json  \n",
            "  inflating: dataset3/train/truth-problem-6428.json  \n",
            "  inflating: dataset3/train/truth-problem-6429.json  \n",
            "  inflating: dataset3/train/truth-problem-643.json  \n",
            "  inflating: dataset3/train/truth-problem-6430.json  \n",
            "  inflating: dataset3/train/truth-problem-6431.json  \n",
            "  inflating: dataset3/train/truth-problem-6432.json  \n",
            "  inflating: dataset3/train/truth-problem-6433.json  \n",
            "  inflating: dataset3/train/truth-problem-6434.json  \n",
            "  inflating: dataset3/train/truth-problem-6435.json  \n",
            "  inflating: dataset3/train/truth-problem-6436.json  \n",
            "  inflating: dataset3/train/truth-problem-6437.json  \n",
            "  inflating: dataset3/train/truth-problem-6438.json  \n",
            "  inflating: dataset3/train/truth-problem-6439.json  \n",
            "  inflating: dataset3/train/truth-problem-644.json  \n",
            "  inflating: dataset3/train/truth-problem-6440.json  \n",
            "  inflating: dataset3/train/truth-problem-6441.json  \n",
            "  inflating: dataset3/train/truth-problem-6442.json  \n",
            "  inflating: dataset3/train/truth-problem-6443.json  \n",
            "  inflating: dataset3/train/truth-problem-6444.json  \n",
            "  inflating: dataset3/train/truth-problem-6445.json  \n",
            "  inflating: dataset3/train/truth-problem-6446.json  \n",
            "  inflating: dataset3/train/truth-problem-6447.json  \n",
            "  inflating: dataset3/train/truth-problem-6448.json  \n",
            "  inflating: dataset3/train/truth-problem-6449.json  \n",
            "  inflating: dataset3/train/truth-problem-645.json  \n",
            "  inflating: dataset3/train/truth-problem-6450.json  \n",
            "  inflating: dataset3/train/truth-problem-6451.json  \n",
            "  inflating: dataset3/train/truth-problem-6452.json  \n",
            "  inflating: dataset3/train/truth-problem-6453.json  \n",
            "  inflating: dataset3/train/truth-problem-6454.json  \n",
            "  inflating: dataset3/train/truth-problem-6455.json  \n",
            "  inflating: dataset3/train/truth-problem-6456.json  \n",
            "  inflating: dataset3/train/truth-problem-6457.json  \n",
            "  inflating: dataset3/train/truth-problem-6458.json  \n",
            "  inflating: dataset3/train/truth-problem-6459.json  \n",
            "  inflating: dataset3/train/truth-problem-646.json  \n",
            "  inflating: dataset3/train/truth-problem-6460.json  \n",
            "  inflating: dataset3/train/truth-problem-6461.json  \n",
            "  inflating: dataset3/train/truth-problem-6462.json  \n",
            "  inflating: dataset3/train/truth-problem-6463.json  \n",
            "  inflating: dataset3/train/truth-problem-6464.json  \n",
            "  inflating: dataset3/train/truth-problem-6465.json  \n",
            "  inflating: dataset3/train/truth-problem-6466.json  \n",
            "  inflating: dataset3/train/truth-problem-6467.json  \n",
            "  inflating: dataset3/train/truth-problem-6468.json  \n",
            "  inflating: dataset3/train/truth-problem-6469.json  \n",
            "  inflating: dataset3/train/truth-problem-647.json  \n",
            "  inflating: dataset3/train/truth-problem-6470.json  \n",
            "  inflating: dataset3/train/truth-problem-6471.json  \n",
            "  inflating: dataset3/train/truth-problem-6472.json  \n",
            "  inflating: dataset3/train/truth-problem-6473.json  \n",
            "  inflating: dataset3/train/truth-problem-6474.json  \n",
            "  inflating: dataset3/train/truth-problem-6475.json  \n",
            "  inflating: dataset3/train/truth-problem-6476.json  \n",
            "  inflating: dataset3/train/truth-problem-6477.json  \n",
            "  inflating: dataset3/train/truth-problem-6478.json  \n",
            "  inflating: dataset3/train/truth-problem-6479.json  \n",
            "  inflating: dataset3/train/truth-problem-648.json  \n",
            "  inflating: dataset3/train/truth-problem-6480.json  \n",
            "  inflating: dataset3/train/truth-problem-6481.json  \n",
            "  inflating: dataset3/train/truth-problem-6482.json  \n",
            "  inflating: dataset3/train/truth-problem-6483.json  \n",
            "  inflating: dataset3/train/truth-problem-6484.json  \n",
            "  inflating: dataset3/train/truth-problem-6485.json  \n",
            "  inflating: dataset3/train/truth-problem-6486.json  \n",
            "  inflating: dataset3/train/truth-problem-6487.json  \n",
            "  inflating: dataset3/train/truth-problem-6488.json  \n",
            "  inflating: dataset3/train/truth-problem-6489.json  \n",
            "  inflating: dataset3/train/truth-problem-649.json  \n",
            "  inflating: dataset3/train/truth-problem-6490.json  \n",
            "  inflating: dataset3/train/truth-problem-6491.json  \n",
            "  inflating: dataset3/train/truth-problem-6492.json  \n",
            "  inflating: dataset3/train/truth-problem-6493.json  \n",
            "  inflating: dataset3/train/truth-problem-6494.json  \n",
            "  inflating: dataset3/train/truth-problem-6495.json  \n",
            "  inflating: dataset3/train/truth-problem-6496.json  \n",
            "  inflating: dataset3/train/truth-problem-6497.json  \n",
            "  inflating: dataset3/train/truth-problem-6498.json  \n",
            "  inflating: dataset3/train/truth-problem-6499.json  \n",
            "  inflating: dataset3/train/truth-problem-65.json  \n",
            "  inflating: dataset3/train/truth-problem-650.json  \n",
            "  inflating: dataset3/train/truth-problem-6500.json  \n",
            "  inflating: dataset3/train/truth-problem-6501.json  \n",
            "  inflating: dataset3/train/truth-problem-6502.json  \n",
            "  inflating: dataset3/train/truth-problem-6503.json  \n",
            "  inflating: dataset3/train/truth-problem-6504.json  \n",
            "  inflating: dataset3/train/truth-problem-6505.json  \n",
            "  inflating: dataset3/train/truth-problem-6506.json  \n",
            "  inflating: dataset3/train/truth-problem-6507.json  \n",
            "  inflating: dataset3/train/truth-problem-6508.json  \n",
            "  inflating: dataset3/train/truth-problem-6509.json  \n",
            "  inflating: dataset3/train/truth-problem-651.json  \n",
            "  inflating: dataset3/train/truth-problem-6510.json  \n",
            "  inflating: dataset3/train/truth-problem-6511.json  \n",
            "  inflating: dataset3/train/truth-problem-6512.json  \n",
            "  inflating: dataset3/train/truth-problem-6513.json  \n",
            "  inflating: dataset3/train/truth-problem-6514.json  \n",
            "  inflating: dataset3/train/truth-problem-6515.json  \n",
            "  inflating: dataset3/train/truth-problem-6516.json  \n",
            "  inflating: dataset3/train/truth-problem-6517.json  \n",
            "  inflating: dataset3/train/truth-problem-6518.json  \n",
            "  inflating: dataset3/train/truth-problem-6519.json  \n",
            "  inflating: dataset3/train/truth-problem-652.json  \n",
            "  inflating: dataset3/train/truth-problem-6520.json  \n",
            "  inflating: dataset3/train/truth-problem-6521.json  \n",
            "  inflating: dataset3/train/truth-problem-6522.json  \n",
            "  inflating: dataset3/train/truth-problem-6523.json  \n",
            "  inflating: dataset3/train/truth-problem-6524.json  \n",
            "  inflating: dataset3/train/truth-problem-6525.json  \n",
            "  inflating: dataset3/train/truth-problem-6526.json  \n",
            "  inflating: dataset3/train/truth-problem-6527.json  \n",
            "  inflating: dataset3/train/truth-problem-6528.json  \n",
            "  inflating: dataset3/train/truth-problem-6529.json  \n",
            "  inflating: dataset3/train/truth-problem-653.json  \n",
            "  inflating: dataset3/train/truth-problem-6530.json  \n",
            "  inflating: dataset3/train/truth-problem-6531.json  \n",
            "  inflating: dataset3/train/truth-problem-6532.json  \n",
            "  inflating: dataset3/train/truth-problem-6533.json  \n",
            "  inflating: dataset3/train/truth-problem-6534.json  \n",
            "  inflating: dataset3/train/truth-problem-6535.json  \n",
            "  inflating: dataset3/train/truth-problem-6536.json  \n",
            "  inflating: dataset3/train/truth-problem-6537.json  \n",
            "  inflating: dataset3/train/truth-problem-6538.json  \n",
            "  inflating: dataset3/train/truth-problem-6539.json  \n",
            "  inflating: dataset3/train/truth-problem-654.json  \n",
            "  inflating: dataset3/train/truth-problem-6540.json  \n",
            "  inflating: dataset3/train/truth-problem-6541.json  \n",
            "  inflating: dataset3/train/truth-problem-6542.json  \n",
            "  inflating: dataset3/train/truth-problem-6543.json  \n",
            "  inflating: dataset3/train/truth-problem-6544.json  \n",
            "  inflating: dataset3/train/truth-problem-6545.json  \n",
            "  inflating: dataset3/train/truth-problem-6546.json  \n",
            "  inflating: dataset3/train/truth-problem-6547.json  \n",
            "  inflating: dataset3/train/truth-problem-6548.json  \n",
            "  inflating: dataset3/train/truth-problem-6549.json  \n",
            "  inflating: dataset3/train/truth-problem-655.json  \n",
            "  inflating: dataset3/train/truth-problem-6550.json  \n",
            "  inflating: dataset3/train/truth-problem-6551.json  \n",
            "  inflating: dataset3/train/truth-problem-6552.json  \n",
            "  inflating: dataset3/train/truth-problem-6553.json  \n",
            "  inflating: dataset3/train/truth-problem-6554.json  \n",
            "  inflating: dataset3/train/truth-problem-6555.json  \n",
            "  inflating: dataset3/train/truth-problem-6556.json  \n",
            "  inflating: dataset3/train/truth-problem-6557.json  \n",
            "  inflating: dataset3/train/truth-problem-6558.json  \n",
            "  inflating: dataset3/train/truth-problem-6559.json  \n",
            "  inflating: dataset3/train/truth-problem-656.json  \n",
            "  inflating: dataset3/train/truth-problem-6560.json  \n",
            "  inflating: dataset3/train/truth-problem-6561.json  \n",
            "  inflating: dataset3/train/truth-problem-6562.json  \n",
            "  inflating: dataset3/train/truth-problem-6563.json  \n",
            "  inflating: dataset3/train/truth-problem-6564.json  \n",
            "  inflating: dataset3/train/truth-problem-6565.json  \n",
            "  inflating: dataset3/train/truth-problem-6566.json  \n",
            "  inflating: dataset3/train/truth-problem-6567.json  \n",
            "  inflating: dataset3/train/truth-problem-6568.json  \n",
            "  inflating: dataset3/train/truth-problem-6569.json  \n",
            "  inflating: dataset3/train/truth-problem-657.json  \n",
            "  inflating: dataset3/train/truth-problem-6570.json  \n",
            "  inflating: dataset3/train/truth-problem-6571.json  \n",
            "  inflating: dataset3/train/truth-problem-6572.json  \n",
            "  inflating: dataset3/train/truth-problem-6573.json  \n",
            "  inflating: dataset3/train/truth-problem-6574.json  \n",
            "  inflating: dataset3/train/truth-problem-6575.json  \n",
            "  inflating: dataset3/train/truth-problem-6576.json  \n",
            "  inflating: dataset3/train/truth-problem-6577.json  \n",
            "  inflating: dataset3/train/truth-problem-6578.json  \n",
            "  inflating: dataset3/train/truth-problem-6579.json  \n",
            "  inflating: dataset3/train/truth-problem-658.json  \n",
            "  inflating: dataset3/train/truth-problem-6580.json  \n",
            "  inflating: dataset3/train/truth-problem-6581.json  \n",
            "  inflating: dataset3/train/truth-problem-6582.json  \n",
            "  inflating: dataset3/train/truth-problem-6583.json  \n",
            "  inflating: dataset3/train/truth-problem-6584.json  \n",
            "  inflating: dataset3/train/truth-problem-6585.json  \n",
            "  inflating: dataset3/train/truth-problem-6586.json  \n",
            "  inflating: dataset3/train/truth-problem-6587.json  \n",
            "  inflating: dataset3/train/truth-problem-6588.json  \n",
            "  inflating: dataset3/train/truth-problem-6589.json  \n",
            "  inflating: dataset3/train/truth-problem-659.json  \n",
            "  inflating: dataset3/train/truth-problem-6590.json  \n",
            "  inflating: dataset3/train/truth-problem-6591.json  \n",
            "  inflating: dataset3/train/truth-problem-6592.json  \n",
            "  inflating: dataset3/train/truth-problem-6593.json  \n",
            "  inflating: dataset3/train/truth-problem-6594.json  \n",
            "  inflating: dataset3/train/truth-problem-6595.json  \n",
            "  inflating: dataset3/train/truth-problem-6596.json  \n",
            "  inflating: dataset3/train/truth-problem-6597.json  \n",
            "  inflating: dataset3/train/truth-problem-6598.json  \n",
            "  inflating: dataset3/train/truth-problem-6599.json  \n",
            "  inflating: dataset3/train/truth-problem-66.json  \n",
            "  inflating: dataset3/train/truth-problem-660.json  \n",
            "  inflating: dataset3/train/truth-problem-6600.json  \n",
            "  inflating: dataset3/train/truth-problem-6601.json  \n",
            "  inflating: dataset3/train/truth-problem-6602.json  \n",
            "  inflating: dataset3/train/truth-problem-6603.json  \n",
            "  inflating: dataset3/train/truth-problem-6604.json  \n",
            "  inflating: dataset3/train/truth-problem-6605.json  \n",
            "  inflating: dataset3/train/truth-problem-6606.json  \n",
            "  inflating: dataset3/train/truth-problem-6607.json  \n",
            "  inflating: dataset3/train/truth-problem-6608.json  \n",
            "  inflating: dataset3/train/truth-problem-6609.json  \n",
            "  inflating: dataset3/train/truth-problem-661.json  \n",
            "  inflating: dataset3/train/truth-problem-6610.json  \n",
            "  inflating: dataset3/train/truth-problem-6611.json  \n",
            "  inflating: dataset3/train/truth-problem-6612.json  \n",
            "  inflating: dataset3/train/truth-problem-6613.json  \n",
            "  inflating: dataset3/train/truth-problem-6614.json  \n",
            "  inflating: dataset3/train/truth-problem-6615.json  \n",
            "  inflating: dataset3/train/truth-problem-6616.json  \n",
            "  inflating: dataset3/train/truth-problem-6617.json  \n",
            "  inflating: dataset3/train/truth-problem-6618.json  \n",
            "  inflating: dataset3/train/truth-problem-6619.json  \n",
            "  inflating: dataset3/train/truth-problem-662.json  \n",
            "  inflating: dataset3/train/truth-problem-6620.json  \n",
            "  inflating: dataset3/train/truth-problem-6621.json  \n",
            "  inflating: dataset3/train/truth-problem-6622.json  \n",
            "  inflating: dataset3/train/truth-problem-6623.json  \n",
            "  inflating: dataset3/train/truth-problem-6624.json  \n",
            "  inflating: dataset3/train/truth-problem-6625.json  \n",
            "  inflating: dataset3/train/truth-problem-6626.json  \n",
            "  inflating: dataset3/train/truth-problem-6627.json  \n",
            "  inflating: dataset3/train/truth-problem-6628.json  \n",
            "  inflating: dataset3/train/truth-problem-6629.json  \n",
            "  inflating: dataset3/train/truth-problem-663.json  \n",
            "  inflating: dataset3/train/truth-problem-6630.json  \n",
            "  inflating: dataset3/train/truth-problem-6631.json  \n",
            "  inflating: dataset3/train/truth-problem-6632.json  \n",
            "  inflating: dataset3/train/truth-problem-6633.json  \n",
            "  inflating: dataset3/train/truth-problem-6634.json  \n",
            "  inflating: dataset3/train/truth-problem-6635.json  \n",
            "  inflating: dataset3/train/truth-problem-6636.json  \n",
            "  inflating: dataset3/train/truth-problem-6637.json  \n",
            "  inflating: dataset3/train/truth-problem-6638.json  \n",
            "  inflating: dataset3/train/truth-problem-6639.json  \n",
            "  inflating: dataset3/train/truth-problem-664.json  \n",
            "  inflating: dataset3/train/truth-problem-6640.json  \n",
            "  inflating: dataset3/train/truth-problem-6641.json  \n",
            "  inflating: dataset3/train/truth-problem-6642.json  \n",
            "  inflating: dataset3/train/truth-problem-6643.json  \n",
            "  inflating: dataset3/train/truth-problem-6644.json  \n",
            "  inflating: dataset3/train/truth-problem-6645.json  \n",
            "  inflating: dataset3/train/truth-problem-6646.json  \n",
            "  inflating: dataset3/train/truth-problem-6647.json  \n",
            "  inflating: dataset3/train/truth-problem-6648.json  \n",
            "  inflating: dataset3/train/truth-problem-6649.json  \n",
            "  inflating: dataset3/train/truth-problem-665.json  \n",
            "  inflating: dataset3/train/truth-problem-6650.json  \n",
            "  inflating: dataset3/train/truth-problem-6651.json  \n",
            "  inflating: dataset3/train/truth-problem-6652.json  \n",
            "  inflating: dataset3/train/truth-problem-6653.json  \n",
            "  inflating: dataset3/train/truth-problem-6654.json  \n",
            "  inflating: dataset3/train/truth-problem-6655.json  \n",
            "  inflating: dataset3/train/truth-problem-6656.json  \n",
            "  inflating: dataset3/train/truth-problem-6657.json  \n",
            "  inflating: dataset3/train/truth-problem-6658.json  \n",
            "  inflating: dataset3/train/truth-problem-6659.json  \n",
            "  inflating: dataset3/train/truth-problem-666.json  \n",
            "  inflating: dataset3/train/truth-problem-6660.json  \n",
            "  inflating: dataset3/train/truth-problem-6661.json  \n",
            "  inflating: dataset3/train/truth-problem-6662.json  \n",
            "  inflating: dataset3/train/truth-problem-6663.json  \n",
            "  inflating: dataset3/train/truth-problem-6664.json  \n",
            "  inflating: dataset3/train/truth-problem-6665.json  \n",
            "  inflating: dataset3/train/truth-problem-6666.json  \n",
            "  inflating: dataset3/train/truth-problem-6667.json  \n",
            "  inflating: dataset3/train/truth-problem-6668.json  \n",
            "  inflating: dataset3/train/truth-problem-6669.json  \n",
            "  inflating: dataset3/train/truth-problem-667.json  \n",
            "  inflating: dataset3/train/truth-problem-6670.json  \n",
            "  inflating: dataset3/train/truth-problem-6671.json  \n",
            "  inflating: dataset3/train/truth-problem-6672.json  \n",
            "  inflating: dataset3/train/truth-problem-6673.json  \n",
            "  inflating: dataset3/train/truth-problem-6674.json  \n",
            "  inflating: dataset3/train/truth-problem-6675.json  \n",
            "  inflating: dataset3/train/truth-problem-6676.json  \n",
            "  inflating: dataset3/train/truth-problem-6677.json  \n",
            "  inflating: dataset3/train/truth-problem-6678.json  \n",
            "  inflating: dataset3/train/truth-problem-6679.json  \n",
            "  inflating: dataset3/train/truth-problem-668.json  \n",
            "  inflating: dataset3/train/truth-problem-6680.json  \n",
            "  inflating: dataset3/train/truth-problem-6681.json  \n",
            "  inflating: dataset3/train/truth-problem-6682.json  \n",
            "  inflating: dataset3/train/truth-problem-6683.json  \n",
            "  inflating: dataset3/train/truth-problem-6684.json  \n",
            "  inflating: dataset3/train/truth-problem-6685.json  \n",
            "  inflating: dataset3/train/truth-problem-6686.json  \n",
            "  inflating: dataset3/train/truth-problem-6687.json  \n",
            "  inflating: dataset3/train/truth-problem-6688.json  \n",
            "  inflating: dataset3/train/truth-problem-6689.json  \n",
            "  inflating: dataset3/train/truth-problem-669.json  \n",
            "  inflating: dataset3/train/truth-problem-6690.json  \n",
            "  inflating: dataset3/train/truth-problem-6691.json  \n",
            "  inflating: dataset3/train/truth-problem-6692.json  \n",
            "  inflating: dataset3/train/truth-problem-6693.json  \n",
            "  inflating: dataset3/train/truth-problem-6694.json  \n",
            "  inflating: dataset3/train/truth-problem-6695.json  \n",
            "  inflating: dataset3/train/truth-problem-6696.json  \n",
            "  inflating: dataset3/train/truth-problem-6697.json  \n",
            "  inflating: dataset3/train/truth-problem-6698.json  \n",
            "  inflating: dataset3/train/truth-problem-6699.json  \n",
            "  inflating: dataset3/train/truth-problem-67.json  \n",
            "  inflating: dataset3/train/truth-problem-670.json  \n",
            "  inflating: dataset3/train/truth-problem-6700.json  \n",
            "  inflating: dataset3/train/truth-problem-6701.json  \n",
            "  inflating: dataset3/train/truth-problem-6702.json  \n",
            "  inflating: dataset3/train/truth-problem-6703.json  \n",
            "  inflating: dataset3/train/truth-problem-6704.json  \n",
            "  inflating: dataset3/train/truth-problem-6705.json  \n",
            "  inflating: dataset3/train/truth-problem-6706.json  \n",
            "  inflating: dataset3/train/truth-problem-6707.json  \n",
            "  inflating: dataset3/train/truth-problem-6708.json  \n",
            "  inflating: dataset3/train/truth-problem-6709.json  \n",
            "  inflating: dataset3/train/truth-problem-671.json  \n",
            "  inflating: dataset3/train/truth-problem-6710.json  \n",
            "  inflating: dataset3/train/truth-problem-6711.json  \n",
            "  inflating: dataset3/train/truth-problem-6712.json  \n",
            "  inflating: dataset3/train/truth-problem-6713.json  \n",
            "  inflating: dataset3/train/truth-problem-6714.json  \n",
            "  inflating: dataset3/train/truth-problem-6715.json  \n",
            "  inflating: dataset3/train/truth-problem-6716.json  \n",
            "  inflating: dataset3/train/truth-problem-6717.json  \n",
            "  inflating: dataset3/train/truth-problem-6718.json  \n",
            "  inflating: dataset3/train/truth-problem-6719.json  \n",
            "  inflating: dataset3/train/truth-problem-672.json  \n",
            "  inflating: dataset3/train/truth-problem-6720.json  \n",
            "  inflating: dataset3/train/truth-problem-6721.json  \n",
            "  inflating: dataset3/train/truth-problem-6722.json  \n",
            "  inflating: dataset3/train/truth-problem-6723.json  \n",
            "  inflating: dataset3/train/truth-problem-6724.json  \n",
            "  inflating: dataset3/train/truth-problem-6725.json  \n",
            "  inflating: dataset3/train/truth-problem-6726.json  \n",
            "  inflating: dataset3/train/truth-problem-6727.json  \n",
            "  inflating: dataset3/train/truth-problem-6728.json  \n",
            "  inflating: dataset3/train/truth-problem-6729.json  \n",
            "  inflating: dataset3/train/truth-problem-673.json  \n",
            "  inflating: dataset3/train/truth-problem-6730.json  \n",
            "  inflating: dataset3/train/truth-problem-6731.json  \n",
            "  inflating: dataset3/train/truth-problem-6732.json  \n",
            "  inflating: dataset3/train/truth-problem-6733.json  \n",
            "  inflating: dataset3/train/truth-problem-6734.json  \n",
            "  inflating: dataset3/train/truth-problem-6735.json  \n",
            "  inflating: dataset3/train/truth-problem-6736.json  \n",
            "  inflating: dataset3/train/truth-problem-6737.json  \n",
            "  inflating: dataset3/train/truth-problem-6738.json  \n",
            "  inflating: dataset3/train/truth-problem-6739.json  \n",
            "  inflating: dataset3/train/truth-problem-674.json  \n",
            "  inflating: dataset3/train/truth-problem-6740.json  \n",
            "  inflating: dataset3/train/truth-problem-6741.json  \n",
            "  inflating: dataset3/train/truth-problem-6742.json  \n",
            "  inflating: dataset3/train/truth-problem-6743.json  \n",
            "  inflating: dataset3/train/truth-problem-6744.json  \n",
            "  inflating: dataset3/train/truth-problem-6745.json  \n",
            "  inflating: dataset3/train/truth-problem-6746.json  \n",
            "  inflating: dataset3/train/truth-problem-6747.json  \n",
            "  inflating: dataset3/train/truth-problem-6748.json  \n",
            "  inflating: dataset3/train/truth-problem-6749.json  \n",
            "  inflating: dataset3/train/truth-problem-675.json  \n",
            "  inflating: dataset3/train/truth-problem-6750.json  \n",
            "  inflating: dataset3/train/truth-problem-6751.json  \n",
            "  inflating: dataset3/train/truth-problem-6752.json  \n",
            "  inflating: dataset3/train/truth-problem-6753.json  \n",
            "  inflating: dataset3/train/truth-problem-6754.json  \n",
            "  inflating: dataset3/train/truth-problem-6755.json  \n",
            "  inflating: dataset3/train/truth-problem-6756.json  \n",
            "  inflating: dataset3/train/truth-problem-6757.json  \n",
            "  inflating: dataset3/train/truth-problem-6758.json  \n",
            "  inflating: dataset3/train/truth-problem-6759.json  \n",
            "  inflating: dataset3/train/truth-problem-676.json  \n",
            "  inflating: dataset3/train/truth-problem-6760.json  \n",
            "  inflating: dataset3/train/truth-problem-6761.json  \n",
            "  inflating: dataset3/train/truth-problem-6762.json  \n",
            "  inflating: dataset3/train/truth-problem-6763.json  \n",
            "  inflating: dataset3/train/truth-problem-6764.json  \n",
            "  inflating: dataset3/train/truth-problem-6765.json  \n",
            "  inflating: dataset3/train/truth-problem-6766.json  \n",
            "  inflating: dataset3/train/truth-problem-6767.json  \n",
            "  inflating: dataset3/train/truth-problem-6768.json  \n",
            "  inflating: dataset3/train/truth-problem-6769.json  \n",
            "  inflating: dataset3/train/truth-problem-677.json  \n",
            "  inflating: dataset3/train/truth-problem-6770.json  \n",
            "  inflating: dataset3/train/truth-problem-6771.json  \n",
            "  inflating: dataset3/train/truth-problem-6772.json  \n",
            "  inflating: dataset3/train/truth-problem-6773.json  \n",
            "  inflating: dataset3/train/truth-problem-6774.json  \n",
            "  inflating: dataset3/train/truth-problem-6775.json  \n",
            "  inflating: dataset3/train/truth-problem-6776.json  \n",
            "  inflating: dataset3/train/truth-problem-6777.json  \n",
            "  inflating: dataset3/train/truth-problem-6778.json  \n",
            "  inflating: dataset3/train/truth-problem-6779.json  \n",
            "  inflating: dataset3/train/truth-problem-678.json  \n",
            "  inflating: dataset3/train/truth-problem-6780.json  \n",
            "  inflating: dataset3/train/truth-problem-6781.json  \n",
            "  inflating: dataset3/train/truth-problem-6782.json  \n",
            "  inflating: dataset3/train/truth-problem-6783.json  \n",
            "  inflating: dataset3/train/truth-problem-6784.json  \n",
            "  inflating: dataset3/train/truth-problem-6785.json  \n",
            "  inflating: dataset3/train/truth-problem-6786.json  \n",
            "  inflating: dataset3/train/truth-problem-6787.json  \n",
            "  inflating: dataset3/train/truth-problem-6788.json  \n",
            "  inflating: dataset3/train/truth-problem-6789.json  \n",
            "  inflating: dataset3/train/truth-problem-679.json  \n",
            "  inflating: dataset3/train/truth-problem-6790.json  \n",
            "  inflating: dataset3/train/truth-problem-6791.json  \n",
            "  inflating: dataset3/train/truth-problem-6792.json  \n",
            "  inflating: dataset3/train/truth-problem-6793.json  \n",
            "  inflating: dataset3/train/truth-problem-6794.json  \n",
            "  inflating: dataset3/train/truth-problem-6795.json  \n",
            "  inflating: dataset3/train/truth-problem-6796.json  \n",
            "  inflating: dataset3/train/truth-problem-6797.json  \n",
            "  inflating: dataset3/train/truth-problem-6798.json  \n",
            "  inflating: dataset3/train/truth-problem-6799.json  \n",
            "  inflating: dataset3/train/truth-problem-68.json  \n",
            "  inflating: dataset3/train/truth-problem-680.json  \n",
            "  inflating: dataset3/train/truth-problem-6800.json  \n",
            "  inflating: dataset3/train/truth-problem-6801.json  \n",
            "  inflating: dataset3/train/truth-problem-6802.json  \n",
            "  inflating: dataset3/train/truth-problem-6803.json  \n",
            "  inflating: dataset3/train/truth-problem-6804.json  \n",
            "  inflating: dataset3/train/truth-problem-6805.json  \n",
            "  inflating: dataset3/train/truth-problem-6806.json  \n",
            "  inflating: dataset3/train/truth-problem-6807.json  \n",
            "  inflating: dataset3/train/truth-problem-6808.json  \n",
            "  inflating: dataset3/train/truth-problem-6809.json  \n",
            "  inflating: dataset3/train/truth-problem-681.json  \n",
            "  inflating: dataset3/train/truth-problem-6810.json  \n",
            "  inflating: dataset3/train/truth-problem-6811.json  \n",
            "  inflating: dataset3/train/truth-problem-6812.json  \n",
            "  inflating: dataset3/train/truth-problem-6813.json  \n",
            "  inflating: dataset3/train/truth-problem-6814.json  \n",
            "  inflating: dataset3/train/truth-problem-6815.json  \n",
            "  inflating: dataset3/train/truth-problem-6816.json  \n",
            "  inflating: dataset3/train/truth-problem-6817.json  \n",
            "  inflating: dataset3/train/truth-problem-6818.json  \n",
            "  inflating: dataset3/train/truth-problem-6819.json  \n",
            "  inflating: dataset3/train/truth-problem-682.json  \n",
            "  inflating: dataset3/train/truth-problem-6820.json  \n",
            "  inflating: dataset3/train/truth-problem-6821.json  \n",
            "  inflating: dataset3/train/truth-problem-6822.json  \n",
            "  inflating: dataset3/train/truth-problem-6823.json  \n",
            "  inflating: dataset3/train/truth-problem-6824.json  \n",
            "  inflating: dataset3/train/truth-problem-6825.json  \n",
            "  inflating: dataset3/train/truth-problem-6826.json  \n",
            "  inflating: dataset3/train/truth-problem-6827.json  \n",
            "  inflating: dataset3/train/truth-problem-6828.json  \n",
            "  inflating: dataset3/train/truth-problem-6829.json  \n",
            "  inflating: dataset3/train/truth-problem-683.json  \n",
            "  inflating: dataset3/train/truth-problem-6830.json  \n",
            "  inflating: dataset3/train/truth-problem-6831.json  \n",
            "  inflating: dataset3/train/truth-problem-6832.json  \n",
            "  inflating: dataset3/train/truth-problem-6833.json  \n",
            "  inflating: dataset3/train/truth-problem-6834.json  \n",
            "  inflating: dataset3/train/truth-problem-6835.json  \n",
            "  inflating: dataset3/train/truth-problem-6836.json  \n",
            "  inflating: dataset3/train/truth-problem-6837.json  \n",
            "  inflating: dataset3/train/truth-problem-6838.json  \n",
            "  inflating: dataset3/train/truth-problem-6839.json  \n",
            "  inflating: dataset3/train/truth-problem-684.json  \n",
            "  inflating: dataset3/train/truth-problem-6840.json  \n",
            "  inflating: dataset3/train/truth-problem-6841.json  \n",
            "  inflating: dataset3/train/truth-problem-6842.json  \n",
            "  inflating: dataset3/train/truth-problem-6843.json  \n",
            "  inflating: dataset3/train/truth-problem-6844.json  \n",
            "  inflating: dataset3/train/truth-problem-6845.json  \n",
            "  inflating: dataset3/train/truth-problem-6846.json  \n",
            "  inflating: dataset3/train/truth-problem-6847.json  \n",
            "  inflating: dataset3/train/truth-problem-6848.json  \n",
            "  inflating: dataset3/train/truth-problem-6849.json  \n",
            "  inflating: dataset3/train/truth-problem-685.json  \n",
            "  inflating: dataset3/train/truth-problem-6850.json  \n",
            "  inflating: dataset3/train/truth-problem-6851.json  \n",
            "  inflating: dataset3/train/truth-problem-6852.json  \n",
            "  inflating: dataset3/train/truth-problem-6853.json  \n",
            "  inflating: dataset3/train/truth-problem-6854.json  \n",
            "  inflating: dataset3/train/truth-problem-6855.json  \n",
            "  inflating: dataset3/train/truth-problem-6856.json  \n",
            "  inflating: dataset3/train/truth-problem-6857.json  \n",
            "  inflating: dataset3/train/truth-problem-6858.json  \n",
            "  inflating: dataset3/train/truth-problem-6859.json  \n",
            "  inflating: dataset3/train/truth-problem-686.json  \n",
            "  inflating: dataset3/train/truth-problem-6860.json  \n",
            "  inflating: dataset3/train/truth-problem-6861.json  \n",
            "  inflating: dataset3/train/truth-problem-6862.json  \n",
            "  inflating: dataset3/train/truth-problem-6863.json  \n",
            "  inflating: dataset3/train/truth-problem-6864.json  \n",
            "  inflating: dataset3/train/truth-problem-6865.json  \n",
            "  inflating: dataset3/train/truth-problem-6866.json  \n",
            "  inflating: dataset3/train/truth-problem-6867.json  \n",
            "  inflating: dataset3/train/truth-problem-6868.json  \n",
            "  inflating: dataset3/train/truth-problem-6869.json  \n",
            "  inflating: dataset3/train/truth-problem-687.json  \n",
            "  inflating: dataset3/train/truth-problem-6870.json  \n",
            "  inflating: dataset3/train/truth-problem-6871.json  \n",
            "  inflating: dataset3/train/truth-problem-6872.json  \n",
            "  inflating: dataset3/train/truth-problem-6873.json  \n",
            "  inflating: dataset3/train/truth-problem-6874.json  \n",
            "  inflating: dataset3/train/truth-problem-6875.json  \n",
            "  inflating: dataset3/train/truth-problem-6876.json  \n",
            "  inflating: dataset3/train/truth-problem-6877.json  \n",
            "  inflating: dataset3/train/truth-problem-6878.json  \n",
            "  inflating: dataset3/train/truth-problem-6879.json  \n",
            "  inflating: dataset3/train/truth-problem-688.json  \n",
            "  inflating: dataset3/train/truth-problem-6880.json  \n",
            "  inflating: dataset3/train/truth-problem-6881.json  \n",
            "  inflating: dataset3/train/truth-problem-6882.json  \n",
            "  inflating: dataset3/train/truth-problem-6883.json  \n",
            "  inflating: dataset3/train/truth-problem-6884.json  \n",
            "  inflating: dataset3/train/truth-problem-6885.json  \n",
            "  inflating: dataset3/train/truth-problem-6886.json  \n",
            "  inflating: dataset3/train/truth-problem-6887.json  \n",
            "  inflating: dataset3/train/truth-problem-6888.json  \n",
            "  inflating: dataset3/train/truth-problem-6889.json  \n",
            "  inflating: dataset3/train/truth-problem-689.json  \n",
            "  inflating: dataset3/train/truth-problem-6890.json  \n",
            "  inflating: dataset3/train/truth-problem-6891.json  \n",
            "  inflating: dataset3/train/truth-problem-6892.json  \n",
            "  inflating: dataset3/train/truth-problem-6893.json  \n",
            "  inflating: dataset3/train/truth-problem-6894.json  \n",
            "  inflating: dataset3/train/truth-problem-6895.json  \n",
            "  inflating: dataset3/train/truth-problem-6896.json  \n",
            "  inflating: dataset3/train/truth-problem-6897.json  \n",
            "  inflating: dataset3/train/truth-problem-6898.json  \n",
            "  inflating: dataset3/train/truth-problem-6899.json  \n",
            "  inflating: dataset3/train/truth-problem-69.json  \n",
            "  inflating: dataset3/train/truth-problem-690.json  \n",
            "  inflating: dataset3/train/truth-problem-6900.json  \n",
            "  inflating: dataset3/train/truth-problem-6901.json  \n",
            "  inflating: dataset3/train/truth-problem-6902.json  \n",
            "  inflating: dataset3/train/truth-problem-6903.json  \n",
            "  inflating: dataset3/train/truth-problem-6904.json  \n",
            "  inflating: dataset3/train/truth-problem-6905.json  \n",
            "  inflating: dataset3/train/truth-problem-6906.json  \n",
            "  inflating: dataset3/train/truth-problem-6907.json  \n",
            "  inflating: dataset3/train/truth-problem-6908.json  \n",
            "  inflating: dataset3/train/truth-problem-6909.json  \n",
            "  inflating: dataset3/train/truth-problem-691.json  \n",
            "  inflating: dataset3/train/truth-problem-6910.json  \n",
            "  inflating: dataset3/train/truth-problem-6911.json  \n",
            "  inflating: dataset3/train/truth-problem-6912.json  \n",
            "  inflating: dataset3/train/truth-problem-6913.json  \n",
            "  inflating: dataset3/train/truth-problem-6914.json  \n",
            "  inflating: dataset3/train/truth-problem-6915.json  \n",
            "  inflating: dataset3/train/truth-problem-6916.json  \n",
            "  inflating: dataset3/train/truth-problem-6917.json  \n",
            "  inflating: dataset3/train/truth-problem-6918.json  \n",
            "  inflating: dataset3/train/truth-problem-6919.json  \n",
            "  inflating: dataset3/train/truth-problem-692.json  \n",
            "  inflating: dataset3/train/truth-problem-6920.json  \n",
            "  inflating: dataset3/train/truth-problem-6921.json  \n",
            "  inflating: dataset3/train/truth-problem-6922.json  \n",
            "  inflating: dataset3/train/truth-problem-6923.json  \n",
            "  inflating: dataset3/train/truth-problem-6924.json  \n",
            "  inflating: dataset3/train/truth-problem-6925.json  \n",
            "  inflating: dataset3/train/truth-problem-6926.json  \n",
            "  inflating: dataset3/train/truth-problem-6927.json  \n",
            "  inflating: dataset3/train/truth-problem-6928.json  \n",
            "  inflating: dataset3/train/truth-problem-6929.json  \n",
            "  inflating: dataset3/train/truth-problem-693.json  \n",
            "  inflating: dataset3/train/truth-problem-6930.json  \n",
            "  inflating: dataset3/train/truth-problem-6931.json  \n",
            "  inflating: dataset3/train/truth-problem-6932.json  \n",
            "  inflating: dataset3/train/truth-problem-6933.json  \n",
            "  inflating: dataset3/train/truth-problem-6934.json  \n",
            "  inflating: dataset3/train/truth-problem-6935.json  \n",
            "  inflating: dataset3/train/truth-problem-6936.json  \n",
            "  inflating: dataset3/train/truth-problem-6937.json  \n",
            "  inflating: dataset3/train/truth-problem-6938.json  \n",
            "  inflating: dataset3/train/truth-problem-6939.json  \n",
            "  inflating: dataset3/train/truth-problem-694.json  \n",
            "  inflating: dataset3/train/truth-problem-6940.json  \n",
            "  inflating: dataset3/train/truth-problem-6941.json  \n",
            "  inflating: dataset3/train/truth-problem-6942.json  \n",
            "  inflating: dataset3/train/truth-problem-6943.json  \n",
            "  inflating: dataset3/train/truth-problem-6944.json  \n",
            "  inflating: dataset3/train/truth-problem-6945.json  \n",
            "  inflating: dataset3/train/truth-problem-6946.json  \n",
            "  inflating: dataset3/train/truth-problem-6947.json  \n",
            "  inflating: dataset3/train/truth-problem-6948.json  \n",
            "  inflating: dataset3/train/truth-problem-6949.json  \n",
            "  inflating: dataset3/train/truth-problem-695.json  \n",
            "  inflating: dataset3/train/truth-problem-6950.json  \n",
            "  inflating: dataset3/train/truth-problem-6951.json  \n",
            "  inflating: dataset3/train/truth-problem-6952.json  \n",
            "  inflating: dataset3/train/truth-problem-6953.json  \n",
            "  inflating: dataset3/train/truth-problem-6954.json  \n",
            "  inflating: dataset3/train/truth-problem-6955.json  \n",
            "  inflating: dataset3/train/truth-problem-6956.json  \n",
            "  inflating: dataset3/train/truth-problem-6957.json  \n",
            "  inflating: dataset3/train/truth-problem-6958.json  \n",
            "  inflating: dataset3/train/truth-problem-6959.json  \n",
            "  inflating: dataset3/train/truth-problem-696.json  \n",
            "  inflating: dataset3/train/truth-problem-6960.json  \n",
            "  inflating: dataset3/train/truth-problem-6961.json  \n",
            "  inflating: dataset3/train/truth-problem-6962.json  \n",
            "  inflating: dataset3/train/truth-problem-6963.json  \n",
            "  inflating: dataset3/train/truth-problem-6964.json  \n",
            "  inflating: dataset3/train/truth-problem-6965.json  \n",
            "  inflating: dataset3/train/truth-problem-6966.json  \n",
            "  inflating: dataset3/train/truth-problem-6967.json  \n",
            "  inflating: dataset3/train/truth-problem-6968.json  \n",
            "  inflating: dataset3/train/truth-problem-6969.json  \n",
            "  inflating: dataset3/train/truth-problem-697.json  \n",
            "  inflating: dataset3/train/truth-problem-6970.json  \n",
            "  inflating: dataset3/train/truth-problem-6971.json  \n",
            "  inflating: dataset3/train/truth-problem-6972.json  \n",
            "  inflating: dataset3/train/truth-problem-6973.json  \n",
            "  inflating: dataset3/train/truth-problem-6974.json  \n",
            "  inflating: dataset3/train/truth-problem-6975.json  \n",
            "  inflating: dataset3/train/truth-problem-6976.json  \n",
            "  inflating: dataset3/train/truth-problem-6977.json  \n",
            "  inflating: dataset3/train/truth-problem-6978.json  \n",
            "  inflating: dataset3/train/truth-problem-6979.json  \n",
            "  inflating: dataset3/train/truth-problem-698.json  \n",
            "  inflating: dataset3/train/truth-problem-6980.json  \n",
            "  inflating: dataset3/train/truth-problem-6981.json  \n",
            "  inflating: dataset3/train/truth-problem-6982.json  \n",
            "  inflating: dataset3/train/truth-problem-6983.json  \n",
            "  inflating: dataset3/train/truth-problem-6984.json  \n",
            "  inflating: dataset3/train/truth-problem-6985.json  \n",
            "  inflating: dataset3/train/truth-problem-6986.json  \n",
            "  inflating: dataset3/train/truth-problem-6987.json  \n",
            "  inflating: dataset3/train/truth-problem-6988.json  \n",
            "  inflating: dataset3/train/truth-problem-6989.json  \n",
            "  inflating: dataset3/train/truth-problem-699.json  \n",
            "  inflating: dataset3/train/truth-problem-6990.json  \n",
            "  inflating: dataset3/train/truth-problem-6991.json  \n",
            "  inflating: dataset3/train/truth-problem-6992.json  \n",
            "  inflating: dataset3/train/truth-problem-6993.json  \n",
            "  inflating: dataset3/train/truth-problem-6994.json  \n",
            "  inflating: dataset3/train/truth-problem-6995.json  \n",
            "  inflating: dataset3/train/truth-problem-6996.json  \n",
            "  inflating: dataset3/train/truth-problem-6997.json  \n",
            "  inflating: dataset3/train/truth-problem-6998.json  \n",
            "  inflating: dataset3/train/truth-problem-6999.json  \n",
            "  inflating: dataset3/train/truth-problem-7.json  \n",
            "  inflating: dataset3/train/truth-problem-70.json  \n",
            "  inflating: dataset3/train/truth-problem-700.json  \n",
            "  inflating: dataset3/train/truth-problem-7000.json  \n",
            "  inflating: dataset3/train/truth-problem-701.json  \n",
            "  inflating: dataset3/train/truth-problem-702.json  \n",
            "  inflating: dataset3/train/truth-problem-703.json  \n",
            "  inflating: dataset3/train/truth-problem-704.json  \n",
            "  inflating: dataset3/train/truth-problem-705.json  \n",
            "  inflating: dataset3/train/truth-problem-706.json  \n",
            "  inflating: dataset3/train/truth-problem-707.json  \n",
            "  inflating: dataset3/train/truth-problem-708.json  \n",
            "  inflating: dataset3/train/truth-problem-709.json  \n",
            "  inflating: dataset3/train/truth-problem-71.json  \n",
            "  inflating: dataset3/train/truth-problem-710.json  \n",
            "  inflating: dataset3/train/truth-problem-711.json  \n",
            "  inflating: dataset3/train/truth-problem-712.json  \n",
            "  inflating: dataset3/train/truth-problem-713.json  \n",
            "  inflating: dataset3/train/truth-problem-714.json  \n",
            "  inflating: dataset3/train/truth-problem-715.json  \n",
            "  inflating: dataset3/train/truth-problem-716.json  \n",
            "  inflating: dataset3/train/truth-problem-717.json  \n",
            "  inflating: dataset3/train/truth-problem-718.json  \n",
            "  inflating: dataset3/train/truth-problem-719.json  \n",
            "  inflating: dataset3/train/truth-problem-72.json  \n",
            "  inflating: dataset3/train/truth-problem-720.json  \n",
            "  inflating: dataset3/train/truth-problem-721.json  \n",
            "  inflating: dataset3/train/truth-problem-722.json  \n",
            "  inflating: dataset3/train/truth-problem-723.json  \n",
            "  inflating: dataset3/train/truth-problem-724.json  \n",
            "  inflating: dataset3/train/truth-problem-725.json  \n",
            "  inflating: dataset3/train/truth-problem-726.json  \n",
            "  inflating: dataset3/train/truth-problem-727.json  \n",
            "  inflating: dataset3/train/truth-problem-728.json  \n",
            "  inflating: dataset3/train/truth-problem-729.json  \n",
            "  inflating: dataset3/train/truth-problem-73.json  \n",
            "  inflating: dataset3/train/truth-problem-730.json  \n",
            "  inflating: dataset3/train/truth-problem-731.json  \n",
            "  inflating: dataset3/train/truth-problem-732.json  \n",
            "  inflating: dataset3/train/truth-problem-733.json  \n",
            "  inflating: dataset3/train/truth-problem-734.json  \n",
            "  inflating: dataset3/train/truth-problem-735.json  \n",
            "  inflating: dataset3/train/truth-problem-736.json  \n",
            "  inflating: dataset3/train/truth-problem-737.json  \n",
            "  inflating: dataset3/train/truth-problem-738.json  \n",
            "  inflating: dataset3/train/truth-problem-739.json  \n",
            "  inflating: dataset3/train/truth-problem-74.json  \n",
            "  inflating: dataset3/train/truth-problem-740.json  \n",
            "  inflating: dataset3/train/truth-problem-741.json  \n",
            "  inflating: dataset3/train/truth-problem-742.json  \n",
            "  inflating: dataset3/train/truth-problem-743.json  \n",
            "  inflating: dataset3/train/truth-problem-744.json  \n",
            "  inflating: dataset3/train/truth-problem-745.json  \n",
            "  inflating: dataset3/train/truth-problem-746.json  \n",
            "  inflating: dataset3/train/truth-problem-747.json  \n",
            "  inflating: dataset3/train/truth-problem-748.json  \n",
            "  inflating: dataset3/train/truth-problem-749.json  \n",
            "  inflating: dataset3/train/truth-problem-75.json  \n",
            "  inflating: dataset3/train/truth-problem-750.json  \n",
            "  inflating: dataset3/train/truth-problem-751.json  \n",
            "  inflating: dataset3/train/truth-problem-752.json  \n",
            "  inflating: dataset3/train/truth-problem-753.json  \n",
            "  inflating: dataset3/train/truth-problem-754.json  \n",
            "  inflating: dataset3/train/truth-problem-755.json  \n",
            "  inflating: dataset3/train/truth-problem-756.json  \n",
            "  inflating: dataset3/train/truth-problem-757.json  \n",
            "  inflating: dataset3/train/truth-problem-758.json  \n",
            "  inflating: dataset3/train/truth-problem-759.json  \n",
            "  inflating: dataset3/train/truth-problem-76.json  \n",
            "  inflating: dataset3/train/truth-problem-760.json  \n",
            "  inflating: dataset3/train/truth-problem-761.json  \n",
            "  inflating: dataset3/train/truth-problem-762.json  \n",
            "  inflating: dataset3/train/truth-problem-763.json  \n",
            "  inflating: dataset3/train/truth-problem-764.json  \n",
            "  inflating: dataset3/train/truth-problem-765.json  \n",
            "  inflating: dataset3/train/truth-problem-766.json  \n",
            "  inflating: dataset3/train/truth-problem-767.json  \n",
            "  inflating: dataset3/train/truth-problem-768.json  \n",
            "  inflating: dataset3/train/truth-problem-769.json  \n",
            "  inflating: dataset3/train/truth-problem-77.json  \n",
            "  inflating: dataset3/train/truth-problem-770.json  \n",
            "  inflating: dataset3/train/truth-problem-771.json  \n",
            "  inflating: dataset3/train/truth-problem-772.json  \n",
            "  inflating: dataset3/train/truth-problem-773.json  \n",
            "  inflating: dataset3/train/truth-problem-774.json  \n",
            "  inflating: dataset3/train/truth-problem-775.json  \n",
            "  inflating: dataset3/train/truth-problem-776.json  \n",
            "  inflating: dataset3/train/truth-problem-777.json  \n",
            "  inflating: dataset3/train/truth-problem-778.json  \n",
            "  inflating: dataset3/train/truth-problem-779.json  \n",
            "  inflating: dataset3/train/truth-problem-78.json  \n",
            "  inflating: dataset3/train/truth-problem-780.json  \n",
            "  inflating: dataset3/train/truth-problem-781.json  \n",
            "  inflating: dataset3/train/truth-problem-782.json  \n",
            "  inflating: dataset3/train/truth-problem-783.json  \n",
            "  inflating: dataset3/train/truth-problem-784.json  \n",
            "  inflating: dataset3/train/truth-problem-785.json  \n",
            "  inflating: dataset3/train/truth-problem-786.json  \n",
            "  inflating: dataset3/train/truth-problem-787.json  \n",
            "  inflating: dataset3/train/truth-problem-788.json  \n",
            "  inflating: dataset3/train/truth-problem-789.json  \n",
            "  inflating: dataset3/train/truth-problem-79.json  \n",
            "  inflating: dataset3/train/truth-problem-790.json  \n",
            "  inflating: dataset3/train/truth-problem-791.json  \n",
            "  inflating: dataset3/train/truth-problem-792.json  \n",
            "  inflating: dataset3/train/truth-problem-793.json  \n",
            "  inflating: dataset3/train/truth-problem-794.json  \n",
            "  inflating: dataset3/train/truth-problem-795.json  \n",
            "  inflating: dataset3/train/truth-problem-796.json  \n",
            "  inflating: dataset3/train/truth-problem-797.json  \n",
            "  inflating: dataset3/train/truth-problem-798.json  \n",
            "  inflating: dataset3/train/truth-problem-799.json  \n",
            "  inflating: dataset3/train/truth-problem-8.json  \n",
            "  inflating: dataset3/train/truth-problem-80.json  \n",
            "  inflating: dataset3/train/truth-problem-800.json  \n",
            "  inflating: dataset3/train/truth-problem-801.json  \n",
            "  inflating: dataset3/train/truth-problem-802.json  \n",
            "  inflating: dataset3/train/truth-problem-803.json  \n",
            "  inflating: dataset3/train/truth-problem-804.json  \n",
            "  inflating: dataset3/train/truth-problem-805.json  \n",
            "  inflating: dataset3/train/truth-problem-806.json  \n",
            "  inflating: dataset3/train/truth-problem-807.json  \n",
            "  inflating: dataset3/train/truth-problem-808.json  \n",
            "  inflating: dataset3/train/truth-problem-809.json  \n",
            "  inflating: dataset3/train/truth-problem-81.json  \n",
            "  inflating: dataset3/train/truth-problem-810.json  \n",
            "  inflating: dataset3/train/truth-problem-811.json  \n",
            "  inflating: dataset3/train/truth-problem-812.json  \n",
            "  inflating: dataset3/train/truth-problem-813.json  \n",
            "  inflating: dataset3/train/truth-problem-814.json  \n",
            "  inflating: dataset3/train/truth-problem-815.json  \n",
            "  inflating: dataset3/train/truth-problem-816.json  \n",
            "  inflating: dataset3/train/truth-problem-817.json  \n",
            "  inflating: dataset3/train/truth-problem-818.json  \n",
            "  inflating: dataset3/train/truth-problem-819.json  \n",
            "  inflating: dataset3/train/truth-problem-82.json  \n",
            "  inflating: dataset3/train/truth-problem-820.json  \n",
            "  inflating: dataset3/train/truth-problem-821.json  \n",
            "  inflating: dataset3/train/truth-problem-822.json  \n",
            "  inflating: dataset3/train/truth-problem-823.json  \n",
            "  inflating: dataset3/train/truth-problem-824.json  \n",
            "  inflating: dataset3/train/truth-problem-825.json  \n",
            "  inflating: dataset3/train/truth-problem-826.json  \n",
            "  inflating: dataset3/train/truth-problem-827.json  \n",
            "  inflating: dataset3/train/truth-problem-828.json  \n",
            "  inflating: dataset3/train/truth-problem-829.json  \n",
            "  inflating: dataset3/train/truth-problem-83.json  \n",
            "  inflating: dataset3/train/truth-problem-830.json  \n",
            "  inflating: dataset3/train/truth-problem-831.json  \n",
            "  inflating: dataset3/train/truth-problem-832.json  \n",
            "  inflating: dataset3/train/truth-problem-833.json  \n",
            "  inflating: dataset3/train/truth-problem-834.json  \n",
            "  inflating: dataset3/train/truth-problem-835.json  \n",
            "  inflating: dataset3/train/truth-problem-836.json  \n",
            "  inflating: dataset3/train/truth-problem-837.json  \n",
            "  inflating: dataset3/train/truth-problem-838.json  \n",
            "  inflating: dataset3/train/truth-problem-839.json  \n",
            "  inflating: dataset3/train/truth-problem-84.json  \n",
            "  inflating: dataset3/train/truth-problem-840.json  \n",
            "  inflating: dataset3/train/truth-problem-841.json  \n",
            "  inflating: dataset3/train/truth-problem-842.json  \n",
            "  inflating: dataset3/train/truth-problem-843.json  \n",
            "  inflating: dataset3/train/truth-problem-844.json  \n",
            "  inflating: dataset3/train/truth-problem-845.json  \n",
            "  inflating: dataset3/train/truth-problem-846.json  \n",
            "  inflating: dataset3/train/truth-problem-847.json  \n",
            "  inflating: dataset3/train/truth-problem-848.json  \n",
            "  inflating: dataset3/train/truth-problem-849.json  \n",
            "  inflating: dataset3/train/truth-problem-85.json  \n",
            "  inflating: dataset3/train/truth-problem-850.json  \n",
            "  inflating: dataset3/train/truth-problem-851.json  \n",
            "  inflating: dataset3/train/truth-problem-852.json  \n",
            "  inflating: dataset3/train/truth-problem-853.json  \n",
            "  inflating: dataset3/train/truth-problem-854.json  \n",
            "  inflating: dataset3/train/truth-problem-855.json  \n",
            "  inflating: dataset3/train/truth-problem-856.json  \n",
            "  inflating: dataset3/train/truth-problem-857.json  \n",
            "  inflating: dataset3/train/truth-problem-858.json  \n",
            "  inflating: dataset3/train/truth-problem-859.json  \n",
            "  inflating: dataset3/train/truth-problem-86.json  \n",
            "  inflating: dataset3/train/truth-problem-860.json  \n",
            "  inflating: dataset3/train/truth-problem-861.json  \n",
            "  inflating: dataset3/train/truth-problem-862.json  \n",
            "  inflating: dataset3/train/truth-problem-863.json  \n",
            "  inflating: dataset3/train/truth-problem-864.json  \n",
            "  inflating: dataset3/train/truth-problem-865.json  \n",
            "  inflating: dataset3/train/truth-problem-866.json  \n",
            "  inflating: dataset3/train/truth-problem-867.json  \n",
            "  inflating: dataset3/train/truth-problem-868.json  \n",
            "  inflating: dataset3/train/truth-problem-869.json  \n",
            "  inflating: dataset3/train/truth-problem-87.json  \n",
            "  inflating: dataset3/train/truth-problem-870.json  \n",
            "  inflating: dataset3/train/truth-problem-871.json  \n",
            "  inflating: dataset3/train/truth-problem-872.json  \n",
            "  inflating: dataset3/train/truth-problem-873.json  \n",
            "  inflating: dataset3/train/truth-problem-874.json  \n",
            "  inflating: dataset3/train/truth-problem-875.json  \n",
            "  inflating: dataset3/train/truth-problem-876.json  \n",
            "  inflating: dataset3/train/truth-problem-877.json  \n",
            "  inflating: dataset3/train/truth-problem-878.json  \n",
            "  inflating: dataset3/train/truth-problem-879.json  \n",
            "  inflating: dataset3/train/truth-problem-88.json  \n",
            "  inflating: dataset3/train/truth-problem-880.json  \n",
            "  inflating: dataset3/train/truth-problem-881.json  \n",
            "  inflating: dataset3/train/truth-problem-882.json  \n",
            "  inflating: dataset3/train/truth-problem-883.json  \n",
            "  inflating: dataset3/train/truth-problem-884.json  \n",
            "  inflating: dataset3/train/truth-problem-885.json  \n",
            "  inflating: dataset3/train/truth-problem-886.json  \n",
            "  inflating: dataset3/train/truth-problem-887.json  \n",
            "  inflating: dataset3/train/truth-problem-888.json  \n",
            "  inflating: dataset3/train/truth-problem-889.json  \n",
            "  inflating: dataset3/train/truth-problem-89.json  \n",
            "  inflating: dataset3/train/truth-problem-890.json  \n",
            "  inflating: dataset3/train/truth-problem-891.json  \n",
            "  inflating: dataset3/train/truth-problem-892.json  \n",
            "  inflating: dataset3/train/truth-problem-893.json  \n",
            "  inflating: dataset3/train/truth-problem-894.json  \n",
            "  inflating: dataset3/train/truth-problem-895.json  \n",
            "  inflating: dataset3/train/truth-problem-896.json  \n",
            "  inflating: dataset3/train/truth-problem-897.json  \n",
            "  inflating: dataset3/train/truth-problem-898.json  \n",
            "  inflating: dataset3/train/truth-problem-899.json  \n",
            "  inflating: dataset3/train/truth-problem-9.json  \n",
            "  inflating: dataset3/train/truth-problem-90.json  \n",
            "  inflating: dataset3/train/truth-problem-900.json  \n",
            "  inflating: dataset3/train/truth-problem-901.json  \n",
            "  inflating: dataset3/train/truth-problem-902.json  \n",
            "  inflating: dataset3/train/truth-problem-903.json  \n",
            "  inflating: dataset3/train/truth-problem-904.json  \n",
            "  inflating: dataset3/train/truth-problem-905.json  \n",
            "  inflating: dataset3/train/truth-problem-906.json  \n",
            "  inflating: dataset3/train/truth-problem-907.json  \n",
            "  inflating: dataset3/train/truth-problem-908.json  \n",
            "  inflating: dataset3/train/truth-problem-909.json  \n",
            "  inflating: dataset3/train/truth-problem-91.json  \n",
            "  inflating: dataset3/train/truth-problem-910.json  \n",
            "  inflating: dataset3/train/truth-problem-911.json  \n",
            "  inflating: dataset3/train/truth-problem-912.json  \n",
            "  inflating: dataset3/train/truth-problem-913.json  \n",
            "  inflating: dataset3/train/truth-problem-914.json  \n",
            "  inflating: dataset3/train/truth-problem-915.json  \n",
            "  inflating: dataset3/train/truth-problem-916.json  \n",
            "  inflating: dataset3/train/truth-problem-917.json  \n",
            "  inflating: dataset3/train/truth-problem-918.json  \n",
            "  inflating: dataset3/train/truth-problem-919.json  \n",
            "  inflating: dataset3/train/truth-problem-92.json  \n",
            "  inflating: dataset3/train/truth-problem-920.json  \n",
            "  inflating: dataset3/train/truth-problem-921.json  \n",
            "  inflating: dataset3/train/truth-problem-922.json  \n",
            "  inflating: dataset3/train/truth-problem-923.json  \n",
            "  inflating: dataset3/train/truth-problem-924.json  \n",
            "  inflating: dataset3/train/truth-problem-925.json  \n",
            "  inflating: dataset3/train/truth-problem-926.json  \n",
            "  inflating: dataset3/train/truth-problem-927.json  \n",
            "  inflating: dataset3/train/truth-problem-928.json  \n",
            "  inflating: dataset3/train/truth-problem-929.json  \n",
            "  inflating: dataset3/train/truth-problem-93.json  \n",
            "  inflating: dataset3/train/truth-problem-930.json  \n",
            "  inflating: dataset3/train/truth-problem-931.json  \n",
            "  inflating: dataset3/train/truth-problem-932.json  \n",
            "  inflating: dataset3/train/truth-problem-933.json  \n",
            "  inflating: dataset3/train/truth-problem-934.json  \n",
            "  inflating: dataset3/train/truth-problem-935.json  \n",
            "  inflating: dataset3/train/truth-problem-936.json  \n",
            "  inflating: dataset3/train/truth-problem-937.json  \n",
            "  inflating: dataset3/train/truth-problem-938.json  \n",
            "  inflating: dataset3/train/truth-problem-939.json  \n",
            "  inflating: dataset3/train/truth-problem-94.json  \n",
            "  inflating: dataset3/train/truth-problem-940.json  \n",
            "  inflating: dataset3/train/truth-problem-941.json  \n",
            "  inflating: dataset3/train/truth-problem-942.json  \n",
            "  inflating: dataset3/train/truth-problem-943.json  \n",
            "  inflating: dataset3/train/truth-problem-944.json  \n",
            "  inflating: dataset3/train/truth-problem-945.json  \n",
            "  inflating: dataset3/train/truth-problem-946.json  \n",
            "  inflating: dataset3/train/truth-problem-947.json  \n",
            "  inflating: dataset3/train/truth-problem-948.json  \n",
            "  inflating: dataset3/train/truth-problem-949.json  \n",
            "  inflating: dataset3/train/truth-problem-95.json  \n",
            "  inflating: dataset3/train/truth-problem-950.json  \n",
            "  inflating: dataset3/train/truth-problem-951.json  \n",
            "  inflating: dataset3/train/truth-problem-952.json  \n",
            "  inflating: dataset3/train/truth-problem-953.json  \n",
            "  inflating: dataset3/train/truth-problem-954.json  \n",
            "  inflating: dataset3/train/truth-problem-955.json  \n",
            "  inflating: dataset3/train/truth-problem-956.json  \n",
            "  inflating: dataset3/train/truth-problem-957.json  \n",
            "  inflating: dataset3/train/truth-problem-958.json  \n",
            "  inflating: dataset3/train/truth-problem-959.json  \n",
            "  inflating: dataset3/train/truth-problem-96.json  \n",
            "  inflating: dataset3/train/truth-problem-960.json  \n",
            "  inflating: dataset3/train/truth-problem-961.json  \n",
            "  inflating: dataset3/train/truth-problem-962.json  \n",
            "  inflating: dataset3/train/truth-problem-963.json  \n",
            "  inflating: dataset3/train/truth-problem-964.json  \n",
            "  inflating: dataset3/train/truth-problem-965.json  \n",
            "  inflating: dataset3/train/truth-problem-966.json  \n",
            "  inflating: dataset3/train/truth-problem-967.json  \n",
            "  inflating: dataset3/train/truth-problem-968.json  \n",
            "  inflating: dataset3/train/truth-problem-969.json  \n",
            "  inflating: dataset3/train/truth-problem-97.json  \n",
            "  inflating: dataset3/train/truth-problem-970.json  \n",
            "  inflating: dataset3/train/truth-problem-971.json  \n",
            "  inflating: dataset3/train/truth-problem-972.json  \n",
            "  inflating: dataset3/train/truth-problem-973.json  \n",
            "  inflating: dataset3/train/truth-problem-974.json  \n",
            "  inflating: dataset3/train/truth-problem-975.json  \n",
            "  inflating: dataset3/train/truth-problem-976.json  \n",
            "  inflating: dataset3/train/truth-problem-977.json  \n",
            "  inflating: dataset3/train/truth-problem-978.json  \n",
            "  inflating: dataset3/train/truth-problem-979.json  \n",
            "  inflating: dataset3/train/truth-problem-98.json  \n",
            "  inflating: dataset3/train/truth-problem-980.json  \n",
            "  inflating: dataset3/train/truth-problem-981.json  \n",
            "  inflating: dataset3/train/truth-problem-982.json  \n",
            "  inflating: dataset3/train/truth-problem-983.json  \n",
            "  inflating: dataset3/train/truth-problem-984.json  \n",
            "  inflating: dataset3/train/truth-problem-985.json  \n",
            "  inflating: dataset3/train/truth-problem-986.json  \n",
            "  inflating: dataset3/train/truth-problem-987.json  \n",
            "  inflating: dataset3/train/truth-problem-988.json  \n",
            "  inflating: dataset3/train/truth-problem-989.json  \n",
            "  inflating: dataset3/train/truth-problem-99.json  \n",
            "  inflating: dataset3/train/truth-problem-990.json  \n",
            "  inflating: dataset3/train/truth-problem-991.json  \n",
            "  inflating: dataset3/train/truth-problem-992.json  \n",
            "  inflating: dataset3/train/truth-problem-993.json  \n",
            "  inflating: dataset3/train/truth-problem-994.json  \n",
            "  inflating: dataset3/train/truth-problem-995.json  \n",
            "  inflating: dataset3/train/truth-problem-996.json  \n",
            "  inflating: dataset3/train/truth-problem-997.json  \n",
            "  inflating: dataset3/train/truth-problem-998.json  \n",
            "  inflating: dataset3/train/truth-problem-999.json  \n",
            "   creating: dataset3/validation/\n",
            "  inflating: dataset3/validation/problem-1.txt  \n",
            "  inflating: dataset3/validation/problem-10.txt  \n",
            "  inflating: dataset3/validation/problem-100.txt  \n",
            "  inflating: dataset3/validation/problem-1000.txt  \n",
            "  inflating: dataset3/validation/problem-1001.txt  \n",
            "  inflating: dataset3/validation/problem-1002.txt  \n",
            "  inflating: dataset3/validation/problem-1003.txt  \n",
            "  inflating: dataset3/validation/problem-1004.txt  \n",
            "  inflating: dataset3/validation/problem-1005.txt  \n",
            "  inflating: dataset3/validation/problem-1006.txt  \n",
            "  inflating: dataset3/validation/problem-1007.txt  \n",
            "  inflating: dataset3/validation/problem-1008.txt  \n",
            "  inflating: dataset3/validation/problem-1009.txt  \n",
            "  inflating: dataset3/validation/problem-101.txt  \n",
            "  inflating: dataset3/validation/problem-1010.txt  \n",
            "  inflating: dataset3/validation/problem-1011.txt  \n",
            "  inflating: dataset3/validation/problem-1012.txt  \n",
            "  inflating: dataset3/validation/problem-1013.txt  \n",
            "  inflating: dataset3/validation/problem-1014.txt  \n",
            "  inflating: dataset3/validation/problem-1015.txt  \n",
            "  inflating: dataset3/validation/problem-1016.txt  \n",
            "  inflating: dataset3/validation/problem-1017.txt  \n",
            "  inflating: dataset3/validation/problem-1018.txt  \n",
            "  inflating: dataset3/validation/problem-1019.txt  \n",
            "  inflating: dataset3/validation/problem-102.txt  \n",
            "  inflating: dataset3/validation/problem-1020.txt  \n",
            "  inflating: dataset3/validation/problem-1021.txt  \n",
            "  inflating: dataset3/validation/problem-1022.txt  \n",
            "  inflating: dataset3/validation/problem-1023.txt  \n",
            "  inflating: dataset3/validation/problem-1024.txt  \n",
            "  inflating: dataset3/validation/problem-1025.txt  \n",
            "  inflating: dataset3/validation/problem-1026.txt  \n",
            "  inflating: dataset3/validation/problem-1027.txt  \n",
            "  inflating: dataset3/validation/problem-1028.txt  \n",
            "  inflating: dataset3/validation/problem-1029.txt  \n",
            "  inflating: dataset3/validation/problem-103.txt  \n",
            "  inflating: dataset3/validation/problem-1030.txt  \n",
            "  inflating: dataset3/validation/problem-1031.txt  \n",
            "  inflating: dataset3/validation/problem-1032.txt  \n",
            "  inflating: dataset3/validation/problem-1033.txt  \n",
            "  inflating: dataset3/validation/problem-1034.txt  \n",
            "  inflating: dataset3/validation/problem-1035.txt  \n",
            "  inflating: dataset3/validation/problem-1036.txt  \n",
            "  inflating: dataset3/validation/problem-1037.txt  \n",
            "  inflating: dataset3/validation/problem-1038.txt  \n",
            "  inflating: dataset3/validation/problem-1039.txt  \n",
            "  inflating: dataset3/validation/problem-104.txt  \n",
            "  inflating: dataset3/validation/problem-1040.txt  \n",
            "  inflating: dataset3/validation/problem-1041.txt  \n",
            "  inflating: dataset3/validation/problem-1042.txt  \n",
            "  inflating: dataset3/validation/problem-1043.txt  \n",
            "  inflating: dataset3/validation/problem-1044.txt  \n",
            "  inflating: dataset3/validation/problem-1045.txt  \n",
            "  inflating: dataset3/validation/problem-1046.txt  \n",
            "  inflating: dataset3/validation/problem-1047.txt  \n",
            "  inflating: dataset3/validation/problem-1048.txt  \n",
            "  inflating: dataset3/validation/problem-1049.txt  \n",
            "  inflating: dataset3/validation/problem-105.txt  \n",
            "  inflating: dataset3/validation/problem-1050.txt  \n",
            "  inflating: dataset3/validation/problem-1051.txt  \n",
            "  inflating: dataset3/validation/problem-1052.txt  \n",
            "  inflating: dataset3/validation/problem-1053.txt  \n",
            "  inflating: dataset3/validation/problem-1054.txt  \n",
            "  inflating: dataset3/validation/problem-1055.txt  \n",
            "  inflating: dataset3/validation/problem-1056.txt  \n",
            "  inflating: dataset3/validation/problem-1057.txt  \n",
            "  inflating: dataset3/validation/problem-1058.txt  \n",
            "  inflating: dataset3/validation/problem-1059.txt  \n",
            "  inflating: dataset3/validation/problem-106.txt  \n",
            "  inflating: dataset3/validation/problem-1060.txt  \n",
            "  inflating: dataset3/validation/problem-1061.txt  \n",
            "  inflating: dataset3/validation/problem-1062.txt  \n",
            "  inflating: dataset3/validation/problem-1063.txt  \n",
            "  inflating: dataset3/validation/problem-1064.txt  \n",
            "  inflating: dataset3/validation/problem-1065.txt  \n",
            "  inflating: dataset3/validation/problem-1066.txt  \n",
            "  inflating: dataset3/validation/problem-1067.txt  \n",
            "  inflating: dataset3/validation/problem-1068.txt  \n",
            "  inflating: dataset3/validation/problem-1069.txt  \n",
            "  inflating: dataset3/validation/problem-107.txt  \n",
            "  inflating: dataset3/validation/problem-1070.txt  \n",
            "  inflating: dataset3/validation/problem-1071.txt  \n",
            "  inflating: dataset3/validation/problem-1072.txt  \n",
            "  inflating: dataset3/validation/problem-1073.txt  \n",
            "  inflating: dataset3/validation/problem-1074.txt  \n",
            "  inflating: dataset3/validation/problem-1075.txt  \n",
            "  inflating: dataset3/validation/problem-1076.txt  \n",
            "  inflating: dataset3/validation/problem-1077.txt  \n",
            "  inflating: dataset3/validation/problem-1078.txt  \n",
            "  inflating: dataset3/validation/problem-1079.txt  \n",
            "  inflating: dataset3/validation/problem-108.txt  \n",
            "  inflating: dataset3/validation/problem-1080.txt  \n",
            "  inflating: dataset3/validation/problem-1081.txt  \n",
            "  inflating: dataset3/validation/problem-1082.txt  \n",
            "  inflating: dataset3/validation/problem-1083.txt  \n",
            "  inflating: dataset3/validation/problem-1084.txt  \n",
            "  inflating: dataset3/validation/problem-1085.txt  \n",
            "  inflating: dataset3/validation/problem-1086.txt  \n",
            "  inflating: dataset3/validation/problem-1087.txt  \n",
            "  inflating: dataset3/validation/problem-1088.txt  \n",
            "  inflating: dataset3/validation/problem-1089.txt  \n",
            "  inflating: dataset3/validation/problem-109.txt  \n",
            "  inflating: dataset3/validation/problem-1090.txt  \n",
            "  inflating: dataset3/validation/problem-1091.txt  \n",
            "  inflating: dataset3/validation/problem-1092.txt  \n",
            "  inflating: dataset3/validation/problem-1093.txt  \n",
            "  inflating: dataset3/validation/problem-1094.txt  \n",
            "  inflating: dataset3/validation/problem-1095.txt  \n",
            "  inflating: dataset3/validation/problem-1096.txt  \n",
            "  inflating: dataset3/validation/problem-1097.txt  \n",
            "  inflating: dataset3/validation/problem-1098.txt  \n",
            "  inflating: dataset3/validation/problem-1099.txt  \n",
            "  inflating: dataset3/validation/problem-11.txt  \n",
            "  inflating: dataset3/validation/problem-110.txt  \n",
            "  inflating: dataset3/validation/problem-1100.txt  \n",
            "  inflating: dataset3/validation/problem-1101.txt  \n",
            "  inflating: dataset3/validation/problem-1102.txt  \n",
            "  inflating: dataset3/validation/problem-1103.txt  \n",
            "  inflating: dataset3/validation/problem-1104.txt  \n",
            "  inflating: dataset3/validation/problem-1105.txt  \n",
            "  inflating: dataset3/validation/problem-1106.txt  \n",
            "  inflating: dataset3/validation/problem-1107.txt  \n",
            "  inflating: dataset3/validation/problem-1108.txt  \n",
            "  inflating: dataset3/validation/problem-1109.txt  \n",
            "  inflating: dataset3/validation/problem-111.txt  \n",
            "  inflating: dataset3/validation/problem-1110.txt  \n",
            "  inflating: dataset3/validation/problem-1111.txt  \n",
            "  inflating: dataset3/validation/problem-1112.txt  \n",
            "  inflating: dataset3/validation/problem-1113.txt  \n",
            "  inflating: dataset3/validation/problem-1114.txt  \n",
            "  inflating: dataset3/validation/problem-1115.txt  \n",
            "  inflating: dataset3/validation/problem-1116.txt  \n",
            "  inflating: dataset3/validation/problem-1117.txt  \n",
            "  inflating: dataset3/validation/problem-1118.txt  \n",
            "  inflating: dataset3/validation/problem-1119.txt  \n",
            "  inflating: dataset3/validation/problem-112.txt  \n",
            "  inflating: dataset3/validation/problem-1120.txt  \n",
            "  inflating: dataset3/validation/problem-1121.txt  \n",
            "  inflating: dataset3/validation/problem-1122.txt  \n",
            "  inflating: dataset3/validation/problem-1123.txt  \n",
            "  inflating: dataset3/validation/problem-1124.txt  \n",
            "  inflating: dataset3/validation/problem-1125.txt  \n",
            "  inflating: dataset3/validation/problem-1126.txt  \n",
            "  inflating: dataset3/validation/problem-1127.txt  \n",
            "  inflating: dataset3/validation/problem-1128.txt  \n",
            "  inflating: dataset3/validation/problem-1129.txt  \n",
            "  inflating: dataset3/validation/problem-113.txt  \n",
            "  inflating: dataset3/validation/problem-1130.txt  \n",
            "  inflating: dataset3/validation/problem-1131.txt  \n",
            "  inflating: dataset3/validation/problem-1132.txt  \n",
            "  inflating: dataset3/validation/problem-1133.txt  \n",
            "  inflating: dataset3/validation/problem-1134.txt  \n",
            "  inflating: dataset3/validation/problem-1135.txt  \n",
            "  inflating: dataset3/validation/problem-1136.txt  \n",
            "  inflating: dataset3/validation/problem-1137.txt  \n",
            "  inflating: dataset3/validation/problem-1138.txt  \n",
            "  inflating: dataset3/validation/problem-1139.txt  \n",
            "  inflating: dataset3/validation/problem-114.txt  \n",
            "  inflating: dataset3/validation/problem-1140.txt  \n",
            "  inflating: dataset3/validation/problem-1141.txt  \n",
            "  inflating: dataset3/validation/problem-1142.txt  \n",
            "  inflating: dataset3/validation/problem-1143.txt  \n",
            "  inflating: dataset3/validation/problem-1144.txt  \n",
            "  inflating: dataset3/validation/problem-1145.txt  \n",
            "  inflating: dataset3/validation/problem-1146.txt  \n",
            "  inflating: dataset3/validation/problem-1147.txt  \n",
            "  inflating: dataset3/validation/problem-1148.txt  \n",
            "  inflating: dataset3/validation/problem-1149.txt  \n",
            "  inflating: dataset3/validation/problem-115.txt  \n",
            "  inflating: dataset3/validation/problem-1150.txt  \n",
            "  inflating: dataset3/validation/problem-1151.txt  \n",
            "  inflating: dataset3/validation/problem-1152.txt  \n",
            "  inflating: dataset3/validation/problem-1153.txt  \n",
            "  inflating: dataset3/validation/problem-1154.txt  \n",
            "  inflating: dataset3/validation/problem-1155.txt  \n",
            "  inflating: dataset3/validation/problem-1156.txt  \n",
            "  inflating: dataset3/validation/problem-1157.txt  \n",
            "  inflating: dataset3/validation/problem-1158.txt  \n",
            "  inflating: dataset3/validation/problem-1159.txt  \n",
            "  inflating: dataset3/validation/problem-116.txt  \n",
            "  inflating: dataset3/validation/problem-1160.txt  \n",
            "  inflating: dataset3/validation/problem-1161.txt  \n",
            "  inflating: dataset3/validation/problem-1162.txt  \n",
            "  inflating: dataset3/validation/problem-1163.txt  \n",
            "  inflating: dataset3/validation/problem-1164.txt  \n",
            "  inflating: dataset3/validation/problem-1165.txt  \n",
            "  inflating: dataset3/validation/problem-1166.txt  \n",
            "  inflating: dataset3/validation/problem-1167.txt  \n",
            "  inflating: dataset3/validation/problem-1168.txt  \n",
            "  inflating: dataset3/validation/problem-1169.txt  \n",
            "  inflating: dataset3/validation/problem-117.txt  \n",
            "  inflating: dataset3/validation/problem-1170.txt  \n",
            "  inflating: dataset3/validation/problem-1171.txt  \n",
            "  inflating: dataset3/validation/problem-1172.txt  \n",
            "  inflating: dataset3/validation/problem-1173.txt  \n",
            "  inflating: dataset3/validation/problem-1174.txt  \n",
            "  inflating: dataset3/validation/problem-1175.txt  \n",
            "  inflating: dataset3/validation/problem-1176.txt  \n",
            "  inflating: dataset3/validation/problem-1177.txt  \n",
            "  inflating: dataset3/validation/problem-1178.txt  \n",
            "  inflating: dataset3/validation/problem-1179.txt  \n",
            "  inflating: dataset3/validation/problem-118.txt  \n",
            "  inflating: dataset3/validation/problem-1180.txt  \n",
            "  inflating: dataset3/validation/problem-1181.txt  \n",
            "  inflating: dataset3/validation/problem-1182.txt  \n",
            "  inflating: dataset3/validation/problem-1183.txt  \n",
            "  inflating: dataset3/validation/problem-1184.txt  \n",
            "  inflating: dataset3/validation/problem-1185.txt  \n",
            "  inflating: dataset3/validation/problem-1186.txt  \n",
            "  inflating: dataset3/validation/problem-1187.txt  \n",
            "  inflating: dataset3/validation/problem-1188.txt  \n",
            "  inflating: dataset3/validation/problem-1189.txt  \n",
            "  inflating: dataset3/validation/problem-119.txt  \n",
            "  inflating: dataset3/validation/problem-1190.txt  \n",
            "  inflating: dataset3/validation/problem-1191.txt  \n",
            "  inflating: dataset3/validation/problem-1192.txt  \n",
            "  inflating: dataset3/validation/problem-1193.txt  \n",
            "  inflating: dataset3/validation/problem-1194.txt  \n",
            "  inflating: dataset3/validation/problem-1195.txt  \n",
            "  inflating: dataset3/validation/problem-1196.txt  \n",
            "  inflating: dataset3/validation/problem-1197.txt  \n",
            "  inflating: dataset3/validation/problem-1198.txt  \n",
            "  inflating: dataset3/validation/problem-1199.txt  \n",
            "  inflating: dataset3/validation/problem-12.txt  \n",
            "  inflating: dataset3/validation/problem-120.txt  \n",
            "  inflating: dataset3/validation/problem-1200.txt  \n",
            "  inflating: dataset3/validation/problem-1201.txt  \n",
            "  inflating: dataset3/validation/problem-1202.txt  \n",
            "  inflating: dataset3/validation/problem-1203.txt  \n",
            "  inflating: dataset3/validation/problem-1204.txt  \n",
            "  inflating: dataset3/validation/problem-1205.txt  \n",
            "  inflating: dataset3/validation/problem-1206.txt  \n",
            "  inflating: dataset3/validation/problem-1207.txt  \n",
            "  inflating: dataset3/validation/problem-1208.txt  \n",
            "  inflating: dataset3/validation/problem-1209.txt  \n",
            "  inflating: dataset3/validation/problem-121.txt  \n",
            "  inflating: dataset3/validation/problem-1210.txt  \n",
            "  inflating: dataset3/validation/problem-1211.txt  \n",
            "  inflating: dataset3/validation/problem-1212.txt  \n",
            "  inflating: dataset3/validation/problem-1213.txt  \n",
            "  inflating: dataset3/validation/problem-1214.txt  \n",
            "  inflating: dataset3/validation/problem-1215.txt  \n",
            "  inflating: dataset3/validation/problem-1216.txt  \n",
            "  inflating: dataset3/validation/problem-1217.txt  \n",
            "  inflating: dataset3/validation/problem-1218.txt  \n",
            "  inflating: dataset3/validation/problem-1219.txt  \n",
            "  inflating: dataset3/validation/problem-122.txt  \n",
            "  inflating: dataset3/validation/problem-1220.txt  \n",
            "  inflating: dataset3/validation/problem-1221.txt  \n",
            "  inflating: dataset3/validation/problem-1222.txt  \n",
            "  inflating: dataset3/validation/problem-1223.txt  \n",
            "  inflating: dataset3/validation/problem-1224.txt  \n",
            "  inflating: dataset3/validation/problem-1225.txt  \n",
            "  inflating: dataset3/validation/problem-1226.txt  \n",
            "  inflating: dataset3/validation/problem-1227.txt  \n",
            "  inflating: dataset3/validation/problem-1228.txt  \n",
            "  inflating: dataset3/validation/problem-1229.txt  \n",
            "  inflating: dataset3/validation/problem-123.txt  \n",
            "  inflating: dataset3/validation/problem-1230.txt  \n",
            "  inflating: dataset3/validation/problem-1231.txt  \n",
            "  inflating: dataset3/validation/problem-1232.txt  \n",
            "  inflating: dataset3/validation/problem-1233.txt  \n",
            "  inflating: dataset3/validation/problem-1234.txt  \n",
            "  inflating: dataset3/validation/problem-1235.txt  \n",
            "  inflating: dataset3/validation/problem-1236.txt  \n",
            "  inflating: dataset3/validation/problem-1237.txt  \n",
            "  inflating: dataset3/validation/problem-1238.txt  \n",
            "  inflating: dataset3/validation/problem-1239.txt  \n",
            "  inflating: dataset3/validation/problem-124.txt  \n",
            "  inflating: dataset3/validation/problem-1240.txt  \n",
            "  inflating: dataset3/validation/problem-1241.txt  \n",
            "  inflating: dataset3/validation/problem-1242.txt  \n",
            "  inflating: dataset3/validation/problem-1243.txt  \n",
            "  inflating: dataset3/validation/problem-1244.txt  \n",
            "  inflating: dataset3/validation/problem-1245.txt  \n",
            "  inflating: dataset3/validation/problem-1246.txt  \n",
            "  inflating: dataset3/validation/problem-1247.txt  \n",
            "  inflating: dataset3/validation/problem-1248.txt  \n",
            "  inflating: dataset3/validation/problem-1249.txt  \n",
            "  inflating: dataset3/validation/problem-125.txt  \n",
            "  inflating: dataset3/validation/problem-1250.txt  \n",
            "  inflating: dataset3/validation/problem-1251.txt  \n",
            "  inflating: dataset3/validation/problem-1252.txt  \n",
            "  inflating: dataset3/validation/problem-1253.txt  \n",
            "  inflating: dataset3/validation/problem-1254.txt  \n",
            "  inflating: dataset3/validation/problem-1255.txt  \n",
            "  inflating: dataset3/validation/problem-1256.txt  \n",
            "  inflating: dataset3/validation/problem-1257.txt  \n",
            "  inflating: dataset3/validation/problem-1258.txt  \n",
            "  inflating: dataset3/validation/problem-1259.txt  \n",
            "  inflating: dataset3/validation/problem-126.txt  \n",
            "  inflating: dataset3/validation/problem-1260.txt  \n",
            "  inflating: dataset3/validation/problem-1261.txt  \n",
            "  inflating: dataset3/validation/problem-1262.txt  \n",
            "  inflating: dataset3/validation/problem-1263.txt  \n",
            "  inflating: dataset3/validation/problem-1264.txt  \n",
            "  inflating: dataset3/validation/problem-1265.txt  \n",
            "  inflating: dataset3/validation/problem-1266.txt  \n",
            "  inflating: dataset3/validation/problem-1267.txt  \n",
            "  inflating: dataset3/validation/problem-1268.txt  \n",
            "  inflating: dataset3/validation/problem-1269.txt  \n",
            "  inflating: dataset3/validation/problem-127.txt  \n",
            "  inflating: dataset3/validation/problem-1270.txt  \n",
            "  inflating: dataset3/validation/problem-1271.txt  \n",
            "  inflating: dataset3/validation/problem-1272.txt  \n",
            "  inflating: dataset3/validation/problem-1273.txt  \n",
            "  inflating: dataset3/validation/problem-1274.txt  \n",
            "  inflating: dataset3/validation/problem-1275.txt  \n",
            "  inflating: dataset3/validation/problem-1276.txt  \n",
            "  inflating: dataset3/validation/problem-1277.txt  \n",
            "  inflating: dataset3/validation/problem-1278.txt  \n",
            "  inflating: dataset3/validation/problem-1279.txt  \n",
            "  inflating: dataset3/validation/problem-128.txt  \n",
            "  inflating: dataset3/validation/problem-1280.txt  \n",
            "  inflating: dataset3/validation/problem-1281.txt  \n",
            "  inflating: dataset3/validation/problem-1282.txt  \n",
            "  inflating: dataset3/validation/problem-1283.txt  \n",
            "  inflating: dataset3/validation/problem-1284.txt  \n",
            "  inflating: dataset3/validation/problem-1285.txt  \n",
            "  inflating: dataset3/validation/problem-1286.txt  \n",
            "  inflating: dataset3/validation/problem-1287.txt  \n",
            "  inflating: dataset3/validation/problem-1288.txt  \n",
            "  inflating: dataset3/validation/problem-1289.txt  \n",
            "  inflating: dataset3/validation/problem-129.txt  \n",
            "  inflating: dataset3/validation/problem-1290.txt  \n",
            "  inflating: dataset3/validation/problem-1291.txt  \n",
            "  inflating: dataset3/validation/problem-1292.txt  \n",
            "  inflating: dataset3/validation/problem-1293.txt  \n",
            "  inflating: dataset3/validation/problem-1294.txt  \n",
            "  inflating: dataset3/validation/problem-1295.txt  \n",
            "  inflating: dataset3/validation/problem-1296.txt  \n",
            "  inflating: dataset3/validation/problem-1297.txt  \n",
            "  inflating: dataset3/validation/problem-1298.txt  \n",
            "  inflating: dataset3/validation/problem-1299.txt  \n",
            "  inflating: dataset3/validation/problem-13.txt  \n",
            "  inflating: dataset3/validation/problem-130.txt  \n",
            "  inflating: dataset3/validation/problem-1300.txt  \n",
            "  inflating: dataset3/validation/problem-1301.txt  \n",
            "  inflating: dataset3/validation/problem-1302.txt  \n",
            "  inflating: dataset3/validation/problem-1303.txt  \n",
            "  inflating: dataset3/validation/problem-1304.txt  \n",
            "  inflating: dataset3/validation/problem-1305.txt  \n",
            "  inflating: dataset3/validation/problem-1306.txt  \n",
            "  inflating: dataset3/validation/problem-1307.txt  \n",
            "  inflating: dataset3/validation/problem-1308.txt  \n",
            "  inflating: dataset3/validation/problem-1309.txt  \n",
            "  inflating: dataset3/validation/problem-131.txt  \n",
            "  inflating: dataset3/validation/problem-1310.txt  \n",
            "  inflating: dataset3/validation/problem-1311.txt  \n",
            "  inflating: dataset3/validation/problem-1312.txt  \n",
            "  inflating: dataset3/validation/problem-1313.txt  \n",
            "  inflating: dataset3/validation/problem-1314.txt  \n",
            "  inflating: dataset3/validation/problem-1315.txt  \n",
            "  inflating: dataset3/validation/problem-1316.txt  \n",
            "  inflating: dataset3/validation/problem-1317.txt  \n",
            "  inflating: dataset3/validation/problem-1318.txt  \n",
            "  inflating: dataset3/validation/problem-1319.txt  \n",
            "  inflating: dataset3/validation/problem-132.txt  \n",
            "  inflating: dataset3/validation/problem-1320.txt  \n",
            "  inflating: dataset3/validation/problem-1321.txt  \n",
            "  inflating: dataset3/validation/problem-1322.txt  \n",
            "  inflating: dataset3/validation/problem-1323.txt  \n",
            "  inflating: dataset3/validation/problem-1324.txt  \n",
            "  inflating: dataset3/validation/problem-1325.txt  \n",
            "  inflating: dataset3/validation/problem-1326.txt  \n",
            "  inflating: dataset3/validation/problem-1327.txt  \n",
            "  inflating: dataset3/validation/problem-1328.txt  \n",
            "  inflating: dataset3/validation/problem-1329.txt  \n",
            "  inflating: dataset3/validation/problem-133.txt  \n",
            "  inflating: dataset3/validation/problem-1330.txt  \n",
            "  inflating: dataset3/validation/problem-1331.txt  \n",
            "  inflating: dataset3/validation/problem-1332.txt  \n",
            "  inflating: dataset3/validation/problem-1333.txt  \n",
            "  inflating: dataset3/validation/problem-1334.txt  \n",
            "  inflating: dataset3/validation/problem-1335.txt  \n",
            "  inflating: dataset3/validation/problem-1336.txt  \n",
            "  inflating: dataset3/validation/problem-1337.txt  \n",
            "  inflating: dataset3/validation/problem-1338.txt  \n",
            "  inflating: dataset3/validation/problem-1339.txt  \n",
            "  inflating: dataset3/validation/problem-134.txt  \n",
            "  inflating: dataset3/validation/problem-1340.txt  \n",
            "  inflating: dataset3/validation/problem-1341.txt  \n",
            "  inflating: dataset3/validation/problem-1342.txt  \n",
            "  inflating: dataset3/validation/problem-1343.txt  \n",
            "  inflating: dataset3/validation/problem-1344.txt  \n",
            "  inflating: dataset3/validation/problem-1345.txt  \n",
            "  inflating: dataset3/validation/problem-1346.txt  \n",
            "  inflating: dataset3/validation/problem-1347.txt  \n",
            "  inflating: dataset3/validation/problem-1348.txt  \n",
            "  inflating: dataset3/validation/problem-1349.txt  \n",
            "  inflating: dataset3/validation/problem-135.txt  \n",
            "  inflating: dataset3/validation/problem-1350.txt  \n",
            "  inflating: dataset3/validation/problem-1351.txt  \n",
            "  inflating: dataset3/validation/problem-1352.txt  \n",
            "  inflating: dataset3/validation/problem-1353.txt  \n",
            "  inflating: dataset3/validation/problem-1354.txt  \n",
            "  inflating: dataset3/validation/problem-1355.txt  \n",
            "  inflating: dataset3/validation/problem-1356.txt  \n",
            "  inflating: dataset3/validation/problem-1357.txt  \n",
            "  inflating: dataset3/validation/problem-1358.txt  \n",
            "  inflating: dataset3/validation/problem-1359.txt  \n",
            "  inflating: dataset3/validation/problem-136.txt  \n",
            "  inflating: dataset3/validation/problem-1360.txt  \n",
            "  inflating: dataset3/validation/problem-1361.txt  \n",
            "  inflating: dataset3/validation/problem-1362.txt  \n",
            "  inflating: dataset3/validation/problem-1363.txt  \n",
            "  inflating: dataset3/validation/problem-1364.txt  \n",
            "  inflating: dataset3/validation/problem-1365.txt  \n",
            "  inflating: dataset3/validation/problem-1366.txt  \n",
            "  inflating: dataset3/validation/problem-1367.txt  \n",
            "  inflating: dataset3/validation/problem-1368.txt  \n",
            "  inflating: dataset3/validation/problem-1369.txt  \n",
            "  inflating: dataset3/validation/problem-137.txt  \n",
            "  inflating: dataset3/validation/problem-1370.txt  \n",
            "  inflating: dataset3/validation/problem-1371.txt  \n",
            "  inflating: dataset3/validation/problem-1372.txt  \n",
            "  inflating: dataset3/validation/problem-1373.txt  \n",
            "  inflating: dataset3/validation/problem-1374.txt  \n",
            "  inflating: dataset3/validation/problem-1375.txt  \n",
            "  inflating: dataset3/validation/problem-1376.txt  \n",
            "  inflating: dataset3/validation/problem-1377.txt  \n",
            "  inflating: dataset3/validation/problem-1378.txt  \n",
            "  inflating: dataset3/validation/problem-1379.txt  \n",
            "  inflating: dataset3/validation/problem-138.txt  \n",
            "  inflating: dataset3/validation/problem-1380.txt  \n",
            "  inflating: dataset3/validation/problem-1381.txt  \n",
            "  inflating: dataset3/validation/problem-1382.txt  \n",
            "  inflating: dataset3/validation/problem-1383.txt  \n",
            "  inflating: dataset3/validation/problem-1384.txt  \n",
            "  inflating: dataset3/validation/problem-1385.txt  \n",
            "  inflating: dataset3/validation/problem-1386.txt  \n",
            "  inflating: dataset3/validation/problem-1387.txt  \n",
            "  inflating: dataset3/validation/problem-1388.txt  \n",
            "  inflating: dataset3/validation/problem-1389.txt  \n",
            "  inflating: dataset3/validation/problem-139.txt  \n",
            "  inflating: dataset3/validation/problem-1390.txt  \n",
            "  inflating: dataset3/validation/problem-1391.txt  \n",
            "  inflating: dataset3/validation/problem-1392.txt  \n",
            "  inflating: dataset3/validation/problem-1393.txt  \n",
            "  inflating: dataset3/validation/problem-1394.txt  \n",
            "  inflating: dataset3/validation/problem-1395.txt  \n",
            "  inflating: dataset3/validation/problem-1396.txt  \n",
            "  inflating: dataset3/validation/problem-1397.txt  \n",
            "  inflating: dataset3/validation/problem-1398.txt  \n",
            "  inflating: dataset3/validation/problem-1399.txt  \n",
            "  inflating: dataset3/validation/problem-14.txt  \n",
            "  inflating: dataset3/validation/problem-140.txt  \n",
            "  inflating: dataset3/validation/problem-1400.txt  \n",
            "  inflating: dataset3/validation/problem-1401.txt  \n",
            "  inflating: dataset3/validation/problem-1402.txt  \n",
            "  inflating: dataset3/validation/problem-1403.txt  \n",
            "  inflating: dataset3/validation/problem-1404.txt  \n",
            "  inflating: dataset3/validation/problem-1405.txt  \n",
            "  inflating: dataset3/validation/problem-1406.txt  \n",
            "  inflating: dataset3/validation/problem-1407.txt  \n",
            "  inflating: dataset3/validation/problem-1408.txt  \n",
            "  inflating: dataset3/validation/problem-1409.txt  \n",
            "  inflating: dataset3/validation/problem-141.txt  \n",
            "  inflating: dataset3/validation/problem-1410.txt  \n",
            "  inflating: dataset3/validation/problem-1411.txt  \n",
            "  inflating: dataset3/validation/problem-1412.txt  \n",
            "  inflating: dataset3/validation/problem-1413.txt  \n",
            "  inflating: dataset3/validation/problem-1414.txt  \n",
            "  inflating: dataset3/validation/problem-1415.txt  \n",
            "  inflating: dataset3/validation/problem-1416.txt  \n",
            "  inflating: dataset3/validation/problem-1417.txt  \n",
            "  inflating: dataset3/validation/problem-1418.txt  \n",
            "  inflating: dataset3/validation/problem-1419.txt  \n",
            "  inflating: dataset3/validation/problem-142.txt  \n",
            "  inflating: dataset3/validation/problem-1420.txt  \n",
            "  inflating: dataset3/validation/problem-1421.txt  \n",
            "  inflating: dataset3/validation/problem-1422.txt  \n",
            "  inflating: dataset3/validation/problem-1423.txt  \n",
            "  inflating: dataset3/validation/problem-1424.txt  \n",
            "  inflating: dataset3/validation/problem-1425.txt  \n",
            "  inflating: dataset3/validation/problem-1426.txt  \n",
            "  inflating: dataset3/validation/problem-1427.txt  \n",
            "  inflating: dataset3/validation/problem-1428.txt  \n",
            "  inflating: dataset3/validation/problem-1429.txt  \n",
            "  inflating: dataset3/validation/problem-143.txt  \n",
            "  inflating: dataset3/validation/problem-1430.txt  \n",
            "  inflating: dataset3/validation/problem-1431.txt  \n",
            "  inflating: dataset3/validation/problem-1432.txt  \n",
            "  inflating: dataset3/validation/problem-1433.txt  \n",
            "  inflating: dataset3/validation/problem-1434.txt  \n",
            "  inflating: dataset3/validation/problem-1435.txt  \n",
            "  inflating: dataset3/validation/problem-1436.txt  \n",
            "  inflating: dataset3/validation/problem-1437.txt  \n",
            "  inflating: dataset3/validation/problem-1438.txt  \n",
            "  inflating: dataset3/validation/problem-1439.txt  \n",
            "  inflating: dataset3/validation/problem-144.txt  \n",
            "  inflating: dataset3/validation/problem-1440.txt  \n",
            "  inflating: dataset3/validation/problem-1441.txt  \n",
            "  inflating: dataset3/validation/problem-1442.txt  \n",
            "  inflating: dataset3/validation/problem-1443.txt  \n",
            "  inflating: dataset3/validation/problem-1444.txt  \n",
            "  inflating: dataset3/validation/problem-1445.txt  \n",
            "  inflating: dataset3/validation/problem-1446.txt  \n",
            "  inflating: dataset3/validation/problem-1447.txt  \n",
            "  inflating: dataset3/validation/problem-1448.txt  \n",
            "  inflating: dataset3/validation/problem-1449.txt  \n",
            "  inflating: dataset3/validation/problem-145.txt  \n",
            "  inflating: dataset3/validation/problem-1450.txt  \n",
            "  inflating: dataset3/validation/problem-1451.txt  \n",
            "  inflating: dataset3/validation/problem-1452.txt  \n",
            "  inflating: dataset3/validation/problem-1453.txt  \n",
            "  inflating: dataset3/validation/problem-1454.txt  \n",
            "  inflating: dataset3/validation/problem-1455.txt  \n",
            "  inflating: dataset3/validation/problem-1456.txt  \n",
            "  inflating: dataset3/validation/problem-1457.txt  \n",
            "  inflating: dataset3/validation/problem-1458.txt  \n",
            "  inflating: dataset3/validation/problem-1459.txt  \n",
            "  inflating: dataset3/validation/problem-146.txt  \n",
            "  inflating: dataset3/validation/problem-1460.txt  \n",
            "  inflating: dataset3/validation/problem-1461.txt  \n",
            "  inflating: dataset3/validation/problem-1462.txt  \n",
            "  inflating: dataset3/validation/problem-1463.txt  \n",
            "  inflating: dataset3/validation/problem-1464.txt  \n",
            "  inflating: dataset3/validation/problem-1465.txt  \n",
            "  inflating: dataset3/validation/problem-1466.txt  \n",
            "  inflating: dataset3/validation/problem-1467.txt  \n",
            "  inflating: dataset3/validation/problem-1468.txt  \n",
            "  inflating: dataset3/validation/problem-1469.txt  \n",
            "  inflating: dataset3/validation/problem-147.txt  \n",
            "  inflating: dataset3/validation/problem-1470.txt  \n",
            "  inflating: dataset3/validation/problem-1471.txt  \n",
            "  inflating: dataset3/validation/problem-1472.txt  \n",
            "  inflating: dataset3/validation/problem-1473.txt  \n",
            "  inflating: dataset3/validation/problem-1474.txt  \n",
            "  inflating: dataset3/validation/problem-1475.txt  \n",
            "  inflating: dataset3/validation/problem-1476.txt  \n",
            "  inflating: dataset3/validation/problem-1477.txt  \n",
            "  inflating: dataset3/validation/problem-1478.txt  \n",
            "  inflating: dataset3/validation/problem-1479.txt  \n",
            "  inflating: dataset3/validation/problem-148.txt  \n",
            "  inflating: dataset3/validation/problem-1480.txt  \n",
            "  inflating: dataset3/validation/problem-1481.txt  \n",
            "  inflating: dataset3/validation/problem-1482.txt  \n",
            "  inflating: dataset3/validation/problem-1483.txt  \n",
            "  inflating: dataset3/validation/problem-1484.txt  \n",
            "  inflating: dataset3/validation/problem-1485.txt  \n",
            "  inflating: dataset3/validation/problem-1486.txt  \n",
            "  inflating: dataset3/validation/problem-1487.txt  \n",
            "  inflating: dataset3/validation/problem-1488.txt  \n",
            "  inflating: dataset3/validation/problem-1489.txt  \n",
            "  inflating: dataset3/validation/problem-149.txt  \n",
            "  inflating: dataset3/validation/problem-1490.txt  \n",
            "  inflating: dataset3/validation/problem-1491.txt  \n",
            "  inflating: dataset3/validation/problem-1492.txt  \n",
            "  inflating: dataset3/validation/problem-1493.txt  \n",
            "  inflating: dataset3/validation/problem-1494.txt  \n",
            "  inflating: dataset3/validation/problem-1495.txt  \n",
            "  inflating: dataset3/validation/problem-1496.txt  \n",
            "  inflating: dataset3/validation/problem-1497.txt  \n",
            "  inflating: dataset3/validation/problem-1498.txt  \n",
            "  inflating: dataset3/validation/problem-1499.txt  \n",
            "  inflating: dataset3/validation/problem-15.txt  \n",
            "  inflating: dataset3/validation/problem-150.txt  \n",
            "  inflating: dataset3/validation/problem-1500.txt  \n",
            "  inflating: dataset3/validation/problem-151.txt  \n",
            "  inflating: dataset3/validation/problem-152.txt  \n",
            "  inflating: dataset3/validation/problem-153.txt  \n",
            "  inflating: dataset3/validation/problem-154.txt  \n",
            "  inflating: dataset3/validation/problem-155.txt  \n",
            "  inflating: dataset3/validation/problem-156.txt  \n",
            "  inflating: dataset3/validation/problem-157.txt  \n",
            "  inflating: dataset3/validation/problem-158.txt  \n",
            "  inflating: dataset3/validation/problem-159.txt  \n",
            "  inflating: dataset3/validation/problem-16.txt  \n",
            "  inflating: dataset3/validation/problem-160.txt  \n",
            "  inflating: dataset3/validation/problem-161.txt  \n",
            "  inflating: dataset3/validation/problem-162.txt  \n",
            "  inflating: dataset3/validation/problem-163.txt  \n",
            "  inflating: dataset3/validation/problem-164.txt  \n",
            "  inflating: dataset3/validation/problem-165.txt  \n",
            "  inflating: dataset3/validation/problem-166.txt  \n",
            "  inflating: dataset3/validation/problem-167.txt  \n",
            "  inflating: dataset3/validation/problem-168.txt  \n",
            "  inflating: dataset3/validation/problem-169.txt  \n",
            "  inflating: dataset3/validation/problem-17.txt  \n",
            "  inflating: dataset3/validation/problem-170.txt  \n",
            "  inflating: dataset3/validation/problem-171.txt  \n",
            "  inflating: dataset3/validation/problem-172.txt  \n",
            "  inflating: dataset3/validation/problem-173.txt  \n",
            "  inflating: dataset3/validation/problem-174.txt  \n",
            "  inflating: dataset3/validation/problem-175.txt  \n",
            "  inflating: dataset3/validation/problem-176.txt  \n",
            "  inflating: dataset3/validation/problem-177.txt  \n",
            "  inflating: dataset3/validation/problem-178.txt  \n",
            "  inflating: dataset3/validation/problem-179.txt  \n",
            "  inflating: dataset3/validation/problem-18.txt  \n",
            "  inflating: dataset3/validation/problem-180.txt  \n",
            "  inflating: dataset3/validation/problem-181.txt  \n",
            "  inflating: dataset3/validation/problem-182.txt  \n",
            "  inflating: dataset3/validation/problem-183.txt  \n",
            "  inflating: dataset3/validation/problem-184.txt  \n",
            "  inflating: dataset3/validation/problem-185.txt  \n",
            "  inflating: dataset3/validation/problem-186.txt  \n",
            "  inflating: dataset3/validation/problem-187.txt  \n",
            "  inflating: dataset3/validation/problem-188.txt  \n",
            "  inflating: dataset3/validation/problem-189.txt  \n",
            "  inflating: dataset3/validation/problem-19.txt  \n",
            "  inflating: dataset3/validation/problem-190.txt  \n",
            "  inflating: dataset3/validation/problem-191.txt  \n",
            "  inflating: dataset3/validation/problem-192.txt  \n",
            "  inflating: dataset3/validation/problem-193.txt  \n",
            "  inflating: dataset3/validation/problem-194.txt  \n",
            "  inflating: dataset3/validation/problem-195.txt  \n",
            "  inflating: dataset3/validation/problem-196.txt  \n",
            "  inflating: dataset3/validation/problem-197.txt  \n",
            "  inflating: dataset3/validation/problem-198.txt  \n",
            "  inflating: dataset3/validation/problem-199.txt  \n",
            "  inflating: dataset3/validation/problem-2.txt  \n",
            "  inflating: dataset3/validation/problem-20.txt  \n",
            "  inflating: dataset3/validation/problem-200.txt  \n",
            "  inflating: dataset3/validation/problem-201.txt  \n",
            "  inflating: dataset3/validation/problem-202.txt  \n",
            "  inflating: dataset3/validation/problem-203.txt  \n",
            "  inflating: dataset3/validation/problem-204.txt  \n",
            "  inflating: dataset3/validation/problem-205.txt  \n",
            "  inflating: dataset3/validation/problem-206.txt  \n",
            "  inflating: dataset3/validation/problem-207.txt  \n",
            "  inflating: dataset3/validation/problem-208.txt  \n",
            "  inflating: dataset3/validation/problem-209.txt  \n",
            "  inflating: dataset3/validation/problem-21.txt  \n",
            "  inflating: dataset3/validation/problem-210.txt  \n",
            "  inflating: dataset3/validation/problem-211.txt  \n",
            "  inflating: dataset3/validation/problem-212.txt  \n",
            "  inflating: dataset3/validation/problem-213.txt  \n",
            "  inflating: dataset3/validation/problem-214.txt  \n",
            "  inflating: dataset3/validation/problem-215.txt  \n",
            "  inflating: dataset3/validation/problem-216.txt  \n",
            "  inflating: dataset3/validation/problem-217.txt  \n",
            "  inflating: dataset3/validation/problem-218.txt  \n",
            "  inflating: dataset3/validation/problem-219.txt  \n",
            "  inflating: dataset3/validation/problem-22.txt  \n",
            "  inflating: dataset3/validation/problem-220.txt  \n",
            "  inflating: dataset3/validation/problem-221.txt  \n",
            "  inflating: dataset3/validation/problem-222.txt  \n",
            "  inflating: dataset3/validation/problem-223.txt  \n",
            "  inflating: dataset3/validation/problem-224.txt  \n",
            "  inflating: dataset3/validation/problem-225.txt  \n",
            "  inflating: dataset3/validation/problem-226.txt  \n",
            "  inflating: dataset3/validation/problem-227.txt  \n",
            "  inflating: dataset3/validation/problem-228.txt  \n",
            "  inflating: dataset3/validation/problem-229.txt  \n",
            "  inflating: dataset3/validation/problem-23.txt  \n",
            "  inflating: dataset3/validation/problem-230.txt  \n",
            "  inflating: dataset3/validation/problem-231.txt  \n",
            "  inflating: dataset3/validation/problem-232.txt  \n",
            "  inflating: dataset3/validation/problem-233.txt  \n",
            "  inflating: dataset3/validation/problem-234.txt  \n",
            "  inflating: dataset3/validation/problem-235.txt  \n",
            "  inflating: dataset3/validation/problem-236.txt  \n",
            "  inflating: dataset3/validation/problem-237.txt  \n",
            "  inflating: dataset3/validation/problem-238.txt  \n",
            "  inflating: dataset3/validation/problem-239.txt  \n",
            "  inflating: dataset3/validation/problem-24.txt  \n",
            "  inflating: dataset3/validation/problem-240.txt  \n",
            "  inflating: dataset3/validation/problem-241.txt  \n",
            "  inflating: dataset3/validation/problem-242.txt  \n",
            "  inflating: dataset3/validation/problem-243.txt  \n",
            "  inflating: dataset3/validation/problem-244.txt  \n",
            "  inflating: dataset3/validation/problem-245.txt  \n",
            "  inflating: dataset3/validation/problem-246.txt  \n",
            "  inflating: dataset3/validation/problem-247.txt  \n",
            "  inflating: dataset3/validation/problem-248.txt  \n",
            "  inflating: dataset3/validation/problem-249.txt  \n",
            "  inflating: dataset3/validation/problem-25.txt  \n",
            "  inflating: dataset3/validation/problem-250.txt  \n",
            "  inflating: dataset3/validation/problem-251.txt  \n",
            "  inflating: dataset3/validation/problem-252.txt  \n",
            "  inflating: dataset3/validation/problem-253.txt  \n",
            "  inflating: dataset3/validation/problem-254.txt  \n",
            "  inflating: dataset3/validation/problem-255.txt  \n",
            "  inflating: dataset3/validation/problem-256.txt  \n",
            "  inflating: dataset3/validation/problem-257.txt  \n",
            "  inflating: dataset3/validation/problem-258.txt  \n",
            "  inflating: dataset3/validation/problem-259.txt  \n",
            "  inflating: dataset3/validation/problem-26.txt  \n",
            "  inflating: dataset3/validation/problem-260.txt  \n",
            "  inflating: dataset3/validation/problem-261.txt  \n",
            "  inflating: dataset3/validation/problem-262.txt  \n",
            "  inflating: dataset3/validation/problem-263.txt  \n",
            "  inflating: dataset3/validation/problem-264.txt  \n",
            "  inflating: dataset3/validation/problem-265.txt  \n",
            "  inflating: dataset3/validation/problem-266.txt  \n",
            "  inflating: dataset3/validation/problem-267.txt  \n",
            "  inflating: dataset3/validation/problem-268.txt  \n",
            "  inflating: dataset3/validation/problem-269.txt  \n",
            "  inflating: dataset3/validation/problem-27.txt  \n",
            "  inflating: dataset3/validation/problem-270.txt  \n",
            "  inflating: dataset3/validation/problem-271.txt  \n",
            "  inflating: dataset3/validation/problem-272.txt  \n",
            "  inflating: dataset3/validation/problem-273.txt  \n",
            "  inflating: dataset3/validation/problem-274.txt  \n",
            "  inflating: dataset3/validation/problem-275.txt  \n",
            "  inflating: dataset3/validation/problem-276.txt  \n",
            "  inflating: dataset3/validation/problem-277.txt  \n",
            "  inflating: dataset3/validation/problem-278.txt  \n",
            "  inflating: dataset3/validation/problem-279.txt  \n",
            "  inflating: dataset3/validation/problem-28.txt  \n",
            "  inflating: dataset3/validation/problem-280.txt  \n",
            "  inflating: dataset3/validation/problem-281.txt  \n",
            "  inflating: dataset3/validation/problem-282.txt  \n",
            "  inflating: dataset3/validation/problem-283.txt  \n",
            "  inflating: dataset3/validation/problem-284.txt  \n",
            "  inflating: dataset3/validation/problem-285.txt  \n",
            "  inflating: dataset3/validation/problem-286.txt  \n",
            "  inflating: dataset3/validation/problem-287.txt  \n",
            "  inflating: dataset3/validation/problem-288.txt  \n",
            "  inflating: dataset3/validation/problem-289.txt  \n",
            "  inflating: dataset3/validation/problem-29.txt  \n",
            "  inflating: dataset3/validation/problem-290.txt  \n",
            "  inflating: dataset3/validation/problem-291.txt  \n",
            "  inflating: dataset3/validation/problem-292.txt  \n",
            "  inflating: dataset3/validation/problem-293.txt  \n",
            "  inflating: dataset3/validation/problem-294.txt  \n",
            "  inflating: dataset3/validation/problem-295.txt  \n",
            "  inflating: dataset3/validation/problem-296.txt  \n",
            "  inflating: dataset3/validation/problem-297.txt  \n",
            "  inflating: dataset3/validation/problem-298.txt  \n",
            "  inflating: dataset3/validation/problem-299.txt  \n",
            "  inflating: dataset3/validation/problem-3.txt  \n",
            "  inflating: dataset3/validation/problem-30.txt  \n",
            "  inflating: dataset3/validation/problem-300.txt  \n",
            "  inflating: dataset3/validation/problem-301.txt  \n",
            "  inflating: dataset3/validation/problem-302.txt  \n",
            "  inflating: dataset3/validation/problem-303.txt  \n",
            "  inflating: dataset3/validation/problem-304.txt  \n",
            "  inflating: dataset3/validation/problem-305.txt  \n",
            "  inflating: dataset3/validation/problem-306.txt  \n",
            "  inflating: dataset3/validation/problem-307.txt  \n",
            "  inflating: dataset3/validation/problem-308.txt  \n",
            "  inflating: dataset3/validation/problem-309.txt  \n",
            "  inflating: dataset3/validation/problem-31.txt  \n",
            "  inflating: dataset3/validation/problem-310.txt  \n",
            "  inflating: dataset3/validation/problem-311.txt  \n",
            "  inflating: dataset3/validation/problem-312.txt  \n",
            "  inflating: dataset3/validation/problem-313.txt  \n",
            "  inflating: dataset3/validation/problem-314.txt  \n",
            "  inflating: dataset3/validation/problem-315.txt  \n",
            "  inflating: dataset3/validation/problem-316.txt  \n",
            "  inflating: dataset3/validation/problem-317.txt  \n",
            "  inflating: dataset3/validation/problem-318.txt  \n",
            "  inflating: dataset3/validation/problem-319.txt  \n",
            "  inflating: dataset3/validation/problem-32.txt  \n",
            "  inflating: dataset3/validation/problem-320.txt  \n",
            "  inflating: dataset3/validation/problem-321.txt  \n",
            "  inflating: dataset3/validation/problem-322.txt  \n",
            "  inflating: dataset3/validation/problem-323.txt  \n",
            "  inflating: dataset3/validation/problem-324.txt  \n",
            "  inflating: dataset3/validation/problem-325.txt  \n",
            "  inflating: dataset3/validation/problem-326.txt  \n",
            "  inflating: dataset3/validation/problem-327.txt  \n",
            "  inflating: dataset3/validation/problem-328.txt  \n",
            "  inflating: dataset3/validation/problem-329.txt  \n",
            "  inflating: dataset3/validation/problem-33.txt  \n",
            "  inflating: dataset3/validation/problem-330.txt  \n",
            "  inflating: dataset3/validation/problem-331.txt  \n",
            "  inflating: dataset3/validation/problem-332.txt  \n",
            "  inflating: dataset3/validation/problem-333.txt  \n",
            "  inflating: dataset3/validation/problem-334.txt  \n",
            "  inflating: dataset3/validation/problem-335.txt  \n",
            "  inflating: dataset3/validation/problem-336.txt  \n",
            "  inflating: dataset3/validation/problem-337.txt  \n",
            "  inflating: dataset3/validation/problem-338.txt  \n",
            "  inflating: dataset3/validation/problem-339.txt  \n",
            "  inflating: dataset3/validation/problem-34.txt  \n",
            "  inflating: dataset3/validation/problem-340.txt  \n",
            "  inflating: dataset3/validation/problem-341.txt  \n",
            "  inflating: dataset3/validation/problem-342.txt  \n",
            "  inflating: dataset3/validation/problem-343.txt  \n",
            "  inflating: dataset3/validation/problem-344.txt  \n",
            "  inflating: dataset3/validation/problem-345.txt  \n",
            "  inflating: dataset3/validation/problem-346.txt  \n",
            "  inflating: dataset3/validation/problem-347.txt  \n",
            "  inflating: dataset3/validation/problem-348.txt  \n",
            "  inflating: dataset3/validation/problem-349.txt  \n",
            "  inflating: dataset3/validation/problem-35.txt  \n",
            "  inflating: dataset3/validation/problem-350.txt  \n",
            "  inflating: dataset3/validation/problem-351.txt  \n",
            "  inflating: dataset3/validation/problem-352.txt  \n",
            "  inflating: dataset3/validation/problem-353.txt  \n",
            "  inflating: dataset3/validation/problem-354.txt  \n",
            "  inflating: dataset3/validation/problem-355.txt  \n",
            "  inflating: dataset3/validation/problem-356.txt  \n",
            "  inflating: dataset3/validation/problem-357.txt  \n",
            "  inflating: dataset3/validation/problem-358.txt  \n",
            "  inflating: dataset3/validation/problem-359.txt  \n",
            "  inflating: dataset3/validation/problem-36.txt  \n",
            "  inflating: dataset3/validation/problem-360.txt  \n",
            "  inflating: dataset3/validation/problem-361.txt  \n",
            "  inflating: dataset3/validation/problem-362.txt  \n",
            "  inflating: dataset3/validation/problem-363.txt  \n",
            "  inflating: dataset3/validation/problem-364.txt  \n",
            "  inflating: dataset3/validation/problem-365.txt  \n",
            "  inflating: dataset3/validation/problem-366.txt  \n",
            "  inflating: dataset3/validation/problem-367.txt  \n",
            "  inflating: dataset3/validation/problem-368.txt  \n",
            "  inflating: dataset3/validation/problem-369.txt  \n",
            "  inflating: dataset3/validation/problem-37.txt  \n",
            "  inflating: dataset3/validation/problem-370.txt  \n",
            "  inflating: dataset3/validation/problem-371.txt  \n",
            "  inflating: dataset3/validation/problem-372.txt  \n",
            "  inflating: dataset3/validation/problem-373.txt  \n",
            "  inflating: dataset3/validation/problem-374.txt  \n",
            "  inflating: dataset3/validation/problem-375.txt  \n",
            "  inflating: dataset3/validation/problem-376.txt  \n",
            "  inflating: dataset3/validation/problem-377.txt  \n",
            "  inflating: dataset3/validation/problem-378.txt  \n",
            "  inflating: dataset3/validation/problem-379.txt  \n",
            "  inflating: dataset3/validation/problem-38.txt  \n",
            "  inflating: dataset3/validation/problem-380.txt  \n",
            "  inflating: dataset3/validation/problem-381.txt  \n",
            "  inflating: dataset3/validation/problem-382.txt  \n",
            "  inflating: dataset3/validation/problem-383.txt  \n",
            "  inflating: dataset3/validation/problem-384.txt  \n",
            "  inflating: dataset3/validation/problem-385.txt  \n",
            "  inflating: dataset3/validation/problem-386.txt  \n",
            "  inflating: dataset3/validation/problem-387.txt  \n",
            "  inflating: dataset3/validation/problem-388.txt  \n",
            "  inflating: dataset3/validation/problem-389.txt  \n",
            "  inflating: dataset3/validation/problem-39.txt  \n",
            "  inflating: dataset3/validation/problem-390.txt  \n",
            "  inflating: dataset3/validation/problem-391.txt  \n",
            "  inflating: dataset3/validation/problem-392.txt  \n",
            "  inflating: dataset3/validation/problem-393.txt  \n",
            "  inflating: dataset3/validation/problem-394.txt  \n",
            "  inflating: dataset3/validation/problem-395.txt  \n",
            "  inflating: dataset3/validation/problem-396.txt  \n",
            "  inflating: dataset3/validation/problem-397.txt  \n",
            "  inflating: dataset3/validation/problem-398.txt  \n",
            "  inflating: dataset3/validation/problem-399.txt  \n",
            "  inflating: dataset3/validation/problem-4.txt  \n",
            "  inflating: dataset3/validation/problem-40.txt  \n",
            "  inflating: dataset3/validation/problem-400.txt  \n",
            "  inflating: dataset3/validation/problem-401.txt  \n",
            "  inflating: dataset3/validation/problem-402.txt  \n",
            "  inflating: dataset3/validation/problem-403.txt  \n",
            "  inflating: dataset3/validation/problem-404.txt  \n",
            "  inflating: dataset3/validation/problem-405.txt  \n",
            "  inflating: dataset3/validation/problem-406.txt  \n",
            "  inflating: dataset3/validation/problem-407.txt  \n",
            "  inflating: dataset3/validation/problem-408.txt  \n",
            "  inflating: dataset3/validation/problem-409.txt  \n",
            "  inflating: dataset3/validation/problem-41.txt  \n",
            "  inflating: dataset3/validation/problem-410.txt  \n",
            "  inflating: dataset3/validation/problem-411.txt  \n",
            "  inflating: dataset3/validation/problem-412.txt  \n",
            "  inflating: dataset3/validation/problem-413.txt  \n",
            "  inflating: dataset3/validation/problem-414.txt  \n",
            "  inflating: dataset3/validation/problem-415.txt  \n",
            "  inflating: dataset3/validation/problem-416.txt  \n",
            "  inflating: dataset3/validation/problem-417.txt  \n",
            "  inflating: dataset3/validation/problem-418.txt  \n",
            "  inflating: dataset3/validation/problem-419.txt  \n",
            "  inflating: dataset3/validation/problem-42.txt  \n",
            "  inflating: dataset3/validation/problem-420.txt  \n",
            "  inflating: dataset3/validation/problem-421.txt  \n",
            "  inflating: dataset3/validation/problem-422.txt  \n",
            "  inflating: dataset3/validation/problem-423.txt  \n",
            "  inflating: dataset3/validation/problem-424.txt  \n",
            "  inflating: dataset3/validation/problem-425.txt  \n",
            "  inflating: dataset3/validation/problem-426.txt  \n",
            "  inflating: dataset3/validation/problem-427.txt  \n",
            "  inflating: dataset3/validation/problem-428.txt  \n",
            "  inflating: dataset3/validation/problem-429.txt  \n",
            "  inflating: dataset3/validation/problem-43.txt  \n",
            "  inflating: dataset3/validation/problem-430.txt  \n",
            "  inflating: dataset3/validation/problem-431.txt  \n",
            "  inflating: dataset3/validation/problem-432.txt  \n",
            "  inflating: dataset3/validation/problem-433.txt  \n",
            "  inflating: dataset3/validation/problem-434.txt  \n",
            "  inflating: dataset3/validation/problem-435.txt  \n",
            "  inflating: dataset3/validation/problem-436.txt  \n",
            "  inflating: dataset3/validation/problem-437.txt  \n",
            "  inflating: dataset3/validation/problem-438.txt  \n",
            "  inflating: dataset3/validation/problem-439.txt  \n",
            "  inflating: dataset3/validation/problem-44.txt  \n",
            "  inflating: dataset3/validation/problem-440.txt  \n",
            "  inflating: dataset3/validation/problem-441.txt  \n",
            "  inflating: dataset3/validation/problem-442.txt  \n",
            "  inflating: dataset3/validation/problem-443.txt  \n",
            "  inflating: dataset3/validation/problem-444.txt  \n",
            "  inflating: dataset3/validation/problem-445.txt  \n",
            "  inflating: dataset3/validation/problem-446.txt  \n",
            "  inflating: dataset3/validation/problem-447.txt  \n",
            "  inflating: dataset3/validation/problem-448.txt  \n",
            "  inflating: dataset3/validation/problem-449.txt  \n",
            "  inflating: dataset3/validation/problem-45.txt  \n",
            "  inflating: dataset3/validation/problem-450.txt  \n",
            "  inflating: dataset3/validation/problem-451.txt  \n",
            "  inflating: dataset3/validation/problem-452.txt  \n",
            "  inflating: dataset3/validation/problem-453.txt  \n",
            "  inflating: dataset3/validation/problem-454.txt  \n",
            "  inflating: dataset3/validation/problem-455.txt  \n",
            "  inflating: dataset3/validation/problem-456.txt  \n",
            "  inflating: dataset3/validation/problem-457.txt  \n",
            "  inflating: dataset3/validation/problem-458.txt  \n",
            "  inflating: dataset3/validation/problem-459.txt  \n",
            "  inflating: dataset3/validation/problem-46.txt  \n",
            "  inflating: dataset3/validation/problem-460.txt  \n",
            "  inflating: dataset3/validation/problem-461.txt  \n",
            "  inflating: dataset3/validation/problem-462.txt  \n",
            "  inflating: dataset3/validation/problem-463.txt  \n",
            "  inflating: dataset3/validation/problem-464.txt  \n",
            "  inflating: dataset3/validation/problem-465.txt  \n",
            "  inflating: dataset3/validation/problem-466.txt  \n",
            "  inflating: dataset3/validation/problem-467.txt  \n",
            "  inflating: dataset3/validation/problem-468.txt  \n",
            "  inflating: dataset3/validation/problem-469.txt  \n",
            "  inflating: dataset3/validation/problem-47.txt  \n",
            "  inflating: dataset3/validation/problem-470.txt  \n",
            "  inflating: dataset3/validation/problem-471.txt  \n",
            "  inflating: dataset3/validation/problem-472.txt  \n",
            "  inflating: dataset3/validation/problem-473.txt  \n",
            "  inflating: dataset3/validation/problem-474.txt  \n",
            "  inflating: dataset3/validation/problem-475.txt  \n",
            "  inflating: dataset3/validation/problem-476.txt  \n",
            "  inflating: dataset3/validation/problem-477.txt  \n",
            "  inflating: dataset3/validation/problem-478.txt  \n",
            "  inflating: dataset3/validation/problem-479.txt  \n",
            "  inflating: dataset3/validation/problem-48.txt  \n",
            "  inflating: dataset3/validation/problem-480.txt  \n",
            "  inflating: dataset3/validation/problem-481.txt  \n",
            "  inflating: dataset3/validation/problem-482.txt  \n",
            "  inflating: dataset3/validation/problem-483.txt  \n",
            "  inflating: dataset3/validation/problem-484.txt  \n",
            "  inflating: dataset3/validation/problem-485.txt  \n",
            "  inflating: dataset3/validation/problem-486.txt  \n",
            "  inflating: dataset3/validation/problem-487.txt  \n",
            "  inflating: dataset3/validation/problem-488.txt  \n",
            "  inflating: dataset3/validation/problem-489.txt  \n",
            "  inflating: dataset3/validation/problem-49.txt  \n",
            "  inflating: dataset3/validation/problem-490.txt  \n",
            "  inflating: dataset3/validation/problem-491.txt  \n",
            "  inflating: dataset3/validation/problem-492.txt  \n",
            "  inflating: dataset3/validation/problem-493.txt  \n",
            "  inflating: dataset3/validation/problem-494.txt  \n",
            "  inflating: dataset3/validation/problem-495.txt  \n",
            "  inflating: dataset3/validation/problem-496.txt  \n",
            "  inflating: dataset3/validation/problem-497.txt  \n",
            "  inflating: dataset3/validation/problem-498.txt  \n",
            "  inflating: dataset3/validation/problem-499.txt  \n",
            "  inflating: dataset3/validation/problem-5.txt  \n",
            "  inflating: dataset3/validation/problem-50.txt  \n",
            "  inflating: dataset3/validation/problem-500.txt  \n",
            "  inflating: dataset3/validation/problem-501.txt  \n",
            "  inflating: dataset3/validation/problem-502.txt  \n",
            "  inflating: dataset3/validation/problem-503.txt  \n",
            "  inflating: dataset3/validation/problem-504.txt  \n",
            "  inflating: dataset3/validation/problem-505.txt  \n",
            "  inflating: dataset3/validation/problem-506.txt  \n",
            "  inflating: dataset3/validation/problem-507.txt  \n",
            "  inflating: dataset3/validation/problem-508.txt  \n",
            "  inflating: dataset3/validation/problem-509.txt  \n",
            "  inflating: dataset3/validation/problem-51.txt  \n",
            "  inflating: dataset3/validation/problem-510.txt  \n",
            "  inflating: dataset3/validation/problem-511.txt  \n",
            "  inflating: dataset3/validation/problem-512.txt  \n",
            "  inflating: dataset3/validation/problem-513.txt  \n",
            "  inflating: dataset3/validation/problem-514.txt  \n",
            "  inflating: dataset3/validation/problem-515.txt  \n",
            "  inflating: dataset3/validation/problem-516.txt  \n",
            "  inflating: dataset3/validation/problem-517.txt  \n",
            "  inflating: dataset3/validation/problem-518.txt  \n",
            "  inflating: dataset3/validation/problem-519.txt  \n",
            "  inflating: dataset3/validation/problem-52.txt  \n",
            "  inflating: dataset3/validation/problem-520.txt  \n",
            "  inflating: dataset3/validation/problem-521.txt  \n",
            "  inflating: dataset3/validation/problem-522.txt  \n",
            "  inflating: dataset3/validation/problem-523.txt  \n",
            "  inflating: dataset3/validation/problem-524.txt  \n",
            "  inflating: dataset3/validation/problem-525.txt  \n",
            "  inflating: dataset3/validation/problem-526.txt  \n",
            "  inflating: dataset3/validation/problem-527.txt  \n",
            "  inflating: dataset3/validation/problem-528.txt  \n",
            "  inflating: dataset3/validation/problem-529.txt  \n",
            "  inflating: dataset3/validation/problem-53.txt  \n",
            "  inflating: dataset3/validation/problem-530.txt  \n",
            "  inflating: dataset3/validation/problem-531.txt  \n",
            "  inflating: dataset3/validation/problem-532.txt  \n",
            "  inflating: dataset3/validation/problem-533.txt  \n",
            "  inflating: dataset3/validation/problem-534.txt  \n",
            "  inflating: dataset3/validation/problem-535.txt  \n",
            "  inflating: dataset3/validation/problem-536.txt  \n",
            "  inflating: dataset3/validation/problem-537.txt  \n",
            "  inflating: dataset3/validation/problem-538.txt  \n",
            "  inflating: dataset3/validation/problem-539.txt  \n",
            "  inflating: dataset3/validation/problem-54.txt  \n",
            "  inflating: dataset3/validation/problem-540.txt  \n",
            "  inflating: dataset3/validation/problem-541.txt  \n",
            "  inflating: dataset3/validation/problem-542.txt  \n",
            "  inflating: dataset3/validation/problem-543.txt  \n",
            "  inflating: dataset3/validation/problem-544.txt  \n",
            "  inflating: dataset3/validation/problem-545.txt  \n",
            "  inflating: dataset3/validation/problem-546.txt  \n",
            "  inflating: dataset3/validation/problem-547.txt  \n",
            "  inflating: dataset3/validation/problem-548.txt  \n",
            "  inflating: dataset3/validation/problem-549.txt  \n",
            "  inflating: dataset3/validation/problem-55.txt  \n",
            "  inflating: dataset3/validation/problem-550.txt  \n",
            "  inflating: dataset3/validation/problem-551.txt  \n",
            "  inflating: dataset3/validation/problem-552.txt  \n",
            "  inflating: dataset3/validation/problem-553.txt  \n",
            "  inflating: dataset3/validation/problem-554.txt  \n",
            "  inflating: dataset3/validation/problem-555.txt  \n",
            "  inflating: dataset3/validation/problem-556.txt  \n",
            "  inflating: dataset3/validation/problem-557.txt  \n",
            "  inflating: dataset3/validation/problem-558.txt  \n",
            "  inflating: dataset3/validation/problem-559.txt  \n",
            "  inflating: dataset3/validation/problem-56.txt  \n",
            "  inflating: dataset3/validation/problem-560.txt  \n",
            "  inflating: dataset3/validation/problem-561.txt  \n",
            "  inflating: dataset3/validation/problem-562.txt  \n",
            "  inflating: dataset3/validation/problem-563.txt  \n",
            "  inflating: dataset3/validation/problem-564.txt  \n",
            "  inflating: dataset3/validation/problem-565.txt  \n",
            "  inflating: dataset3/validation/problem-566.txt  \n",
            "  inflating: dataset3/validation/problem-567.txt  \n",
            "  inflating: dataset3/validation/problem-568.txt  \n",
            "  inflating: dataset3/validation/problem-569.txt  \n",
            "  inflating: dataset3/validation/problem-57.txt  \n",
            "  inflating: dataset3/validation/problem-570.txt  \n",
            "  inflating: dataset3/validation/problem-571.txt  \n",
            "  inflating: dataset3/validation/problem-572.txt  \n",
            "  inflating: dataset3/validation/problem-573.txt  \n",
            "  inflating: dataset3/validation/problem-574.txt  \n",
            "  inflating: dataset3/validation/problem-575.txt  \n",
            "  inflating: dataset3/validation/problem-576.txt  \n",
            "  inflating: dataset3/validation/problem-577.txt  \n",
            "  inflating: dataset3/validation/problem-578.txt  \n",
            "  inflating: dataset3/validation/problem-579.txt  \n",
            "  inflating: dataset3/validation/problem-58.txt  \n",
            "  inflating: dataset3/validation/problem-580.txt  \n",
            "  inflating: dataset3/validation/problem-581.txt  \n",
            "  inflating: dataset3/validation/problem-582.txt  \n",
            "  inflating: dataset3/validation/problem-583.txt  \n",
            "  inflating: dataset3/validation/problem-584.txt  \n",
            "  inflating: dataset3/validation/problem-585.txt  \n",
            "  inflating: dataset3/validation/problem-586.txt  \n",
            "  inflating: dataset3/validation/problem-587.txt  \n",
            "  inflating: dataset3/validation/problem-588.txt  \n",
            "  inflating: dataset3/validation/problem-589.txt  \n",
            "  inflating: dataset3/validation/problem-59.txt  \n",
            "  inflating: dataset3/validation/problem-590.txt  \n",
            "  inflating: dataset3/validation/problem-591.txt  \n",
            "  inflating: dataset3/validation/problem-592.txt  \n",
            "  inflating: dataset3/validation/problem-593.txt  \n",
            "  inflating: dataset3/validation/problem-594.txt  \n",
            "  inflating: dataset3/validation/problem-595.txt  \n",
            "  inflating: dataset3/validation/problem-596.txt  \n",
            "  inflating: dataset3/validation/problem-597.txt  \n",
            "  inflating: dataset3/validation/problem-598.txt  \n",
            "  inflating: dataset3/validation/problem-599.txt  \n",
            "  inflating: dataset3/validation/problem-6.txt  \n",
            "  inflating: dataset3/validation/problem-60.txt  \n",
            "  inflating: dataset3/validation/problem-600.txt  \n",
            "  inflating: dataset3/validation/problem-601.txt  \n",
            "  inflating: dataset3/validation/problem-602.txt  \n",
            "  inflating: dataset3/validation/problem-603.txt  \n",
            "  inflating: dataset3/validation/problem-604.txt  \n",
            "  inflating: dataset3/validation/problem-605.txt  \n",
            "  inflating: dataset3/validation/problem-606.txt  \n",
            "  inflating: dataset3/validation/problem-607.txt  \n",
            "  inflating: dataset3/validation/problem-608.txt  \n",
            "  inflating: dataset3/validation/problem-609.txt  \n",
            "  inflating: dataset3/validation/problem-61.txt  \n",
            "  inflating: dataset3/validation/problem-610.txt  \n",
            "  inflating: dataset3/validation/problem-611.txt  \n",
            "  inflating: dataset3/validation/problem-612.txt  \n",
            "  inflating: dataset3/validation/problem-613.txt  \n",
            "  inflating: dataset3/validation/problem-614.txt  \n",
            "  inflating: dataset3/validation/problem-615.txt  \n",
            "  inflating: dataset3/validation/problem-616.txt  \n",
            "  inflating: dataset3/validation/problem-617.txt  \n",
            "  inflating: dataset3/validation/problem-618.txt  \n",
            "  inflating: dataset3/validation/problem-619.txt  \n",
            "  inflating: dataset3/validation/problem-62.txt  \n",
            "  inflating: dataset3/validation/problem-620.txt  \n",
            "  inflating: dataset3/validation/problem-621.txt  \n",
            "  inflating: dataset3/validation/problem-622.txt  \n",
            "  inflating: dataset3/validation/problem-623.txt  \n",
            "  inflating: dataset3/validation/problem-624.txt  \n",
            "  inflating: dataset3/validation/problem-625.txt  \n",
            "  inflating: dataset3/validation/problem-626.txt  \n",
            "  inflating: dataset3/validation/problem-627.txt  \n",
            "  inflating: dataset3/validation/problem-628.txt  \n",
            "  inflating: dataset3/validation/problem-629.txt  \n",
            "  inflating: dataset3/validation/problem-63.txt  \n",
            "  inflating: dataset3/validation/problem-630.txt  \n",
            "  inflating: dataset3/validation/problem-631.txt  \n",
            "  inflating: dataset3/validation/problem-632.txt  \n",
            "  inflating: dataset3/validation/problem-633.txt  \n",
            "  inflating: dataset3/validation/problem-634.txt  \n",
            "  inflating: dataset3/validation/problem-635.txt  \n",
            "  inflating: dataset3/validation/problem-636.txt  \n",
            "  inflating: dataset3/validation/problem-637.txt  \n",
            "  inflating: dataset3/validation/problem-638.txt  \n",
            "  inflating: dataset3/validation/problem-639.txt  \n",
            "  inflating: dataset3/validation/problem-64.txt  \n",
            "  inflating: dataset3/validation/problem-640.txt  \n",
            "  inflating: dataset3/validation/problem-641.txt  \n",
            "  inflating: dataset3/validation/problem-642.txt  \n",
            "  inflating: dataset3/validation/problem-643.txt  \n",
            "  inflating: dataset3/validation/problem-644.txt  \n",
            "  inflating: dataset3/validation/problem-645.txt  \n",
            "  inflating: dataset3/validation/problem-646.txt  \n",
            "  inflating: dataset3/validation/problem-647.txt  \n",
            "  inflating: dataset3/validation/problem-648.txt  \n",
            "  inflating: dataset3/validation/problem-649.txt  \n",
            "  inflating: dataset3/validation/problem-65.txt  \n",
            "  inflating: dataset3/validation/problem-650.txt  \n",
            "  inflating: dataset3/validation/problem-651.txt  \n",
            "  inflating: dataset3/validation/problem-652.txt  \n",
            "  inflating: dataset3/validation/problem-653.txt  \n",
            "  inflating: dataset3/validation/problem-654.txt  \n",
            "  inflating: dataset3/validation/problem-655.txt  \n",
            "  inflating: dataset3/validation/problem-656.txt  \n",
            "  inflating: dataset3/validation/problem-657.txt  \n",
            "  inflating: dataset3/validation/problem-658.txt  \n",
            "  inflating: dataset3/validation/problem-659.txt  \n",
            "  inflating: dataset3/validation/problem-66.txt  \n",
            "  inflating: dataset3/validation/problem-660.txt  \n",
            "  inflating: dataset3/validation/problem-661.txt  \n",
            "  inflating: dataset3/validation/problem-662.txt  \n",
            "  inflating: dataset3/validation/problem-663.txt  \n",
            "  inflating: dataset3/validation/problem-664.txt  \n",
            "  inflating: dataset3/validation/problem-665.txt  \n",
            "  inflating: dataset3/validation/problem-666.txt  \n",
            "  inflating: dataset3/validation/problem-667.txt  \n",
            "  inflating: dataset3/validation/problem-668.txt  \n",
            "  inflating: dataset3/validation/problem-669.txt  \n",
            "  inflating: dataset3/validation/problem-67.txt  \n",
            "  inflating: dataset3/validation/problem-670.txt  \n",
            "  inflating: dataset3/validation/problem-671.txt  \n",
            "  inflating: dataset3/validation/problem-672.txt  \n",
            "  inflating: dataset3/validation/problem-673.txt  \n",
            "  inflating: dataset3/validation/problem-674.txt  \n",
            "  inflating: dataset3/validation/problem-675.txt  \n",
            "  inflating: dataset3/validation/problem-676.txt  \n",
            "  inflating: dataset3/validation/problem-677.txt  \n",
            "  inflating: dataset3/validation/problem-678.txt  \n",
            "  inflating: dataset3/validation/problem-679.txt  \n",
            "  inflating: dataset3/validation/problem-68.txt  \n",
            "  inflating: dataset3/validation/problem-680.txt  \n",
            "  inflating: dataset3/validation/problem-681.txt  \n",
            "  inflating: dataset3/validation/problem-682.txt  \n",
            "  inflating: dataset3/validation/problem-683.txt  \n",
            "  inflating: dataset3/validation/problem-684.txt  \n",
            "  inflating: dataset3/validation/problem-685.txt  \n",
            "  inflating: dataset3/validation/problem-686.txt  \n",
            "  inflating: dataset3/validation/problem-687.txt  \n",
            "  inflating: dataset3/validation/problem-688.txt  \n",
            "  inflating: dataset3/validation/problem-689.txt  \n",
            "  inflating: dataset3/validation/problem-69.txt  \n",
            "  inflating: dataset3/validation/problem-690.txt  \n",
            "  inflating: dataset3/validation/problem-691.txt  \n",
            "  inflating: dataset3/validation/problem-692.txt  \n",
            "  inflating: dataset3/validation/problem-693.txt  \n",
            "  inflating: dataset3/validation/problem-694.txt  \n",
            "  inflating: dataset3/validation/problem-695.txt  \n",
            "  inflating: dataset3/validation/problem-696.txt  \n",
            "  inflating: dataset3/validation/problem-697.txt  \n",
            "  inflating: dataset3/validation/problem-698.txt  \n",
            "  inflating: dataset3/validation/problem-699.txt  \n",
            "  inflating: dataset3/validation/problem-7.txt  \n",
            "  inflating: dataset3/validation/problem-70.txt  \n",
            "  inflating: dataset3/validation/problem-700.txt  \n",
            "  inflating: dataset3/validation/problem-701.txt  \n",
            "  inflating: dataset3/validation/problem-702.txt  \n",
            "  inflating: dataset3/validation/problem-703.txt  \n",
            "  inflating: dataset3/validation/problem-704.txt  \n",
            "  inflating: dataset3/validation/problem-705.txt  \n",
            "  inflating: dataset3/validation/problem-706.txt  \n",
            "  inflating: dataset3/validation/problem-707.txt  \n",
            "  inflating: dataset3/validation/problem-708.txt  \n",
            "  inflating: dataset3/validation/problem-709.txt  \n",
            "  inflating: dataset3/validation/problem-71.txt  \n",
            "  inflating: dataset3/validation/problem-710.txt  \n",
            "  inflating: dataset3/validation/problem-711.txt  \n",
            "  inflating: dataset3/validation/problem-712.txt  \n",
            "  inflating: dataset3/validation/problem-713.txt  \n",
            "  inflating: dataset3/validation/problem-714.txt  \n",
            "  inflating: dataset3/validation/problem-715.txt  \n",
            "  inflating: dataset3/validation/problem-716.txt  \n",
            "  inflating: dataset3/validation/problem-717.txt  \n",
            "  inflating: dataset3/validation/problem-718.txt  \n",
            "  inflating: dataset3/validation/problem-719.txt  \n",
            "  inflating: dataset3/validation/problem-72.txt  \n",
            "  inflating: dataset3/validation/problem-720.txt  \n",
            "  inflating: dataset3/validation/problem-721.txt  \n",
            "  inflating: dataset3/validation/problem-722.txt  \n",
            "  inflating: dataset3/validation/problem-723.txt  \n",
            "  inflating: dataset3/validation/problem-724.txt  \n",
            "  inflating: dataset3/validation/problem-725.txt  \n",
            "  inflating: dataset3/validation/problem-726.txt  \n",
            "  inflating: dataset3/validation/problem-727.txt  \n",
            "  inflating: dataset3/validation/problem-728.txt  \n",
            "  inflating: dataset3/validation/problem-729.txt  \n",
            "  inflating: dataset3/validation/problem-73.txt  \n",
            "  inflating: dataset3/validation/problem-730.txt  \n",
            "  inflating: dataset3/validation/problem-731.txt  \n",
            "  inflating: dataset3/validation/problem-732.txt  \n",
            "  inflating: dataset3/validation/problem-733.txt  \n",
            "  inflating: dataset3/validation/problem-734.txt  \n",
            "  inflating: dataset3/validation/problem-735.txt  \n",
            "  inflating: dataset3/validation/problem-736.txt  \n",
            "  inflating: dataset3/validation/problem-737.txt  \n",
            "  inflating: dataset3/validation/problem-738.txt  \n",
            "  inflating: dataset3/validation/problem-739.txt  \n",
            "  inflating: dataset3/validation/problem-74.txt  \n",
            "  inflating: dataset3/validation/problem-740.txt  \n",
            "  inflating: dataset3/validation/problem-741.txt  \n",
            "  inflating: dataset3/validation/problem-742.txt  \n",
            "  inflating: dataset3/validation/problem-743.txt  \n",
            "  inflating: dataset3/validation/problem-744.txt  \n",
            "  inflating: dataset3/validation/problem-745.txt  \n",
            "  inflating: dataset3/validation/problem-746.txt  \n",
            "  inflating: dataset3/validation/problem-747.txt  \n",
            "  inflating: dataset3/validation/problem-748.txt  \n",
            "  inflating: dataset3/validation/problem-749.txt  \n",
            "  inflating: dataset3/validation/problem-75.txt  \n",
            "  inflating: dataset3/validation/problem-750.txt  \n",
            "  inflating: dataset3/validation/problem-751.txt  \n",
            "  inflating: dataset3/validation/problem-752.txt  \n",
            "  inflating: dataset3/validation/problem-753.txt  \n",
            "  inflating: dataset3/validation/problem-754.txt  \n",
            "  inflating: dataset3/validation/problem-755.txt  \n",
            "  inflating: dataset3/validation/problem-756.txt  \n",
            "  inflating: dataset3/validation/problem-757.txt  \n",
            "  inflating: dataset3/validation/problem-758.txt  \n",
            "  inflating: dataset3/validation/problem-759.txt  \n",
            "  inflating: dataset3/validation/problem-76.txt  \n",
            "  inflating: dataset3/validation/problem-760.txt  \n",
            "  inflating: dataset3/validation/problem-761.txt  \n",
            "  inflating: dataset3/validation/problem-762.txt  \n",
            "  inflating: dataset3/validation/problem-763.txt  \n",
            "  inflating: dataset3/validation/problem-764.txt  \n",
            "  inflating: dataset3/validation/problem-765.txt  \n",
            "  inflating: dataset3/validation/problem-766.txt  \n",
            "  inflating: dataset3/validation/problem-767.txt  \n",
            "  inflating: dataset3/validation/problem-768.txt  \n",
            "  inflating: dataset3/validation/problem-769.txt  \n",
            "  inflating: dataset3/validation/problem-77.txt  \n",
            "  inflating: dataset3/validation/problem-770.txt  \n",
            "  inflating: dataset3/validation/problem-771.txt  \n",
            "  inflating: dataset3/validation/problem-772.txt  \n",
            "  inflating: dataset3/validation/problem-773.txt  \n",
            "  inflating: dataset3/validation/problem-774.txt  \n",
            "  inflating: dataset3/validation/problem-775.txt  \n",
            "  inflating: dataset3/validation/problem-776.txt  \n",
            "  inflating: dataset3/validation/problem-777.txt  \n",
            "  inflating: dataset3/validation/problem-778.txt  \n",
            "  inflating: dataset3/validation/problem-779.txt  \n",
            "  inflating: dataset3/validation/problem-78.txt  \n",
            "  inflating: dataset3/validation/problem-780.txt  \n",
            "  inflating: dataset3/validation/problem-781.txt  \n",
            "  inflating: dataset3/validation/problem-782.txt  \n",
            "  inflating: dataset3/validation/problem-783.txt  \n",
            "  inflating: dataset3/validation/problem-784.txt  \n",
            "  inflating: dataset3/validation/problem-785.txt  \n",
            "  inflating: dataset3/validation/problem-786.txt  \n",
            "  inflating: dataset3/validation/problem-787.txt  \n",
            "  inflating: dataset3/validation/problem-788.txt  \n",
            "  inflating: dataset3/validation/problem-789.txt  \n",
            "  inflating: dataset3/validation/problem-79.txt  \n",
            "  inflating: dataset3/validation/problem-790.txt  \n",
            "  inflating: dataset3/validation/problem-791.txt  \n",
            "  inflating: dataset3/validation/problem-792.txt  \n",
            "  inflating: dataset3/validation/problem-793.txt  \n",
            "  inflating: dataset3/validation/problem-794.txt  \n",
            "  inflating: dataset3/validation/problem-795.txt  \n",
            "  inflating: dataset3/validation/problem-796.txt  \n",
            "  inflating: dataset3/validation/problem-797.txt  \n",
            "  inflating: dataset3/validation/problem-798.txt  \n",
            "  inflating: dataset3/validation/problem-799.txt  \n",
            "  inflating: dataset3/validation/problem-8.txt  \n",
            "  inflating: dataset3/validation/problem-80.txt  \n",
            "  inflating: dataset3/validation/problem-800.txt  \n",
            "  inflating: dataset3/validation/problem-801.txt  \n",
            "  inflating: dataset3/validation/problem-802.txt  \n",
            "  inflating: dataset3/validation/problem-803.txt  \n",
            "  inflating: dataset3/validation/problem-804.txt  \n",
            "  inflating: dataset3/validation/problem-805.txt  \n",
            "  inflating: dataset3/validation/problem-806.txt  \n",
            "  inflating: dataset3/validation/problem-807.txt  \n",
            "  inflating: dataset3/validation/problem-808.txt  \n",
            "  inflating: dataset3/validation/problem-809.txt  \n",
            "  inflating: dataset3/validation/problem-81.txt  \n",
            "  inflating: dataset3/validation/problem-810.txt  \n",
            "  inflating: dataset3/validation/problem-811.txt  \n",
            "  inflating: dataset3/validation/problem-812.txt  \n",
            "  inflating: dataset3/validation/problem-813.txt  \n",
            "  inflating: dataset3/validation/problem-814.txt  \n",
            "  inflating: dataset3/validation/problem-815.txt  \n",
            "  inflating: dataset3/validation/problem-816.txt  \n",
            "  inflating: dataset3/validation/problem-817.txt  \n",
            "  inflating: dataset3/validation/problem-818.txt  \n",
            "  inflating: dataset3/validation/problem-819.txt  \n",
            "  inflating: dataset3/validation/problem-82.txt  \n",
            "  inflating: dataset3/validation/problem-820.txt  \n",
            "  inflating: dataset3/validation/problem-821.txt  \n",
            "  inflating: dataset3/validation/problem-822.txt  \n",
            "  inflating: dataset3/validation/problem-823.txt  \n",
            "  inflating: dataset3/validation/problem-824.txt  \n",
            "  inflating: dataset3/validation/problem-825.txt  \n",
            "  inflating: dataset3/validation/problem-826.txt  \n",
            "  inflating: dataset3/validation/problem-827.txt  \n",
            "  inflating: dataset3/validation/problem-828.txt  \n",
            "  inflating: dataset3/validation/problem-829.txt  \n",
            "  inflating: dataset3/validation/problem-83.txt  \n",
            "  inflating: dataset3/validation/problem-830.txt  \n",
            "  inflating: dataset3/validation/problem-831.txt  \n",
            "  inflating: dataset3/validation/problem-832.txt  \n",
            "  inflating: dataset3/validation/problem-833.txt  \n",
            "  inflating: dataset3/validation/problem-834.txt  \n",
            "  inflating: dataset3/validation/problem-835.txt  \n",
            "  inflating: dataset3/validation/problem-836.txt  \n",
            "  inflating: dataset3/validation/problem-837.txt  \n",
            "  inflating: dataset3/validation/problem-838.txt  \n",
            "  inflating: dataset3/validation/problem-839.txt  \n",
            "  inflating: dataset3/validation/problem-84.txt  \n",
            "  inflating: dataset3/validation/problem-840.txt  \n",
            "  inflating: dataset3/validation/problem-841.txt  \n",
            "  inflating: dataset3/validation/problem-842.txt  \n",
            "  inflating: dataset3/validation/problem-843.txt  \n",
            "  inflating: dataset3/validation/problem-844.txt  \n",
            "  inflating: dataset3/validation/problem-845.txt  \n",
            "  inflating: dataset3/validation/problem-846.txt  \n",
            "  inflating: dataset3/validation/problem-847.txt  \n",
            "  inflating: dataset3/validation/problem-848.txt  \n",
            "  inflating: dataset3/validation/problem-849.txt  \n",
            "  inflating: dataset3/validation/problem-85.txt  \n",
            "  inflating: dataset3/validation/problem-850.txt  \n",
            "  inflating: dataset3/validation/problem-851.txt  \n",
            "  inflating: dataset3/validation/problem-852.txt  \n",
            "  inflating: dataset3/validation/problem-853.txt  \n",
            "  inflating: dataset3/validation/problem-854.txt  \n",
            "  inflating: dataset3/validation/problem-855.txt  \n",
            "  inflating: dataset3/validation/problem-856.txt  \n",
            "  inflating: dataset3/validation/problem-857.txt  \n",
            "  inflating: dataset3/validation/problem-858.txt  \n",
            "  inflating: dataset3/validation/problem-859.txt  \n",
            "  inflating: dataset3/validation/problem-86.txt  \n",
            "  inflating: dataset3/validation/problem-860.txt  \n",
            "  inflating: dataset3/validation/problem-861.txt  \n",
            "  inflating: dataset3/validation/problem-862.txt  \n",
            "  inflating: dataset3/validation/problem-863.txt  \n",
            "  inflating: dataset3/validation/problem-864.txt  \n",
            "  inflating: dataset3/validation/problem-865.txt  \n",
            "  inflating: dataset3/validation/problem-866.txt  \n",
            "  inflating: dataset3/validation/problem-867.txt  \n",
            "  inflating: dataset3/validation/problem-868.txt  \n",
            "  inflating: dataset3/validation/problem-869.txt  \n",
            "  inflating: dataset3/validation/problem-87.txt  \n",
            "  inflating: dataset3/validation/problem-870.txt  \n",
            "  inflating: dataset3/validation/problem-871.txt  \n",
            "  inflating: dataset3/validation/problem-872.txt  \n",
            "  inflating: dataset3/validation/problem-873.txt  \n",
            "  inflating: dataset3/validation/problem-874.txt  \n",
            "  inflating: dataset3/validation/problem-875.txt  \n",
            "  inflating: dataset3/validation/problem-876.txt  \n",
            "  inflating: dataset3/validation/problem-877.txt  \n",
            "  inflating: dataset3/validation/problem-878.txt  \n",
            "  inflating: dataset3/validation/problem-879.txt  \n",
            "  inflating: dataset3/validation/problem-88.txt  \n",
            "  inflating: dataset3/validation/problem-880.txt  \n",
            "  inflating: dataset3/validation/problem-881.txt  \n",
            "  inflating: dataset3/validation/problem-882.txt  \n",
            "  inflating: dataset3/validation/problem-883.txt  \n",
            "  inflating: dataset3/validation/problem-884.txt  \n",
            "  inflating: dataset3/validation/problem-885.txt  \n",
            "  inflating: dataset3/validation/problem-886.txt  \n",
            "  inflating: dataset3/validation/problem-887.txt  \n",
            "  inflating: dataset3/validation/problem-888.txt  \n",
            "  inflating: dataset3/validation/problem-889.txt  \n",
            "  inflating: dataset3/validation/problem-89.txt  \n",
            "  inflating: dataset3/validation/problem-890.txt  \n",
            "  inflating: dataset3/validation/problem-891.txt  \n",
            "  inflating: dataset3/validation/problem-892.txt  \n",
            "  inflating: dataset3/validation/problem-893.txt  \n",
            "  inflating: dataset3/validation/problem-894.txt  \n",
            "  inflating: dataset3/validation/problem-895.txt  \n",
            "  inflating: dataset3/validation/problem-896.txt  \n",
            "  inflating: dataset3/validation/problem-897.txt  \n",
            "  inflating: dataset3/validation/problem-898.txt  \n",
            "  inflating: dataset3/validation/problem-899.txt  \n",
            "  inflating: dataset3/validation/problem-9.txt  \n",
            "  inflating: dataset3/validation/problem-90.txt  \n",
            "  inflating: dataset3/validation/problem-900.txt  \n",
            "  inflating: dataset3/validation/problem-901.txt  \n",
            "  inflating: dataset3/validation/problem-902.txt  \n",
            "  inflating: dataset3/validation/problem-903.txt  \n",
            "  inflating: dataset3/validation/problem-904.txt  \n",
            "  inflating: dataset3/validation/problem-905.txt  \n",
            "  inflating: dataset3/validation/problem-906.txt  \n",
            "  inflating: dataset3/validation/problem-907.txt  \n",
            "  inflating: dataset3/validation/problem-908.txt  \n",
            "  inflating: dataset3/validation/problem-909.txt  \n",
            "  inflating: dataset3/validation/problem-91.txt  \n",
            "  inflating: dataset3/validation/problem-910.txt  \n",
            "  inflating: dataset3/validation/problem-911.txt  \n",
            "  inflating: dataset3/validation/problem-912.txt  \n",
            "  inflating: dataset3/validation/problem-913.txt  \n",
            "  inflating: dataset3/validation/problem-914.txt  \n",
            "  inflating: dataset3/validation/problem-915.txt  \n",
            "  inflating: dataset3/validation/problem-916.txt  \n",
            "  inflating: dataset3/validation/problem-917.txt  \n",
            "  inflating: dataset3/validation/problem-918.txt  \n",
            "  inflating: dataset3/validation/problem-919.txt  \n",
            "  inflating: dataset3/validation/problem-92.txt  \n",
            "  inflating: dataset3/validation/problem-920.txt  \n",
            "  inflating: dataset3/validation/problem-921.txt  \n",
            "  inflating: dataset3/validation/problem-922.txt  \n",
            "  inflating: dataset3/validation/problem-923.txt  \n",
            "  inflating: dataset3/validation/problem-924.txt  \n",
            "  inflating: dataset3/validation/problem-925.txt  \n",
            "  inflating: dataset3/validation/problem-926.txt  \n",
            "  inflating: dataset3/validation/problem-927.txt  \n",
            "  inflating: dataset3/validation/problem-928.txt  \n",
            "  inflating: dataset3/validation/problem-929.txt  \n",
            "  inflating: dataset3/validation/problem-93.txt  \n",
            "  inflating: dataset3/validation/problem-930.txt  \n",
            "  inflating: dataset3/validation/problem-931.txt  \n",
            "  inflating: dataset3/validation/problem-932.txt  \n",
            "  inflating: dataset3/validation/problem-933.txt  \n",
            "  inflating: dataset3/validation/problem-934.txt  \n",
            "  inflating: dataset3/validation/problem-935.txt  \n",
            "  inflating: dataset3/validation/problem-936.txt  \n",
            "  inflating: dataset3/validation/problem-937.txt  \n",
            "  inflating: dataset3/validation/problem-938.txt  \n",
            "  inflating: dataset3/validation/problem-939.txt  \n",
            "  inflating: dataset3/validation/problem-94.txt  \n",
            "  inflating: dataset3/validation/problem-940.txt  \n",
            "  inflating: dataset3/validation/problem-941.txt  \n",
            "  inflating: dataset3/validation/problem-942.txt  \n",
            "  inflating: dataset3/validation/problem-943.txt  \n",
            "  inflating: dataset3/validation/problem-944.txt  \n",
            "  inflating: dataset3/validation/problem-945.txt  \n",
            "  inflating: dataset3/validation/problem-946.txt  \n",
            "  inflating: dataset3/validation/problem-947.txt  \n",
            "  inflating: dataset3/validation/problem-948.txt  \n",
            "  inflating: dataset3/validation/problem-949.txt  \n",
            "  inflating: dataset3/validation/problem-95.txt  \n",
            "  inflating: dataset3/validation/problem-950.txt  \n",
            "  inflating: dataset3/validation/problem-951.txt  \n",
            "  inflating: dataset3/validation/problem-952.txt  \n",
            "  inflating: dataset3/validation/problem-953.txt  \n",
            "  inflating: dataset3/validation/problem-954.txt  \n",
            "  inflating: dataset3/validation/problem-955.txt  \n",
            "  inflating: dataset3/validation/problem-956.txt  \n",
            "  inflating: dataset3/validation/problem-957.txt  \n",
            "  inflating: dataset3/validation/problem-958.txt  \n",
            "  inflating: dataset3/validation/problem-959.txt  \n",
            "  inflating: dataset3/validation/problem-96.txt  \n",
            "  inflating: dataset3/validation/problem-960.txt  \n",
            "  inflating: dataset3/validation/problem-961.txt  \n",
            "  inflating: dataset3/validation/problem-962.txt  \n",
            "  inflating: dataset3/validation/problem-963.txt  \n",
            "  inflating: dataset3/validation/problem-964.txt  \n",
            "  inflating: dataset3/validation/problem-965.txt  \n",
            "  inflating: dataset3/validation/problem-966.txt  \n",
            "  inflating: dataset3/validation/problem-967.txt  \n",
            "  inflating: dataset3/validation/problem-968.txt  \n",
            "  inflating: dataset3/validation/problem-969.txt  \n",
            "  inflating: dataset3/validation/problem-97.txt  \n",
            "  inflating: dataset3/validation/problem-970.txt  \n",
            "  inflating: dataset3/validation/problem-971.txt  \n",
            "  inflating: dataset3/validation/problem-972.txt  \n",
            "  inflating: dataset3/validation/problem-973.txt  \n",
            "  inflating: dataset3/validation/problem-974.txt  \n",
            "  inflating: dataset3/validation/problem-975.txt  \n",
            "  inflating: dataset3/validation/problem-976.txt  \n",
            "  inflating: dataset3/validation/problem-977.txt  \n",
            "  inflating: dataset3/validation/problem-978.txt  \n",
            "  inflating: dataset3/validation/problem-979.txt  \n",
            "  inflating: dataset3/validation/problem-98.txt  \n",
            "  inflating: dataset3/validation/problem-980.txt  \n",
            "  inflating: dataset3/validation/problem-981.txt  \n",
            "  inflating: dataset3/validation/problem-982.txt  \n",
            "  inflating: dataset3/validation/problem-983.txt  \n",
            "  inflating: dataset3/validation/problem-984.txt  \n",
            "  inflating: dataset3/validation/problem-985.txt  \n",
            "  inflating: dataset3/validation/problem-986.txt  \n",
            "  inflating: dataset3/validation/problem-987.txt  \n",
            "  inflating: dataset3/validation/problem-988.txt  \n",
            "  inflating: dataset3/validation/problem-989.txt  \n",
            "  inflating: dataset3/validation/problem-99.txt  \n",
            "  inflating: dataset3/validation/problem-990.txt  \n",
            "  inflating: dataset3/validation/problem-991.txt  \n",
            "  inflating: dataset3/validation/problem-992.txt  \n",
            "  inflating: dataset3/validation/problem-993.txt  \n",
            "  inflating: dataset3/validation/problem-994.txt  \n",
            "  inflating: dataset3/validation/problem-995.txt  \n",
            "  inflating: dataset3/validation/problem-996.txt  \n",
            "  inflating: dataset3/validation/problem-997.txt  \n",
            "  inflating: dataset3/validation/problem-998.txt  \n",
            "  inflating: dataset3/validation/problem-999.txt  \n",
            "  inflating: dataset3/validation/truth-problem-1.json  \n",
            "  inflating: dataset3/validation/truth-problem-10.json  \n",
            "  inflating: dataset3/validation/truth-problem-100.json  \n",
            "  inflating: dataset3/validation/truth-problem-1000.json  \n",
            "  inflating: dataset3/validation/truth-problem-1001.json  \n",
            "  inflating: dataset3/validation/truth-problem-1002.json  \n",
            "  inflating: dataset3/validation/truth-problem-1003.json  \n",
            "  inflating: dataset3/validation/truth-problem-1004.json  \n",
            "  inflating: dataset3/validation/truth-problem-1005.json  \n",
            "  inflating: dataset3/validation/truth-problem-1006.json  \n",
            "  inflating: dataset3/validation/truth-problem-1007.json  \n",
            "  inflating: dataset3/validation/truth-problem-1008.json  \n",
            "  inflating: dataset3/validation/truth-problem-1009.json  \n",
            "  inflating: dataset3/validation/truth-problem-101.json  \n",
            "  inflating: dataset3/validation/truth-problem-1010.json  \n",
            "  inflating: dataset3/validation/truth-problem-1011.json  \n",
            "  inflating: dataset3/validation/truth-problem-1012.json  \n",
            "  inflating: dataset3/validation/truth-problem-1013.json  \n",
            "  inflating: dataset3/validation/truth-problem-1014.json  \n",
            "  inflating: dataset3/validation/truth-problem-1015.json  \n",
            "  inflating: dataset3/validation/truth-problem-1016.json  \n",
            "  inflating: dataset3/validation/truth-problem-1017.json  \n",
            "  inflating: dataset3/validation/truth-problem-1018.json  \n",
            "  inflating: dataset3/validation/truth-problem-1019.json  \n",
            "  inflating: dataset3/validation/truth-problem-102.json  \n",
            "  inflating: dataset3/validation/truth-problem-1020.json  \n",
            "  inflating: dataset3/validation/truth-problem-1021.json  \n",
            "  inflating: dataset3/validation/truth-problem-1022.json  \n",
            "  inflating: dataset3/validation/truth-problem-1023.json  \n",
            "  inflating: dataset3/validation/truth-problem-1024.json  \n",
            "  inflating: dataset3/validation/truth-problem-1025.json  \n",
            "  inflating: dataset3/validation/truth-problem-1026.json  \n",
            "  inflating: dataset3/validation/truth-problem-1027.json  \n",
            "  inflating: dataset3/validation/truth-problem-1028.json  \n",
            "  inflating: dataset3/validation/truth-problem-1029.json  \n",
            "  inflating: dataset3/validation/truth-problem-103.json  \n",
            "  inflating: dataset3/validation/truth-problem-1030.json  \n",
            "  inflating: dataset3/validation/truth-problem-1031.json  \n",
            "  inflating: dataset3/validation/truth-problem-1032.json  \n",
            "  inflating: dataset3/validation/truth-problem-1033.json  \n",
            "  inflating: dataset3/validation/truth-problem-1034.json  \n",
            "  inflating: dataset3/validation/truth-problem-1035.json  \n",
            "  inflating: dataset3/validation/truth-problem-1036.json  \n",
            "  inflating: dataset3/validation/truth-problem-1037.json  \n",
            "  inflating: dataset3/validation/truth-problem-1038.json  \n",
            "  inflating: dataset3/validation/truth-problem-1039.json  \n",
            "  inflating: dataset3/validation/truth-problem-104.json  \n",
            "  inflating: dataset3/validation/truth-problem-1040.json  \n",
            "  inflating: dataset3/validation/truth-problem-1041.json  \n",
            "  inflating: dataset3/validation/truth-problem-1042.json  \n",
            "  inflating: dataset3/validation/truth-problem-1043.json  \n",
            "  inflating: dataset3/validation/truth-problem-1044.json  \n",
            "  inflating: dataset3/validation/truth-problem-1045.json  \n",
            "  inflating: dataset3/validation/truth-problem-1046.json  \n",
            "  inflating: dataset3/validation/truth-problem-1047.json  \n",
            "  inflating: dataset3/validation/truth-problem-1048.json  \n",
            "  inflating: dataset3/validation/truth-problem-1049.json  \n",
            "  inflating: dataset3/validation/truth-problem-105.json  \n",
            "  inflating: dataset3/validation/truth-problem-1050.json  \n",
            "  inflating: dataset3/validation/truth-problem-1051.json  \n",
            "  inflating: dataset3/validation/truth-problem-1052.json  \n",
            "  inflating: dataset3/validation/truth-problem-1053.json  \n",
            "  inflating: dataset3/validation/truth-problem-1054.json  \n",
            "  inflating: dataset3/validation/truth-problem-1055.json  \n",
            "  inflating: dataset3/validation/truth-problem-1056.json  \n",
            "  inflating: dataset3/validation/truth-problem-1057.json  \n",
            "  inflating: dataset3/validation/truth-problem-1058.json  \n",
            "  inflating: dataset3/validation/truth-problem-1059.json  \n",
            "  inflating: dataset3/validation/truth-problem-106.json  \n",
            "  inflating: dataset3/validation/truth-problem-1060.json  \n",
            "  inflating: dataset3/validation/truth-problem-1061.json  \n",
            "  inflating: dataset3/validation/truth-problem-1062.json  \n",
            "  inflating: dataset3/validation/truth-problem-1063.json  \n",
            "  inflating: dataset3/validation/truth-problem-1064.json  \n",
            "  inflating: dataset3/validation/truth-problem-1065.json  \n",
            "  inflating: dataset3/validation/truth-problem-1066.json  \n",
            "  inflating: dataset3/validation/truth-problem-1067.json  \n",
            "  inflating: dataset3/validation/truth-problem-1068.json  \n",
            "  inflating: dataset3/validation/truth-problem-1069.json  \n",
            "  inflating: dataset3/validation/truth-problem-107.json  \n",
            "  inflating: dataset3/validation/truth-problem-1070.json  \n",
            "  inflating: dataset3/validation/truth-problem-1071.json  \n",
            "  inflating: dataset3/validation/truth-problem-1072.json  \n",
            "  inflating: dataset3/validation/truth-problem-1073.json  \n",
            "  inflating: dataset3/validation/truth-problem-1074.json  \n",
            "  inflating: dataset3/validation/truth-problem-1075.json  \n",
            "  inflating: dataset3/validation/truth-problem-1076.json  \n",
            "  inflating: dataset3/validation/truth-problem-1077.json  \n",
            "  inflating: dataset3/validation/truth-problem-1078.json  \n",
            "  inflating: dataset3/validation/truth-problem-1079.json  \n",
            "  inflating: dataset3/validation/truth-problem-108.json  \n",
            "  inflating: dataset3/validation/truth-problem-1080.json  \n",
            "  inflating: dataset3/validation/truth-problem-1081.json  \n",
            "  inflating: dataset3/validation/truth-problem-1082.json  \n",
            "  inflating: dataset3/validation/truth-problem-1083.json  \n",
            "  inflating: dataset3/validation/truth-problem-1084.json  \n",
            "  inflating: dataset3/validation/truth-problem-1085.json  \n",
            "  inflating: dataset3/validation/truth-problem-1086.json  \n",
            "  inflating: dataset3/validation/truth-problem-1087.json  \n",
            "  inflating: dataset3/validation/truth-problem-1088.json  \n",
            "  inflating: dataset3/validation/truth-problem-1089.json  \n",
            "  inflating: dataset3/validation/truth-problem-109.json  \n",
            "  inflating: dataset3/validation/truth-problem-1090.json  \n",
            "  inflating: dataset3/validation/truth-problem-1091.json  \n",
            "  inflating: dataset3/validation/truth-problem-1092.json  \n",
            "  inflating: dataset3/validation/truth-problem-1093.json  \n",
            "  inflating: dataset3/validation/truth-problem-1094.json  \n",
            "  inflating: dataset3/validation/truth-problem-1095.json  \n",
            "  inflating: dataset3/validation/truth-problem-1096.json  \n",
            "  inflating: dataset3/validation/truth-problem-1097.json  \n",
            "  inflating: dataset3/validation/truth-problem-1098.json  \n",
            "  inflating: dataset3/validation/truth-problem-1099.json  \n",
            "  inflating: dataset3/validation/truth-problem-11.json  \n",
            "  inflating: dataset3/validation/truth-problem-110.json  \n",
            "  inflating: dataset3/validation/truth-problem-1100.json  \n",
            "  inflating: dataset3/validation/truth-problem-1101.json  \n",
            "  inflating: dataset3/validation/truth-problem-1102.json  \n",
            "  inflating: dataset3/validation/truth-problem-1103.json  \n",
            "  inflating: dataset3/validation/truth-problem-1104.json  \n",
            "  inflating: dataset3/validation/truth-problem-1105.json  \n",
            "  inflating: dataset3/validation/truth-problem-1106.json  \n",
            "  inflating: dataset3/validation/truth-problem-1107.json  \n",
            "  inflating: dataset3/validation/truth-problem-1108.json  \n",
            "  inflating: dataset3/validation/truth-problem-1109.json  \n",
            "  inflating: dataset3/validation/truth-problem-111.json  \n",
            "  inflating: dataset3/validation/truth-problem-1110.json  \n",
            "  inflating: dataset3/validation/truth-problem-1111.json  \n",
            "  inflating: dataset3/validation/truth-problem-1112.json  \n",
            "  inflating: dataset3/validation/truth-problem-1113.json  \n",
            "  inflating: dataset3/validation/truth-problem-1114.json  \n",
            "  inflating: dataset3/validation/truth-problem-1115.json  \n",
            "  inflating: dataset3/validation/truth-problem-1116.json  \n",
            "  inflating: dataset3/validation/truth-problem-1117.json  \n",
            "  inflating: dataset3/validation/truth-problem-1118.json  \n",
            "  inflating: dataset3/validation/truth-problem-1119.json  \n",
            "  inflating: dataset3/validation/truth-problem-112.json  \n",
            "  inflating: dataset3/validation/truth-problem-1120.json  \n",
            "  inflating: dataset3/validation/truth-problem-1121.json  \n",
            "  inflating: dataset3/validation/truth-problem-1122.json  \n",
            "  inflating: dataset3/validation/truth-problem-1123.json  \n",
            "  inflating: dataset3/validation/truth-problem-1124.json  \n",
            "  inflating: dataset3/validation/truth-problem-1125.json  \n",
            "  inflating: dataset3/validation/truth-problem-1126.json  \n",
            "  inflating: dataset3/validation/truth-problem-1127.json  \n",
            "  inflating: dataset3/validation/truth-problem-1128.json  \n",
            "  inflating: dataset3/validation/truth-problem-1129.json  \n",
            "  inflating: dataset3/validation/truth-problem-113.json  \n",
            "  inflating: dataset3/validation/truth-problem-1130.json  \n",
            "  inflating: dataset3/validation/truth-problem-1131.json  \n",
            "  inflating: dataset3/validation/truth-problem-1132.json  \n",
            "  inflating: dataset3/validation/truth-problem-1133.json  \n",
            "  inflating: dataset3/validation/truth-problem-1134.json  \n",
            "  inflating: dataset3/validation/truth-problem-1135.json  \n",
            "  inflating: dataset3/validation/truth-problem-1136.json  \n",
            "  inflating: dataset3/validation/truth-problem-1137.json  \n",
            "  inflating: dataset3/validation/truth-problem-1138.json  \n",
            "  inflating: dataset3/validation/truth-problem-1139.json  \n",
            "  inflating: dataset3/validation/truth-problem-114.json  \n",
            "  inflating: dataset3/validation/truth-problem-1140.json  \n",
            "  inflating: dataset3/validation/truth-problem-1141.json  \n",
            "  inflating: dataset3/validation/truth-problem-1142.json  \n",
            "  inflating: dataset3/validation/truth-problem-1143.json  \n",
            "  inflating: dataset3/validation/truth-problem-1144.json  \n",
            "  inflating: dataset3/validation/truth-problem-1145.json  \n",
            "  inflating: dataset3/validation/truth-problem-1146.json  \n",
            "  inflating: dataset3/validation/truth-problem-1147.json  \n",
            "  inflating: dataset3/validation/truth-problem-1148.json  \n",
            "  inflating: dataset3/validation/truth-problem-1149.json  \n",
            "  inflating: dataset3/validation/truth-problem-115.json  \n",
            "  inflating: dataset3/validation/truth-problem-1150.json  \n",
            "  inflating: dataset3/validation/truth-problem-1151.json  \n",
            "  inflating: dataset3/validation/truth-problem-1152.json  \n",
            "  inflating: dataset3/validation/truth-problem-1153.json  \n",
            "  inflating: dataset3/validation/truth-problem-1154.json  \n",
            "  inflating: dataset3/validation/truth-problem-1155.json  \n",
            "  inflating: dataset3/validation/truth-problem-1156.json  \n",
            "  inflating: dataset3/validation/truth-problem-1157.json  \n",
            "  inflating: dataset3/validation/truth-problem-1158.json  \n",
            "  inflating: dataset3/validation/truth-problem-1159.json  \n",
            "  inflating: dataset3/validation/truth-problem-116.json  \n",
            "  inflating: dataset3/validation/truth-problem-1160.json  \n",
            "  inflating: dataset3/validation/truth-problem-1161.json  \n",
            "  inflating: dataset3/validation/truth-problem-1162.json  \n",
            "  inflating: dataset3/validation/truth-problem-1163.json  \n",
            "  inflating: dataset3/validation/truth-problem-1164.json  \n",
            "  inflating: dataset3/validation/truth-problem-1165.json  \n",
            "  inflating: dataset3/validation/truth-problem-1166.json  \n",
            "  inflating: dataset3/validation/truth-problem-1167.json  \n",
            "  inflating: dataset3/validation/truth-problem-1168.json  \n",
            "  inflating: dataset3/validation/truth-problem-1169.json  \n",
            "  inflating: dataset3/validation/truth-problem-117.json  \n",
            "  inflating: dataset3/validation/truth-problem-1170.json  \n",
            "  inflating: dataset3/validation/truth-problem-1171.json  \n",
            "  inflating: dataset3/validation/truth-problem-1172.json  \n",
            "  inflating: dataset3/validation/truth-problem-1173.json  \n",
            "  inflating: dataset3/validation/truth-problem-1174.json  \n",
            "  inflating: dataset3/validation/truth-problem-1175.json  \n",
            "  inflating: dataset3/validation/truth-problem-1176.json  \n",
            "  inflating: dataset3/validation/truth-problem-1177.json  \n",
            "  inflating: dataset3/validation/truth-problem-1178.json  \n",
            "  inflating: dataset3/validation/truth-problem-1179.json  \n",
            "  inflating: dataset3/validation/truth-problem-118.json  \n",
            "  inflating: dataset3/validation/truth-problem-1180.json  \n",
            "  inflating: dataset3/validation/truth-problem-1181.json  \n",
            "  inflating: dataset3/validation/truth-problem-1182.json  \n",
            "  inflating: dataset3/validation/truth-problem-1183.json  \n",
            "  inflating: dataset3/validation/truth-problem-1184.json  \n",
            "  inflating: dataset3/validation/truth-problem-1185.json  \n",
            "  inflating: dataset3/validation/truth-problem-1186.json  \n",
            "  inflating: dataset3/validation/truth-problem-1187.json  \n",
            "  inflating: dataset3/validation/truth-problem-1188.json  \n",
            "  inflating: dataset3/validation/truth-problem-1189.json  \n",
            "  inflating: dataset3/validation/truth-problem-119.json  \n",
            "  inflating: dataset3/validation/truth-problem-1190.json  \n",
            "  inflating: dataset3/validation/truth-problem-1191.json  \n",
            "  inflating: dataset3/validation/truth-problem-1192.json  \n",
            "  inflating: dataset3/validation/truth-problem-1193.json  \n",
            "  inflating: dataset3/validation/truth-problem-1194.json  \n",
            "  inflating: dataset3/validation/truth-problem-1195.json  \n",
            "  inflating: dataset3/validation/truth-problem-1196.json  \n",
            "  inflating: dataset3/validation/truth-problem-1197.json  \n",
            "  inflating: dataset3/validation/truth-problem-1198.json  \n",
            "  inflating: dataset3/validation/truth-problem-1199.json  \n",
            "  inflating: dataset3/validation/truth-problem-12.json  \n",
            "  inflating: dataset3/validation/truth-problem-120.json  \n",
            "  inflating: dataset3/validation/truth-problem-1200.json  \n",
            "  inflating: dataset3/validation/truth-problem-1201.json  \n",
            "  inflating: dataset3/validation/truth-problem-1202.json  \n",
            "  inflating: dataset3/validation/truth-problem-1203.json  \n",
            "  inflating: dataset3/validation/truth-problem-1204.json  \n",
            "  inflating: dataset3/validation/truth-problem-1205.json  \n",
            "  inflating: dataset3/validation/truth-problem-1206.json  \n",
            "  inflating: dataset3/validation/truth-problem-1207.json  \n",
            "  inflating: dataset3/validation/truth-problem-1208.json  \n",
            "  inflating: dataset3/validation/truth-problem-1209.json  \n",
            "  inflating: dataset3/validation/truth-problem-121.json  \n",
            "  inflating: dataset3/validation/truth-problem-1210.json  \n",
            "  inflating: dataset3/validation/truth-problem-1211.json  \n",
            "  inflating: dataset3/validation/truth-problem-1212.json  \n",
            "  inflating: dataset3/validation/truth-problem-1213.json  \n",
            "  inflating: dataset3/validation/truth-problem-1214.json  \n",
            "  inflating: dataset3/validation/truth-problem-1215.json  \n",
            "  inflating: dataset3/validation/truth-problem-1216.json  \n",
            "  inflating: dataset3/validation/truth-problem-1217.json  \n",
            "  inflating: dataset3/validation/truth-problem-1218.json  \n",
            "  inflating: dataset3/validation/truth-problem-1219.json  \n",
            "  inflating: dataset3/validation/truth-problem-122.json  \n",
            "  inflating: dataset3/validation/truth-problem-1220.json  \n",
            "  inflating: dataset3/validation/truth-problem-1221.json  \n",
            "  inflating: dataset3/validation/truth-problem-1222.json  \n",
            "  inflating: dataset3/validation/truth-problem-1223.json  \n",
            "  inflating: dataset3/validation/truth-problem-1224.json  \n",
            "  inflating: dataset3/validation/truth-problem-1225.json  \n",
            "  inflating: dataset3/validation/truth-problem-1226.json  \n",
            "  inflating: dataset3/validation/truth-problem-1227.json  \n",
            "  inflating: dataset3/validation/truth-problem-1228.json  \n",
            "  inflating: dataset3/validation/truth-problem-1229.json  \n",
            "  inflating: dataset3/validation/truth-problem-123.json  \n",
            "  inflating: dataset3/validation/truth-problem-1230.json  \n",
            "  inflating: dataset3/validation/truth-problem-1231.json  \n",
            "  inflating: dataset3/validation/truth-problem-1232.json  \n",
            "  inflating: dataset3/validation/truth-problem-1233.json  \n",
            "  inflating: dataset3/validation/truth-problem-1234.json  \n",
            "  inflating: dataset3/validation/truth-problem-1235.json  \n",
            "  inflating: dataset3/validation/truth-problem-1236.json  \n",
            "  inflating: dataset3/validation/truth-problem-1237.json  \n",
            "  inflating: dataset3/validation/truth-problem-1238.json  \n",
            "  inflating: dataset3/validation/truth-problem-1239.json  \n",
            "  inflating: dataset3/validation/truth-problem-124.json  \n",
            "  inflating: dataset3/validation/truth-problem-1240.json  \n",
            "  inflating: dataset3/validation/truth-problem-1241.json  \n",
            "  inflating: dataset3/validation/truth-problem-1242.json  \n",
            "  inflating: dataset3/validation/truth-problem-1243.json  \n",
            "  inflating: dataset3/validation/truth-problem-1244.json  \n",
            "  inflating: dataset3/validation/truth-problem-1245.json  \n",
            "  inflating: dataset3/validation/truth-problem-1246.json  \n",
            "  inflating: dataset3/validation/truth-problem-1247.json  \n",
            "  inflating: dataset3/validation/truth-problem-1248.json  \n",
            "  inflating: dataset3/validation/truth-problem-1249.json  \n",
            "  inflating: dataset3/validation/truth-problem-125.json  \n",
            "  inflating: dataset3/validation/truth-problem-1250.json  \n",
            "  inflating: dataset3/validation/truth-problem-1251.json  \n",
            "  inflating: dataset3/validation/truth-problem-1252.json  \n",
            "  inflating: dataset3/validation/truth-problem-1253.json  \n",
            "  inflating: dataset3/validation/truth-problem-1254.json  \n",
            "  inflating: dataset3/validation/truth-problem-1255.json  \n",
            "  inflating: dataset3/validation/truth-problem-1256.json  \n",
            "  inflating: dataset3/validation/truth-problem-1257.json  \n",
            "  inflating: dataset3/validation/truth-problem-1258.json  \n",
            "  inflating: dataset3/validation/truth-problem-1259.json  \n",
            "  inflating: dataset3/validation/truth-problem-126.json  \n",
            "  inflating: dataset3/validation/truth-problem-1260.json  \n",
            "  inflating: dataset3/validation/truth-problem-1261.json  \n",
            "  inflating: dataset3/validation/truth-problem-1262.json  \n",
            "  inflating: dataset3/validation/truth-problem-1263.json  \n",
            "  inflating: dataset3/validation/truth-problem-1264.json  \n",
            "  inflating: dataset3/validation/truth-problem-1265.json  \n",
            "  inflating: dataset3/validation/truth-problem-1266.json  \n",
            "  inflating: dataset3/validation/truth-problem-1267.json  \n",
            "  inflating: dataset3/validation/truth-problem-1268.json  \n",
            "  inflating: dataset3/validation/truth-problem-1269.json  \n",
            "  inflating: dataset3/validation/truth-problem-127.json  \n",
            "  inflating: dataset3/validation/truth-problem-1270.json  \n",
            "  inflating: dataset3/validation/truth-problem-1271.json  \n",
            "  inflating: dataset3/validation/truth-problem-1272.json  \n",
            "  inflating: dataset3/validation/truth-problem-1273.json  \n",
            "  inflating: dataset3/validation/truth-problem-1274.json  \n",
            "  inflating: dataset3/validation/truth-problem-1275.json  \n",
            "  inflating: dataset3/validation/truth-problem-1276.json  \n",
            "  inflating: dataset3/validation/truth-problem-1277.json  \n",
            "  inflating: dataset3/validation/truth-problem-1278.json  \n",
            "  inflating: dataset3/validation/truth-problem-1279.json  \n",
            "  inflating: dataset3/validation/truth-problem-128.json  \n",
            "  inflating: dataset3/validation/truth-problem-1280.json  \n",
            "  inflating: dataset3/validation/truth-problem-1281.json  \n",
            "  inflating: dataset3/validation/truth-problem-1282.json  \n",
            "  inflating: dataset3/validation/truth-problem-1283.json  \n",
            "  inflating: dataset3/validation/truth-problem-1284.json  \n",
            "  inflating: dataset3/validation/truth-problem-1285.json  \n",
            "  inflating: dataset3/validation/truth-problem-1286.json  \n",
            "  inflating: dataset3/validation/truth-problem-1287.json  \n",
            "  inflating: dataset3/validation/truth-problem-1288.json  \n",
            "  inflating: dataset3/validation/truth-problem-1289.json  \n",
            "  inflating: dataset3/validation/truth-problem-129.json  \n",
            "  inflating: dataset3/validation/truth-problem-1290.json  \n",
            "  inflating: dataset3/validation/truth-problem-1291.json  \n",
            "  inflating: dataset3/validation/truth-problem-1292.json  \n",
            "  inflating: dataset3/validation/truth-problem-1293.json  \n",
            "  inflating: dataset3/validation/truth-problem-1294.json  \n",
            "  inflating: dataset3/validation/truth-problem-1295.json  \n",
            "  inflating: dataset3/validation/truth-problem-1296.json  \n",
            "  inflating: dataset3/validation/truth-problem-1297.json  \n",
            "  inflating: dataset3/validation/truth-problem-1298.json  \n",
            "  inflating: dataset3/validation/truth-problem-1299.json  \n",
            "  inflating: dataset3/validation/truth-problem-13.json  \n",
            "  inflating: dataset3/validation/truth-problem-130.json  \n",
            "  inflating: dataset3/validation/truth-problem-1300.json  \n",
            "  inflating: dataset3/validation/truth-problem-1301.json  \n",
            "  inflating: dataset3/validation/truth-problem-1302.json  \n",
            "  inflating: dataset3/validation/truth-problem-1303.json  \n",
            "  inflating: dataset3/validation/truth-problem-1304.json  \n",
            "  inflating: dataset3/validation/truth-problem-1305.json  \n",
            "  inflating: dataset3/validation/truth-problem-1306.json  \n",
            "  inflating: dataset3/validation/truth-problem-1307.json  \n",
            "  inflating: dataset3/validation/truth-problem-1308.json  \n",
            "  inflating: dataset3/validation/truth-problem-1309.json  \n",
            "  inflating: dataset3/validation/truth-problem-131.json  \n",
            "  inflating: dataset3/validation/truth-problem-1310.json  \n",
            "  inflating: dataset3/validation/truth-problem-1311.json  \n",
            "  inflating: dataset3/validation/truth-problem-1312.json  \n",
            "  inflating: dataset3/validation/truth-problem-1313.json  \n",
            "  inflating: dataset3/validation/truth-problem-1314.json  \n",
            "  inflating: dataset3/validation/truth-problem-1315.json  \n",
            "  inflating: dataset3/validation/truth-problem-1316.json  \n",
            "  inflating: dataset3/validation/truth-problem-1317.json  \n",
            "  inflating: dataset3/validation/truth-problem-1318.json  \n",
            "  inflating: dataset3/validation/truth-problem-1319.json  \n",
            "  inflating: dataset3/validation/truth-problem-132.json  \n",
            "  inflating: dataset3/validation/truth-problem-1320.json  \n",
            "  inflating: dataset3/validation/truth-problem-1321.json  \n",
            "  inflating: dataset3/validation/truth-problem-1322.json  \n",
            "  inflating: dataset3/validation/truth-problem-1323.json  \n",
            "  inflating: dataset3/validation/truth-problem-1324.json  \n",
            "  inflating: dataset3/validation/truth-problem-1325.json  \n",
            "  inflating: dataset3/validation/truth-problem-1326.json  \n",
            "  inflating: dataset3/validation/truth-problem-1327.json  \n",
            "  inflating: dataset3/validation/truth-problem-1328.json  \n",
            "  inflating: dataset3/validation/truth-problem-1329.json  \n",
            "  inflating: dataset3/validation/truth-problem-133.json  \n",
            "  inflating: dataset3/validation/truth-problem-1330.json  \n",
            "  inflating: dataset3/validation/truth-problem-1331.json  \n",
            "  inflating: dataset3/validation/truth-problem-1332.json  \n",
            "  inflating: dataset3/validation/truth-problem-1333.json  \n",
            "  inflating: dataset3/validation/truth-problem-1334.json  \n",
            "  inflating: dataset3/validation/truth-problem-1335.json  \n",
            "  inflating: dataset3/validation/truth-problem-1336.json  \n",
            "  inflating: dataset3/validation/truth-problem-1337.json  \n",
            "  inflating: dataset3/validation/truth-problem-1338.json  \n",
            "  inflating: dataset3/validation/truth-problem-1339.json  \n",
            "  inflating: dataset3/validation/truth-problem-134.json  \n",
            "  inflating: dataset3/validation/truth-problem-1340.json  \n",
            "  inflating: dataset3/validation/truth-problem-1341.json  \n",
            "  inflating: dataset3/validation/truth-problem-1342.json  \n",
            "  inflating: dataset3/validation/truth-problem-1343.json  \n",
            "  inflating: dataset3/validation/truth-problem-1344.json  \n",
            "  inflating: dataset3/validation/truth-problem-1345.json  \n",
            "  inflating: dataset3/validation/truth-problem-1346.json  \n",
            "  inflating: dataset3/validation/truth-problem-1347.json  \n",
            "  inflating: dataset3/validation/truth-problem-1348.json  \n",
            "  inflating: dataset3/validation/truth-problem-1349.json  \n",
            "  inflating: dataset3/validation/truth-problem-135.json  \n",
            "  inflating: dataset3/validation/truth-problem-1350.json  \n",
            "  inflating: dataset3/validation/truth-problem-1351.json  \n",
            "  inflating: dataset3/validation/truth-problem-1352.json  \n",
            "  inflating: dataset3/validation/truth-problem-1353.json  \n",
            "  inflating: dataset3/validation/truth-problem-1354.json  \n",
            "  inflating: dataset3/validation/truth-problem-1355.json  \n",
            "  inflating: dataset3/validation/truth-problem-1356.json  \n",
            "  inflating: dataset3/validation/truth-problem-1357.json  \n",
            "  inflating: dataset3/validation/truth-problem-1358.json  \n",
            "  inflating: dataset3/validation/truth-problem-1359.json  \n",
            "  inflating: dataset3/validation/truth-problem-136.json  \n",
            "  inflating: dataset3/validation/truth-problem-1360.json  \n",
            "  inflating: dataset3/validation/truth-problem-1361.json  \n",
            "  inflating: dataset3/validation/truth-problem-1362.json  \n",
            "  inflating: dataset3/validation/truth-problem-1363.json  \n",
            "  inflating: dataset3/validation/truth-problem-1364.json  \n",
            "  inflating: dataset3/validation/truth-problem-1365.json  \n",
            "  inflating: dataset3/validation/truth-problem-1366.json  \n",
            "  inflating: dataset3/validation/truth-problem-1367.json  \n",
            "  inflating: dataset3/validation/truth-problem-1368.json  \n",
            "  inflating: dataset3/validation/truth-problem-1369.json  \n",
            "  inflating: dataset3/validation/truth-problem-137.json  \n",
            "  inflating: dataset3/validation/truth-problem-1370.json  \n",
            "  inflating: dataset3/validation/truth-problem-1371.json  \n",
            "  inflating: dataset3/validation/truth-problem-1372.json  \n",
            "  inflating: dataset3/validation/truth-problem-1373.json  \n",
            "  inflating: dataset3/validation/truth-problem-1374.json  \n",
            "  inflating: dataset3/validation/truth-problem-1375.json  \n",
            "  inflating: dataset3/validation/truth-problem-1376.json  \n",
            "  inflating: dataset3/validation/truth-problem-1377.json  \n",
            "  inflating: dataset3/validation/truth-problem-1378.json  \n",
            "  inflating: dataset3/validation/truth-problem-1379.json  \n",
            "  inflating: dataset3/validation/truth-problem-138.json  \n",
            "  inflating: dataset3/validation/truth-problem-1380.json  \n",
            "  inflating: dataset3/validation/truth-problem-1381.json  \n",
            "  inflating: dataset3/validation/truth-problem-1382.json  \n",
            "  inflating: dataset3/validation/truth-problem-1383.json  \n",
            "  inflating: dataset3/validation/truth-problem-1384.json  \n",
            "  inflating: dataset3/validation/truth-problem-1385.json  \n",
            "  inflating: dataset3/validation/truth-problem-1386.json  \n",
            "  inflating: dataset3/validation/truth-problem-1387.json  \n",
            "  inflating: dataset3/validation/truth-problem-1388.json  \n",
            "  inflating: dataset3/validation/truth-problem-1389.json  \n",
            "  inflating: dataset3/validation/truth-problem-139.json  \n",
            "  inflating: dataset3/validation/truth-problem-1390.json  \n",
            "  inflating: dataset3/validation/truth-problem-1391.json  \n",
            "  inflating: dataset3/validation/truth-problem-1392.json  \n",
            "  inflating: dataset3/validation/truth-problem-1393.json  \n",
            "  inflating: dataset3/validation/truth-problem-1394.json  \n",
            "  inflating: dataset3/validation/truth-problem-1395.json  \n",
            "  inflating: dataset3/validation/truth-problem-1396.json  \n",
            "  inflating: dataset3/validation/truth-problem-1397.json  \n",
            "  inflating: dataset3/validation/truth-problem-1398.json  \n",
            "  inflating: dataset3/validation/truth-problem-1399.json  \n",
            "  inflating: dataset3/validation/truth-problem-14.json  \n",
            "  inflating: dataset3/validation/truth-problem-140.json  \n",
            "  inflating: dataset3/validation/truth-problem-1400.json  \n",
            "  inflating: dataset3/validation/truth-problem-1401.json  \n",
            "  inflating: dataset3/validation/truth-problem-1402.json  \n",
            "  inflating: dataset3/validation/truth-problem-1403.json  \n",
            "  inflating: dataset3/validation/truth-problem-1404.json  \n",
            "  inflating: dataset3/validation/truth-problem-1405.json  \n",
            "  inflating: dataset3/validation/truth-problem-1406.json  \n",
            "  inflating: dataset3/validation/truth-problem-1407.json  \n",
            "  inflating: dataset3/validation/truth-problem-1408.json  \n",
            "  inflating: dataset3/validation/truth-problem-1409.json  \n",
            "  inflating: dataset3/validation/truth-problem-141.json  \n",
            "  inflating: dataset3/validation/truth-problem-1410.json  \n",
            "  inflating: dataset3/validation/truth-problem-1411.json  \n",
            "  inflating: dataset3/validation/truth-problem-1412.json  \n",
            "  inflating: dataset3/validation/truth-problem-1413.json  \n",
            "  inflating: dataset3/validation/truth-problem-1414.json  \n",
            "  inflating: dataset3/validation/truth-problem-1415.json  \n",
            "  inflating: dataset3/validation/truth-problem-1416.json  \n",
            "  inflating: dataset3/validation/truth-problem-1417.json  \n",
            "  inflating: dataset3/validation/truth-problem-1418.json  \n",
            "  inflating: dataset3/validation/truth-problem-1419.json  \n",
            "  inflating: dataset3/validation/truth-problem-142.json  \n",
            "  inflating: dataset3/validation/truth-problem-1420.json  \n",
            "  inflating: dataset3/validation/truth-problem-1421.json  \n",
            "  inflating: dataset3/validation/truth-problem-1422.json  \n",
            "  inflating: dataset3/validation/truth-problem-1423.json  \n",
            "  inflating: dataset3/validation/truth-problem-1424.json  \n",
            "  inflating: dataset3/validation/truth-problem-1425.json  \n",
            "  inflating: dataset3/validation/truth-problem-1426.json  \n",
            "  inflating: dataset3/validation/truth-problem-1427.json  \n",
            "  inflating: dataset3/validation/truth-problem-1428.json  \n",
            "  inflating: dataset3/validation/truth-problem-1429.json  \n",
            "  inflating: dataset3/validation/truth-problem-143.json  \n",
            "  inflating: dataset3/validation/truth-problem-1430.json  \n",
            "  inflating: dataset3/validation/truth-problem-1431.json  \n",
            "  inflating: dataset3/validation/truth-problem-1432.json  \n",
            "  inflating: dataset3/validation/truth-problem-1433.json  \n",
            "  inflating: dataset3/validation/truth-problem-1434.json  \n",
            "  inflating: dataset3/validation/truth-problem-1435.json  \n",
            "  inflating: dataset3/validation/truth-problem-1436.json  \n",
            "  inflating: dataset3/validation/truth-problem-1437.json  \n",
            "  inflating: dataset3/validation/truth-problem-1438.json  \n",
            "  inflating: dataset3/validation/truth-problem-1439.json  \n",
            "  inflating: dataset3/validation/truth-problem-144.json  \n",
            "  inflating: dataset3/validation/truth-problem-1440.json  \n",
            "  inflating: dataset3/validation/truth-problem-1441.json  \n",
            "  inflating: dataset3/validation/truth-problem-1442.json  \n",
            "  inflating: dataset3/validation/truth-problem-1443.json  \n",
            "  inflating: dataset3/validation/truth-problem-1444.json  \n",
            "  inflating: dataset3/validation/truth-problem-1445.json  \n",
            "  inflating: dataset3/validation/truth-problem-1446.json  \n",
            "  inflating: dataset3/validation/truth-problem-1447.json  \n",
            "  inflating: dataset3/validation/truth-problem-1448.json  \n",
            "  inflating: dataset3/validation/truth-problem-1449.json  \n",
            "  inflating: dataset3/validation/truth-problem-145.json  \n",
            "  inflating: dataset3/validation/truth-problem-1450.json  \n",
            "  inflating: dataset3/validation/truth-problem-1451.json  \n",
            "  inflating: dataset3/validation/truth-problem-1452.json  \n",
            "  inflating: dataset3/validation/truth-problem-1453.json  \n",
            "  inflating: dataset3/validation/truth-problem-1454.json  \n",
            "  inflating: dataset3/validation/truth-problem-1455.json  \n",
            "  inflating: dataset3/validation/truth-problem-1456.json  \n",
            "  inflating: dataset3/validation/truth-problem-1457.json  \n",
            "  inflating: dataset3/validation/truth-problem-1458.json  \n",
            "  inflating: dataset3/validation/truth-problem-1459.json  \n",
            "  inflating: dataset3/validation/truth-problem-146.json  \n",
            "  inflating: dataset3/validation/truth-problem-1460.json  \n",
            "  inflating: dataset3/validation/truth-problem-1461.json  \n",
            "  inflating: dataset3/validation/truth-problem-1462.json  \n",
            "  inflating: dataset3/validation/truth-problem-1463.json  \n",
            "  inflating: dataset3/validation/truth-problem-1464.json  \n",
            "  inflating: dataset3/validation/truth-problem-1465.json  \n",
            "  inflating: dataset3/validation/truth-problem-1466.json  \n",
            "  inflating: dataset3/validation/truth-problem-1467.json  \n",
            "  inflating: dataset3/validation/truth-problem-1468.json  \n",
            "  inflating: dataset3/validation/truth-problem-1469.json  \n",
            "  inflating: dataset3/validation/truth-problem-147.json  \n",
            "  inflating: dataset3/validation/truth-problem-1470.json  \n",
            "  inflating: dataset3/validation/truth-problem-1471.json  \n",
            "  inflating: dataset3/validation/truth-problem-1472.json  \n",
            "  inflating: dataset3/validation/truth-problem-1473.json  \n",
            "  inflating: dataset3/validation/truth-problem-1474.json  \n",
            "  inflating: dataset3/validation/truth-problem-1475.json  \n",
            "  inflating: dataset3/validation/truth-problem-1476.json  \n",
            "  inflating: dataset3/validation/truth-problem-1477.json  \n",
            "  inflating: dataset3/validation/truth-problem-1478.json  \n",
            "  inflating: dataset3/validation/truth-problem-1479.json  \n",
            "  inflating: dataset3/validation/truth-problem-148.json  \n",
            "  inflating: dataset3/validation/truth-problem-1480.json  \n",
            "  inflating: dataset3/validation/truth-problem-1481.json  \n",
            "  inflating: dataset3/validation/truth-problem-1482.json  \n",
            "  inflating: dataset3/validation/truth-problem-1483.json  \n",
            "  inflating: dataset3/validation/truth-problem-1484.json  \n",
            "  inflating: dataset3/validation/truth-problem-1485.json  \n",
            "  inflating: dataset3/validation/truth-problem-1486.json  \n",
            "  inflating: dataset3/validation/truth-problem-1487.json  \n",
            "  inflating: dataset3/validation/truth-problem-1488.json  \n",
            "  inflating: dataset3/validation/truth-problem-1489.json  \n",
            "  inflating: dataset3/validation/truth-problem-149.json  \n",
            "  inflating: dataset3/validation/truth-problem-1490.json  \n",
            "  inflating: dataset3/validation/truth-problem-1491.json  \n",
            "  inflating: dataset3/validation/truth-problem-1492.json  \n",
            "  inflating: dataset3/validation/truth-problem-1493.json  \n",
            "  inflating: dataset3/validation/truth-problem-1494.json  \n",
            "  inflating: dataset3/validation/truth-problem-1495.json  \n",
            "  inflating: dataset3/validation/truth-problem-1496.json  \n",
            "  inflating: dataset3/validation/truth-problem-1497.json  \n",
            "  inflating: dataset3/validation/truth-problem-1498.json  \n",
            "  inflating: dataset3/validation/truth-problem-1499.json  \n",
            "  inflating: dataset3/validation/truth-problem-15.json  \n",
            "  inflating: dataset3/validation/truth-problem-150.json  \n",
            "  inflating: dataset3/validation/truth-problem-1500.json  \n",
            "  inflating: dataset3/validation/truth-problem-151.json  \n",
            "  inflating: dataset3/validation/truth-problem-152.json  \n",
            "  inflating: dataset3/validation/truth-problem-153.json  \n",
            "  inflating: dataset3/validation/truth-problem-154.json  \n",
            "  inflating: dataset3/validation/truth-problem-155.json  \n",
            "  inflating: dataset3/validation/truth-problem-156.json  \n",
            "  inflating: dataset3/validation/truth-problem-157.json  \n",
            "  inflating: dataset3/validation/truth-problem-158.json  \n",
            "  inflating: dataset3/validation/truth-problem-159.json  \n",
            "  inflating: dataset3/validation/truth-problem-16.json  \n",
            "  inflating: dataset3/validation/truth-problem-160.json  \n",
            "  inflating: dataset3/validation/truth-problem-161.json  \n",
            "  inflating: dataset3/validation/truth-problem-162.json  \n",
            "  inflating: dataset3/validation/truth-problem-163.json  \n",
            "  inflating: dataset3/validation/truth-problem-164.json  \n",
            "  inflating: dataset3/validation/truth-problem-165.json  \n",
            "  inflating: dataset3/validation/truth-problem-166.json  \n",
            "  inflating: dataset3/validation/truth-problem-167.json  \n",
            "  inflating: dataset3/validation/truth-problem-168.json  \n",
            "  inflating: dataset3/validation/truth-problem-169.json  \n",
            "  inflating: dataset3/validation/truth-problem-17.json  \n",
            "  inflating: dataset3/validation/truth-problem-170.json  \n",
            "  inflating: dataset3/validation/truth-problem-171.json  \n",
            "  inflating: dataset3/validation/truth-problem-172.json  \n",
            "  inflating: dataset3/validation/truth-problem-173.json  \n",
            "  inflating: dataset3/validation/truth-problem-174.json  \n",
            "  inflating: dataset3/validation/truth-problem-175.json  \n",
            "  inflating: dataset3/validation/truth-problem-176.json  \n",
            "  inflating: dataset3/validation/truth-problem-177.json  \n",
            "  inflating: dataset3/validation/truth-problem-178.json  \n",
            "  inflating: dataset3/validation/truth-problem-179.json  \n",
            "  inflating: dataset3/validation/truth-problem-18.json  \n",
            "  inflating: dataset3/validation/truth-problem-180.json  \n",
            "  inflating: dataset3/validation/truth-problem-181.json  \n",
            "  inflating: dataset3/validation/truth-problem-182.json  \n",
            "  inflating: dataset3/validation/truth-problem-183.json  \n",
            "  inflating: dataset3/validation/truth-problem-184.json  \n",
            "  inflating: dataset3/validation/truth-problem-185.json  \n",
            "  inflating: dataset3/validation/truth-problem-186.json  \n",
            "  inflating: dataset3/validation/truth-problem-187.json  \n",
            "  inflating: dataset3/validation/truth-problem-188.json  \n",
            "  inflating: dataset3/validation/truth-problem-189.json  \n",
            "  inflating: dataset3/validation/truth-problem-19.json  \n",
            "  inflating: dataset3/validation/truth-problem-190.json  \n",
            "  inflating: dataset3/validation/truth-problem-191.json  \n",
            "  inflating: dataset3/validation/truth-problem-192.json  \n",
            "  inflating: dataset3/validation/truth-problem-193.json  \n",
            "  inflating: dataset3/validation/truth-problem-194.json  \n",
            "  inflating: dataset3/validation/truth-problem-195.json  \n",
            "  inflating: dataset3/validation/truth-problem-196.json  \n",
            "  inflating: dataset3/validation/truth-problem-197.json  \n",
            "  inflating: dataset3/validation/truth-problem-198.json  \n",
            "  inflating: dataset3/validation/truth-problem-199.json  \n",
            "  inflating: dataset3/validation/truth-problem-2.json  \n",
            "  inflating: dataset3/validation/truth-problem-20.json  \n",
            "  inflating: dataset3/validation/truth-problem-200.json  \n",
            "  inflating: dataset3/validation/truth-problem-201.json  \n",
            "  inflating: dataset3/validation/truth-problem-202.json  \n",
            "  inflating: dataset3/validation/truth-problem-203.json  \n",
            "  inflating: dataset3/validation/truth-problem-204.json  \n",
            "  inflating: dataset3/validation/truth-problem-205.json  \n",
            "  inflating: dataset3/validation/truth-problem-206.json  \n",
            "  inflating: dataset3/validation/truth-problem-207.json  \n",
            "  inflating: dataset3/validation/truth-problem-208.json  \n",
            "  inflating: dataset3/validation/truth-problem-209.json  \n",
            "  inflating: dataset3/validation/truth-problem-21.json  \n",
            "  inflating: dataset3/validation/truth-problem-210.json  \n",
            "  inflating: dataset3/validation/truth-problem-211.json  \n",
            "  inflating: dataset3/validation/truth-problem-212.json  \n",
            "  inflating: dataset3/validation/truth-problem-213.json  \n",
            "  inflating: dataset3/validation/truth-problem-214.json  \n",
            "  inflating: dataset3/validation/truth-problem-215.json  \n",
            "  inflating: dataset3/validation/truth-problem-216.json  \n",
            "  inflating: dataset3/validation/truth-problem-217.json  \n",
            "  inflating: dataset3/validation/truth-problem-218.json  \n",
            "  inflating: dataset3/validation/truth-problem-219.json  \n",
            "  inflating: dataset3/validation/truth-problem-22.json  \n",
            "  inflating: dataset3/validation/truth-problem-220.json  \n",
            "  inflating: dataset3/validation/truth-problem-221.json  \n",
            "  inflating: dataset3/validation/truth-problem-222.json  \n",
            "  inflating: dataset3/validation/truth-problem-223.json  \n",
            "  inflating: dataset3/validation/truth-problem-224.json  \n",
            "  inflating: dataset3/validation/truth-problem-225.json  \n",
            "  inflating: dataset3/validation/truth-problem-226.json  \n",
            "  inflating: dataset3/validation/truth-problem-227.json  \n",
            "  inflating: dataset3/validation/truth-problem-228.json  \n",
            "  inflating: dataset3/validation/truth-problem-229.json  \n",
            "  inflating: dataset3/validation/truth-problem-23.json  \n",
            "  inflating: dataset3/validation/truth-problem-230.json  \n",
            "  inflating: dataset3/validation/truth-problem-231.json  \n",
            "  inflating: dataset3/validation/truth-problem-232.json  \n",
            "  inflating: dataset3/validation/truth-problem-233.json  \n",
            "  inflating: dataset3/validation/truth-problem-234.json  \n",
            "  inflating: dataset3/validation/truth-problem-235.json  \n",
            "  inflating: dataset3/validation/truth-problem-236.json  \n",
            "  inflating: dataset3/validation/truth-problem-237.json  \n",
            "  inflating: dataset3/validation/truth-problem-238.json  \n",
            "  inflating: dataset3/validation/truth-problem-239.json  \n",
            "  inflating: dataset3/validation/truth-problem-24.json  \n",
            "  inflating: dataset3/validation/truth-problem-240.json  \n",
            "  inflating: dataset3/validation/truth-problem-241.json  \n",
            "  inflating: dataset3/validation/truth-problem-242.json  \n",
            "  inflating: dataset3/validation/truth-problem-243.json  \n",
            "  inflating: dataset3/validation/truth-problem-244.json  \n",
            "  inflating: dataset3/validation/truth-problem-245.json  \n",
            "  inflating: dataset3/validation/truth-problem-246.json  \n",
            "  inflating: dataset3/validation/truth-problem-247.json  \n",
            "  inflating: dataset3/validation/truth-problem-248.json  \n",
            "  inflating: dataset3/validation/truth-problem-249.json  \n",
            "  inflating: dataset3/validation/truth-problem-25.json  \n",
            "  inflating: dataset3/validation/truth-problem-250.json  \n",
            "  inflating: dataset3/validation/truth-problem-251.json  \n",
            "  inflating: dataset3/validation/truth-problem-252.json  \n",
            "  inflating: dataset3/validation/truth-problem-253.json  \n",
            "  inflating: dataset3/validation/truth-problem-254.json  \n",
            "  inflating: dataset3/validation/truth-problem-255.json  \n",
            "  inflating: dataset3/validation/truth-problem-256.json  \n",
            "  inflating: dataset3/validation/truth-problem-257.json  \n",
            "  inflating: dataset3/validation/truth-problem-258.json  \n",
            "  inflating: dataset3/validation/truth-problem-259.json  \n",
            "  inflating: dataset3/validation/truth-problem-26.json  \n",
            "  inflating: dataset3/validation/truth-problem-260.json  \n",
            "  inflating: dataset3/validation/truth-problem-261.json  \n",
            "  inflating: dataset3/validation/truth-problem-262.json  \n",
            "  inflating: dataset3/validation/truth-problem-263.json  \n",
            "  inflating: dataset3/validation/truth-problem-264.json  \n",
            "  inflating: dataset3/validation/truth-problem-265.json  \n",
            "  inflating: dataset3/validation/truth-problem-266.json  \n",
            "  inflating: dataset3/validation/truth-problem-267.json  \n",
            "  inflating: dataset3/validation/truth-problem-268.json  \n",
            "  inflating: dataset3/validation/truth-problem-269.json  \n",
            "  inflating: dataset3/validation/truth-problem-27.json  \n",
            "  inflating: dataset3/validation/truth-problem-270.json  \n",
            "  inflating: dataset3/validation/truth-problem-271.json  \n",
            "  inflating: dataset3/validation/truth-problem-272.json  \n",
            "  inflating: dataset3/validation/truth-problem-273.json  \n",
            "  inflating: dataset3/validation/truth-problem-274.json  \n",
            "  inflating: dataset3/validation/truth-problem-275.json  \n",
            "  inflating: dataset3/validation/truth-problem-276.json  \n",
            "  inflating: dataset3/validation/truth-problem-277.json  \n",
            "  inflating: dataset3/validation/truth-problem-278.json  \n",
            "  inflating: dataset3/validation/truth-problem-279.json  \n",
            "  inflating: dataset3/validation/truth-problem-28.json  \n",
            "  inflating: dataset3/validation/truth-problem-280.json  \n",
            "  inflating: dataset3/validation/truth-problem-281.json  \n",
            "  inflating: dataset3/validation/truth-problem-282.json  \n",
            "  inflating: dataset3/validation/truth-problem-283.json  \n",
            "  inflating: dataset3/validation/truth-problem-284.json  \n",
            "  inflating: dataset3/validation/truth-problem-285.json  \n",
            "  inflating: dataset3/validation/truth-problem-286.json  \n",
            "  inflating: dataset3/validation/truth-problem-287.json  \n",
            "  inflating: dataset3/validation/truth-problem-288.json  \n",
            "  inflating: dataset3/validation/truth-problem-289.json  \n",
            "  inflating: dataset3/validation/truth-problem-29.json  \n",
            "  inflating: dataset3/validation/truth-problem-290.json  \n",
            "  inflating: dataset3/validation/truth-problem-291.json  \n",
            "  inflating: dataset3/validation/truth-problem-292.json  \n",
            "  inflating: dataset3/validation/truth-problem-293.json  \n",
            "  inflating: dataset3/validation/truth-problem-294.json  \n",
            "  inflating: dataset3/validation/truth-problem-295.json  \n",
            "  inflating: dataset3/validation/truth-problem-296.json  \n",
            "  inflating: dataset3/validation/truth-problem-297.json  \n",
            "  inflating: dataset3/validation/truth-problem-298.json  \n",
            "  inflating: dataset3/validation/truth-problem-299.json  \n",
            "  inflating: dataset3/validation/truth-problem-3.json  \n",
            "  inflating: dataset3/validation/truth-problem-30.json  \n",
            "  inflating: dataset3/validation/truth-problem-300.json  \n",
            "  inflating: dataset3/validation/truth-problem-301.json  \n",
            "  inflating: dataset3/validation/truth-problem-302.json  \n",
            "  inflating: dataset3/validation/truth-problem-303.json  \n",
            "  inflating: dataset3/validation/truth-problem-304.json  \n",
            "  inflating: dataset3/validation/truth-problem-305.json  \n",
            "  inflating: dataset3/validation/truth-problem-306.json  \n",
            "  inflating: dataset3/validation/truth-problem-307.json  \n",
            "  inflating: dataset3/validation/truth-problem-308.json  \n",
            "  inflating: dataset3/validation/truth-problem-309.json  \n",
            "  inflating: dataset3/validation/truth-problem-31.json  \n",
            "  inflating: dataset3/validation/truth-problem-310.json  \n",
            "  inflating: dataset3/validation/truth-problem-311.json  \n",
            "  inflating: dataset3/validation/truth-problem-312.json  \n",
            "  inflating: dataset3/validation/truth-problem-313.json  \n",
            "  inflating: dataset3/validation/truth-problem-314.json  \n",
            "  inflating: dataset3/validation/truth-problem-315.json  \n",
            "  inflating: dataset3/validation/truth-problem-316.json  \n",
            "  inflating: dataset3/validation/truth-problem-317.json  \n",
            "  inflating: dataset3/validation/truth-problem-318.json  \n",
            "  inflating: dataset3/validation/truth-problem-319.json  \n",
            "  inflating: dataset3/validation/truth-problem-32.json  \n",
            "  inflating: dataset3/validation/truth-problem-320.json  \n",
            "  inflating: dataset3/validation/truth-problem-321.json  \n",
            "  inflating: dataset3/validation/truth-problem-322.json  \n",
            "  inflating: dataset3/validation/truth-problem-323.json  \n",
            "  inflating: dataset3/validation/truth-problem-324.json  \n",
            "  inflating: dataset3/validation/truth-problem-325.json  \n",
            "  inflating: dataset3/validation/truth-problem-326.json  \n",
            "  inflating: dataset3/validation/truth-problem-327.json  \n",
            "  inflating: dataset3/validation/truth-problem-328.json  \n",
            "  inflating: dataset3/validation/truth-problem-329.json  \n",
            "  inflating: dataset3/validation/truth-problem-33.json  \n",
            "  inflating: dataset3/validation/truth-problem-330.json  \n",
            "  inflating: dataset3/validation/truth-problem-331.json  \n",
            "  inflating: dataset3/validation/truth-problem-332.json  \n",
            "  inflating: dataset3/validation/truth-problem-333.json  \n",
            "  inflating: dataset3/validation/truth-problem-334.json  \n",
            "  inflating: dataset3/validation/truth-problem-335.json  \n",
            "  inflating: dataset3/validation/truth-problem-336.json  \n",
            "  inflating: dataset3/validation/truth-problem-337.json  \n",
            "  inflating: dataset3/validation/truth-problem-338.json  \n",
            "  inflating: dataset3/validation/truth-problem-339.json  \n",
            "  inflating: dataset3/validation/truth-problem-34.json  \n",
            "  inflating: dataset3/validation/truth-problem-340.json  \n",
            "  inflating: dataset3/validation/truth-problem-341.json  \n",
            "  inflating: dataset3/validation/truth-problem-342.json  \n",
            "  inflating: dataset3/validation/truth-problem-343.json  \n",
            "  inflating: dataset3/validation/truth-problem-344.json  \n",
            "  inflating: dataset3/validation/truth-problem-345.json  \n",
            "  inflating: dataset3/validation/truth-problem-346.json  \n",
            "  inflating: dataset3/validation/truth-problem-347.json  \n",
            "  inflating: dataset3/validation/truth-problem-348.json  \n",
            "  inflating: dataset3/validation/truth-problem-349.json  \n",
            "  inflating: dataset3/validation/truth-problem-35.json  \n",
            "  inflating: dataset3/validation/truth-problem-350.json  \n",
            "  inflating: dataset3/validation/truth-problem-351.json  \n",
            "  inflating: dataset3/validation/truth-problem-352.json  \n",
            "  inflating: dataset3/validation/truth-problem-353.json  \n",
            "  inflating: dataset3/validation/truth-problem-354.json  \n",
            "  inflating: dataset3/validation/truth-problem-355.json  \n",
            "  inflating: dataset3/validation/truth-problem-356.json  \n",
            "  inflating: dataset3/validation/truth-problem-357.json  \n",
            "  inflating: dataset3/validation/truth-problem-358.json  \n",
            "  inflating: dataset3/validation/truth-problem-359.json  \n",
            "  inflating: dataset3/validation/truth-problem-36.json  \n",
            "  inflating: dataset3/validation/truth-problem-360.json  \n",
            "  inflating: dataset3/validation/truth-problem-361.json  \n",
            "  inflating: dataset3/validation/truth-problem-362.json  \n",
            "  inflating: dataset3/validation/truth-problem-363.json  \n",
            "  inflating: dataset3/validation/truth-problem-364.json  \n",
            "  inflating: dataset3/validation/truth-problem-365.json  \n",
            "  inflating: dataset3/validation/truth-problem-366.json  \n",
            "  inflating: dataset3/validation/truth-problem-367.json  \n",
            "  inflating: dataset3/validation/truth-problem-368.json  \n",
            "  inflating: dataset3/validation/truth-problem-369.json  \n",
            "  inflating: dataset3/validation/truth-problem-37.json  \n",
            "  inflating: dataset3/validation/truth-problem-370.json  \n",
            "  inflating: dataset3/validation/truth-problem-371.json  \n",
            "  inflating: dataset3/validation/truth-problem-372.json  \n",
            "  inflating: dataset3/validation/truth-problem-373.json  \n",
            "  inflating: dataset3/validation/truth-problem-374.json  \n",
            "  inflating: dataset3/validation/truth-problem-375.json  \n",
            "  inflating: dataset3/validation/truth-problem-376.json  \n",
            "  inflating: dataset3/validation/truth-problem-377.json  \n",
            "  inflating: dataset3/validation/truth-problem-378.json  \n",
            "  inflating: dataset3/validation/truth-problem-379.json  \n",
            "  inflating: dataset3/validation/truth-problem-38.json  \n",
            "  inflating: dataset3/validation/truth-problem-380.json  \n",
            "  inflating: dataset3/validation/truth-problem-381.json  \n",
            "  inflating: dataset3/validation/truth-problem-382.json  \n",
            "  inflating: dataset3/validation/truth-problem-383.json  \n",
            "  inflating: dataset3/validation/truth-problem-384.json  \n",
            "  inflating: dataset3/validation/truth-problem-385.json  \n",
            "  inflating: dataset3/validation/truth-problem-386.json  \n",
            "  inflating: dataset3/validation/truth-problem-387.json  \n",
            "  inflating: dataset3/validation/truth-problem-388.json  \n",
            "  inflating: dataset3/validation/truth-problem-389.json  \n",
            "  inflating: dataset3/validation/truth-problem-39.json  \n",
            "  inflating: dataset3/validation/truth-problem-390.json  \n",
            "  inflating: dataset3/validation/truth-problem-391.json  \n",
            "  inflating: dataset3/validation/truth-problem-392.json  \n",
            "  inflating: dataset3/validation/truth-problem-393.json  \n",
            "  inflating: dataset3/validation/truth-problem-394.json  \n",
            "  inflating: dataset3/validation/truth-problem-395.json  \n",
            "  inflating: dataset3/validation/truth-problem-396.json  \n",
            "  inflating: dataset3/validation/truth-problem-397.json  \n",
            "  inflating: dataset3/validation/truth-problem-398.json  \n",
            "  inflating: dataset3/validation/truth-problem-399.json  \n",
            "  inflating: dataset3/validation/truth-problem-4.json  \n",
            "  inflating: dataset3/validation/truth-problem-40.json  \n",
            "  inflating: dataset3/validation/truth-problem-400.json  \n",
            "  inflating: dataset3/validation/truth-problem-401.json  \n",
            "  inflating: dataset3/validation/truth-problem-402.json  \n",
            "  inflating: dataset3/validation/truth-problem-403.json  \n",
            "  inflating: dataset3/validation/truth-problem-404.json  \n",
            "  inflating: dataset3/validation/truth-problem-405.json  \n",
            "  inflating: dataset3/validation/truth-problem-406.json  \n",
            "  inflating: dataset3/validation/truth-problem-407.json  \n",
            "  inflating: dataset3/validation/truth-problem-408.json  \n",
            "  inflating: dataset3/validation/truth-problem-409.json  \n",
            "  inflating: dataset3/validation/truth-problem-41.json  \n",
            "  inflating: dataset3/validation/truth-problem-410.json  \n",
            "  inflating: dataset3/validation/truth-problem-411.json  \n",
            "  inflating: dataset3/validation/truth-problem-412.json  \n",
            "  inflating: dataset3/validation/truth-problem-413.json  \n",
            "  inflating: dataset3/validation/truth-problem-414.json  \n",
            "  inflating: dataset3/validation/truth-problem-415.json  \n",
            "  inflating: dataset3/validation/truth-problem-416.json  \n",
            "  inflating: dataset3/validation/truth-problem-417.json  \n",
            "  inflating: dataset3/validation/truth-problem-418.json  \n",
            "  inflating: dataset3/validation/truth-problem-419.json  \n",
            "  inflating: dataset3/validation/truth-problem-42.json  \n",
            "  inflating: dataset3/validation/truth-problem-420.json  \n",
            "  inflating: dataset3/validation/truth-problem-421.json  \n",
            "  inflating: dataset3/validation/truth-problem-422.json  \n",
            "  inflating: dataset3/validation/truth-problem-423.json  \n",
            "  inflating: dataset3/validation/truth-problem-424.json  \n",
            "  inflating: dataset3/validation/truth-problem-425.json  \n",
            "  inflating: dataset3/validation/truth-problem-426.json  \n",
            "  inflating: dataset3/validation/truth-problem-427.json  \n",
            "  inflating: dataset3/validation/truth-problem-428.json  \n",
            "  inflating: dataset3/validation/truth-problem-429.json  \n",
            "  inflating: dataset3/validation/truth-problem-43.json  \n",
            "  inflating: dataset3/validation/truth-problem-430.json  \n",
            "  inflating: dataset3/validation/truth-problem-431.json  \n",
            "  inflating: dataset3/validation/truth-problem-432.json  \n",
            "  inflating: dataset3/validation/truth-problem-433.json  \n",
            "  inflating: dataset3/validation/truth-problem-434.json  \n",
            "  inflating: dataset3/validation/truth-problem-435.json  \n",
            "  inflating: dataset3/validation/truth-problem-436.json  \n",
            "  inflating: dataset3/validation/truth-problem-437.json  \n",
            "  inflating: dataset3/validation/truth-problem-438.json  \n",
            "  inflating: dataset3/validation/truth-problem-439.json  \n",
            "  inflating: dataset3/validation/truth-problem-44.json  \n",
            "  inflating: dataset3/validation/truth-problem-440.json  \n",
            "  inflating: dataset3/validation/truth-problem-441.json  \n",
            "  inflating: dataset3/validation/truth-problem-442.json  \n",
            "  inflating: dataset3/validation/truth-problem-443.json  \n",
            "  inflating: dataset3/validation/truth-problem-444.json  \n",
            "  inflating: dataset3/validation/truth-problem-445.json  \n",
            "  inflating: dataset3/validation/truth-problem-446.json  \n",
            "  inflating: dataset3/validation/truth-problem-447.json  \n",
            "  inflating: dataset3/validation/truth-problem-448.json  \n",
            "  inflating: dataset3/validation/truth-problem-449.json  \n",
            "  inflating: dataset3/validation/truth-problem-45.json  \n",
            "  inflating: dataset3/validation/truth-problem-450.json  \n",
            "  inflating: dataset3/validation/truth-problem-451.json  \n",
            "  inflating: dataset3/validation/truth-problem-452.json  \n",
            "  inflating: dataset3/validation/truth-problem-453.json  \n",
            "  inflating: dataset3/validation/truth-problem-454.json  \n",
            "  inflating: dataset3/validation/truth-problem-455.json  \n",
            "  inflating: dataset3/validation/truth-problem-456.json  \n",
            "  inflating: dataset3/validation/truth-problem-457.json  \n",
            "  inflating: dataset3/validation/truth-problem-458.json  \n",
            "  inflating: dataset3/validation/truth-problem-459.json  \n",
            "  inflating: dataset3/validation/truth-problem-46.json  \n",
            "  inflating: dataset3/validation/truth-problem-460.json  \n",
            "  inflating: dataset3/validation/truth-problem-461.json  \n",
            "  inflating: dataset3/validation/truth-problem-462.json  \n",
            "  inflating: dataset3/validation/truth-problem-463.json  \n",
            "  inflating: dataset3/validation/truth-problem-464.json  \n",
            "  inflating: dataset3/validation/truth-problem-465.json  \n",
            "  inflating: dataset3/validation/truth-problem-466.json  \n",
            "  inflating: dataset3/validation/truth-problem-467.json  \n",
            "  inflating: dataset3/validation/truth-problem-468.json  \n",
            "  inflating: dataset3/validation/truth-problem-469.json  \n",
            "  inflating: dataset3/validation/truth-problem-47.json  \n",
            "  inflating: dataset3/validation/truth-problem-470.json  \n",
            "  inflating: dataset3/validation/truth-problem-471.json  \n",
            "  inflating: dataset3/validation/truth-problem-472.json  \n",
            "  inflating: dataset3/validation/truth-problem-473.json  \n",
            "  inflating: dataset3/validation/truth-problem-474.json  \n",
            "  inflating: dataset3/validation/truth-problem-475.json  \n",
            "  inflating: dataset3/validation/truth-problem-476.json  \n",
            "  inflating: dataset3/validation/truth-problem-477.json  \n",
            "  inflating: dataset3/validation/truth-problem-478.json  \n",
            "  inflating: dataset3/validation/truth-problem-479.json  \n",
            "  inflating: dataset3/validation/truth-problem-48.json  \n",
            "  inflating: dataset3/validation/truth-problem-480.json  \n",
            "  inflating: dataset3/validation/truth-problem-481.json  \n",
            "  inflating: dataset3/validation/truth-problem-482.json  \n",
            "  inflating: dataset3/validation/truth-problem-483.json  \n",
            "  inflating: dataset3/validation/truth-problem-484.json  \n",
            "  inflating: dataset3/validation/truth-problem-485.json  \n",
            "  inflating: dataset3/validation/truth-problem-486.json  \n",
            "  inflating: dataset3/validation/truth-problem-487.json  \n",
            "  inflating: dataset3/validation/truth-problem-488.json  \n",
            "  inflating: dataset3/validation/truth-problem-489.json  \n",
            "  inflating: dataset3/validation/truth-problem-49.json  \n",
            "  inflating: dataset3/validation/truth-problem-490.json  \n",
            "  inflating: dataset3/validation/truth-problem-491.json  \n",
            "  inflating: dataset3/validation/truth-problem-492.json  \n",
            "  inflating: dataset3/validation/truth-problem-493.json  \n",
            "  inflating: dataset3/validation/truth-problem-494.json  \n",
            "  inflating: dataset3/validation/truth-problem-495.json  \n",
            "  inflating: dataset3/validation/truth-problem-496.json  \n",
            "  inflating: dataset3/validation/truth-problem-497.json  \n",
            "  inflating: dataset3/validation/truth-problem-498.json  \n",
            "  inflating: dataset3/validation/truth-problem-499.json  \n",
            "  inflating: dataset3/validation/truth-problem-5.json  \n",
            "  inflating: dataset3/validation/truth-problem-50.json  \n",
            "  inflating: dataset3/validation/truth-problem-500.json  \n",
            "  inflating: dataset3/validation/truth-problem-501.json  \n",
            "  inflating: dataset3/validation/truth-problem-502.json  \n",
            "  inflating: dataset3/validation/truth-problem-503.json  \n",
            "  inflating: dataset3/validation/truth-problem-504.json  \n",
            "  inflating: dataset3/validation/truth-problem-505.json  \n",
            "  inflating: dataset3/validation/truth-problem-506.json  \n",
            "  inflating: dataset3/validation/truth-problem-507.json  \n",
            "  inflating: dataset3/validation/truth-problem-508.json  \n",
            "  inflating: dataset3/validation/truth-problem-509.json  \n",
            "  inflating: dataset3/validation/truth-problem-51.json  \n",
            "  inflating: dataset3/validation/truth-problem-510.json  \n",
            "  inflating: dataset3/validation/truth-problem-511.json  \n",
            "  inflating: dataset3/validation/truth-problem-512.json  \n",
            "  inflating: dataset3/validation/truth-problem-513.json  \n",
            "  inflating: dataset3/validation/truth-problem-514.json  \n",
            "  inflating: dataset3/validation/truth-problem-515.json  \n",
            "  inflating: dataset3/validation/truth-problem-516.json  \n",
            "  inflating: dataset3/validation/truth-problem-517.json  \n",
            "  inflating: dataset3/validation/truth-problem-518.json  \n",
            "  inflating: dataset3/validation/truth-problem-519.json  \n",
            "  inflating: dataset3/validation/truth-problem-52.json  \n",
            "  inflating: dataset3/validation/truth-problem-520.json  \n",
            "  inflating: dataset3/validation/truth-problem-521.json  \n",
            "  inflating: dataset3/validation/truth-problem-522.json  \n",
            "  inflating: dataset3/validation/truth-problem-523.json  \n",
            "  inflating: dataset3/validation/truth-problem-524.json  \n",
            "  inflating: dataset3/validation/truth-problem-525.json  \n",
            "  inflating: dataset3/validation/truth-problem-526.json  \n",
            "  inflating: dataset3/validation/truth-problem-527.json  \n",
            "  inflating: dataset3/validation/truth-problem-528.json  \n",
            "  inflating: dataset3/validation/truth-problem-529.json  \n",
            "  inflating: dataset3/validation/truth-problem-53.json  \n",
            "  inflating: dataset3/validation/truth-problem-530.json  \n",
            "  inflating: dataset3/validation/truth-problem-531.json  \n",
            "  inflating: dataset3/validation/truth-problem-532.json  \n",
            "  inflating: dataset3/validation/truth-problem-533.json  \n",
            "  inflating: dataset3/validation/truth-problem-534.json  \n",
            "  inflating: dataset3/validation/truth-problem-535.json  \n",
            "  inflating: dataset3/validation/truth-problem-536.json  \n",
            "  inflating: dataset3/validation/truth-problem-537.json  \n",
            "  inflating: dataset3/validation/truth-problem-538.json  \n",
            "  inflating: dataset3/validation/truth-problem-539.json  \n",
            "  inflating: dataset3/validation/truth-problem-54.json  \n",
            "  inflating: dataset3/validation/truth-problem-540.json  \n",
            "  inflating: dataset3/validation/truth-problem-541.json  \n",
            "  inflating: dataset3/validation/truth-problem-542.json  \n",
            "  inflating: dataset3/validation/truth-problem-543.json  \n",
            "  inflating: dataset3/validation/truth-problem-544.json  \n",
            "  inflating: dataset3/validation/truth-problem-545.json  \n",
            "  inflating: dataset3/validation/truth-problem-546.json  \n",
            "  inflating: dataset3/validation/truth-problem-547.json  \n",
            "  inflating: dataset3/validation/truth-problem-548.json  \n",
            "  inflating: dataset3/validation/truth-problem-549.json  \n",
            "  inflating: dataset3/validation/truth-problem-55.json  \n",
            "  inflating: dataset3/validation/truth-problem-550.json  \n",
            "  inflating: dataset3/validation/truth-problem-551.json  \n",
            "  inflating: dataset3/validation/truth-problem-552.json  \n",
            "  inflating: dataset3/validation/truth-problem-553.json  \n",
            "  inflating: dataset3/validation/truth-problem-554.json  \n",
            "  inflating: dataset3/validation/truth-problem-555.json  \n",
            "  inflating: dataset3/validation/truth-problem-556.json  \n",
            "  inflating: dataset3/validation/truth-problem-557.json  \n",
            "  inflating: dataset3/validation/truth-problem-558.json  \n",
            "  inflating: dataset3/validation/truth-problem-559.json  \n",
            "  inflating: dataset3/validation/truth-problem-56.json  \n",
            "  inflating: dataset3/validation/truth-problem-560.json  \n",
            "  inflating: dataset3/validation/truth-problem-561.json  \n",
            "  inflating: dataset3/validation/truth-problem-562.json  \n",
            "  inflating: dataset3/validation/truth-problem-563.json  \n",
            "  inflating: dataset3/validation/truth-problem-564.json  \n",
            "  inflating: dataset3/validation/truth-problem-565.json  \n",
            "  inflating: dataset3/validation/truth-problem-566.json  \n",
            "  inflating: dataset3/validation/truth-problem-567.json  \n",
            "  inflating: dataset3/validation/truth-problem-568.json  \n",
            "  inflating: dataset3/validation/truth-problem-569.json  \n",
            "  inflating: dataset3/validation/truth-problem-57.json  \n",
            "  inflating: dataset3/validation/truth-problem-570.json  \n",
            "  inflating: dataset3/validation/truth-problem-571.json  \n",
            "  inflating: dataset3/validation/truth-problem-572.json  \n",
            "  inflating: dataset3/validation/truth-problem-573.json  \n",
            "  inflating: dataset3/validation/truth-problem-574.json  \n",
            "  inflating: dataset3/validation/truth-problem-575.json  \n",
            "  inflating: dataset3/validation/truth-problem-576.json  \n",
            "  inflating: dataset3/validation/truth-problem-577.json  \n",
            "  inflating: dataset3/validation/truth-problem-578.json  \n",
            "  inflating: dataset3/validation/truth-problem-579.json  \n",
            "  inflating: dataset3/validation/truth-problem-58.json  \n",
            "  inflating: dataset3/validation/truth-problem-580.json  \n",
            "  inflating: dataset3/validation/truth-problem-581.json  \n",
            "  inflating: dataset3/validation/truth-problem-582.json  \n",
            "  inflating: dataset3/validation/truth-problem-583.json  \n",
            "  inflating: dataset3/validation/truth-problem-584.json  \n",
            "  inflating: dataset3/validation/truth-problem-585.json  \n",
            "  inflating: dataset3/validation/truth-problem-586.json  \n",
            "  inflating: dataset3/validation/truth-problem-587.json  \n",
            "  inflating: dataset3/validation/truth-problem-588.json  \n",
            "  inflating: dataset3/validation/truth-problem-589.json  \n",
            "  inflating: dataset3/validation/truth-problem-59.json  \n",
            "  inflating: dataset3/validation/truth-problem-590.json  \n",
            "  inflating: dataset3/validation/truth-problem-591.json  \n",
            "  inflating: dataset3/validation/truth-problem-592.json  \n",
            "  inflating: dataset3/validation/truth-problem-593.json  \n",
            "  inflating: dataset3/validation/truth-problem-594.json  \n",
            "  inflating: dataset3/validation/truth-problem-595.json  \n",
            "  inflating: dataset3/validation/truth-problem-596.json  \n",
            "  inflating: dataset3/validation/truth-problem-597.json  \n",
            "  inflating: dataset3/validation/truth-problem-598.json  \n",
            "  inflating: dataset3/validation/truth-problem-599.json  \n",
            "  inflating: dataset3/validation/truth-problem-6.json  \n",
            "  inflating: dataset3/validation/truth-problem-60.json  \n",
            "  inflating: dataset3/validation/truth-problem-600.json  \n",
            "  inflating: dataset3/validation/truth-problem-601.json  \n",
            "  inflating: dataset3/validation/truth-problem-602.json  \n",
            "  inflating: dataset3/validation/truth-problem-603.json  \n",
            "  inflating: dataset3/validation/truth-problem-604.json  \n",
            "  inflating: dataset3/validation/truth-problem-605.json  \n",
            "  inflating: dataset3/validation/truth-problem-606.json  \n",
            "  inflating: dataset3/validation/truth-problem-607.json  \n",
            "  inflating: dataset3/validation/truth-problem-608.json  \n",
            "  inflating: dataset3/validation/truth-problem-609.json  \n",
            "  inflating: dataset3/validation/truth-problem-61.json  \n",
            "  inflating: dataset3/validation/truth-problem-610.json  \n",
            "  inflating: dataset3/validation/truth-problem-611.json  \n",
            "  inflating: dataset3/validation/truth-problem-612.json  \n",
            "  inflating: dataset3/validation/truth-problem-613.json  \n",
            "  inflating: dataset3/validation/truth-problem-614.json  \n",
            "  inflating: dataset3/validation/truth-problem-615.json  \n",
            "  inflating: dataset3/validation/truth-problem-616.json  \n",
            "  inflating: dataset3/validation/truth-problem-617.json  \n",
            "  inflating: dataset3/validation/truth-problem-618.json  \n",
            "  inflating: dataset3/validation/truth-problem-619.json  \n",
            "  inflating: dataset3/validation/truth-problem-62.json  \n",
            "  inflating: dataset3/validation/truth-problem-620.json  \n",
            "  inflating: dataset3/validation/truth-problem-621.json  \n",
            "  inflating: dataset3/validation/truth-problem-622.json  \n",
            "  inflating: dataset3/validation/truth-problem-623.json  \n",
            "  inflating: dataset3/validation/truth-problem-624.json  \n",
            "  inflating: dataset3/validation/truth-problem-625.json  \n",
            "  inflating: dataset3/validation/truth-problem-626.json  \n",
            "  inflating: dataset3/validation/truth-problem-627.json  \n",
            "  inflating: dataset3/validation/truth-problem-628.json  \n",
            "  inflating: dataset3/validation/truth-problem-629.json  \n",
            "  inflating: dataset3/validation/truth-problem-63.json  \n",
            "  inflating: dataset3/validation/truth-problem-630.json  \n",
            "  inflating: dataset3/validation/truth-problem-631.json  \n",
            "  inflating: dataset3/validation/truth-problem-632.json  \n",
            "  inflating: dataset3/validation/truth-problem-633.json  \n",
            "  inflating: dataset3/validation/truth-problem-634.json  \n",
            "  inflating: dataset3/validation/truth-problem-635.json  \n",
            "  inflating: dataset3/validation/truth-problem-636.json  \n",
            "  inflating: dataset3/validation/truth-problem-637.json  \n",
            "  inflating: dataset3/validation/truth-problem-638.json  \n",
            "  inflating: dataset3/validation/truth-problem-639.json  \n",
            "  inflating: dataset3/validation/truth-problem-64.json  \n",
            "  inflating: dataset3/validation/truth-problem-640.json  \n",
            "  inflating: dataset3/validation/truth-problem-641.json  \n",
            "  inflating: dataset3/validation/truth-problem-642.json  \n",
            "  inflating: dataset3/validation/truth-problem-643.json  \n",
            "  inflating: dataset3/validation/truth-problem-644.json  \n",
            "  inflating: dataset3/validation/truth-problem-645.json  \n",
            "  inflating: dataset3/validation/truth-problem-646.json  \n",
            "  inflating: dataset3/validation/truth-problem-647.json  \n",
            "  inflating: dataset3/validation/truth-problem-648.json  \n",
            "  inflating: dataset3/validation/truth-problem-649.json  \n",
            "  inflating: dataset3/validation/truth-problem-65.json  \n",
            "  inflating: dataset3/validation/truth-problem-650.json  \n",
            "  inflating: dataset3/validation/truth-problem-651.json  \n",
            "  inflating: dataset3/validation/truth-problem-652.json  \n",
            "  inflating: dataset3/validation/truth-problem-653.json  \n",
            "  inflating: dataset3/validation/truth-problem-654.json  \n",
            "  inflating: dataset3/validation/truth-problem-655.json  \n",
            "  inflating: dataset3/validation/truth-problem-656.json  \n",
            "  inflating: dataset3/validation/truth-problem-657.json  \n",
            "  inflating: dataset3/validation/truth-problem-658.json  \n",
            "  inflating: dataset3/validation/truth-problem-659.json  \n",
            "  inflating: dataset3/validation/truth-problem-66.json  \n",
            "  inflating: dataset3/validation/truth-problem-660.json  \n",
            "  inflating: dataset3/validation/truth-problem-661.json  \n",
            "  inflating: dataset3/validation/truth-problem-662.json  \n",
            "  inflating: dataset3/validation/truth-problem-663.json  \n",
            "  inflating: dataset3/validation/truth-problem-664.json  \n",
            "  inflating: dataset3/validation/truth-problem-665.json  \n",
            "  inflating: dataset3/validation/truth-problem-666.json  \n",
            "  inflating: dataset3/validation/truth-problem-667.json  \n",
            "  inflating: dataset3/validation/truth-problem-668.json  \n",
            "  inflating: dataset3/validation/truth-problem-669.json  \n",
            "  inflating: dataset3/validation/truth-problem-67.json  \n",
            "  inflating: dataset3/validation/truth-problem-670.json  \n",
            "  inflating: dataset3/validation/truth-problem-671.json  \n",
            "  inflating: dataset3/validation/truth-problem-672.json  \n",
            "  inflating: dataset3/validation/truth-problem-673.json  \n",
            "  inflating: dataset3/validation/truth-problem-674.json  \n",
            "  inflating: dataset3/validation/truth-problem-675.json  \n",
            "  inflating: dataset3/validation/truth-problem-676.json  \n",
            "  inflating: dataset3/validation/truth-problem-677.json  \n",
            "  inflating: dataset3/validation/truth-problem-678.json  \n",
            "  inflating: dataset3/validation/truth-problem-679.json  \n",
            "  inflating: dataset3/validation/truth-problem-68.json  \n",
            "  inflating: dataset3/validation/truth-problem-680.json  \n",
            "  inflating: dataset3/validation/truth-problem-681.json  \n",
            "  inflating: dataset3/validation/truth-problem-682.json  \n",
            "  inflating: dataset3/validation/truth-problem-683.json  \n",
            "  inflating: dataset3/validation/truth-problem-684.json  \n",
            "  inflating: dataset3/validation/truth-problem-685.json  \n",
            "  inflating: dataset3/validation/truth-problem-686.json  \n",
            "  inflating: dataset3/validation/truth-problem-687.json  \n",
            "  inflating: dataset3/validation/truth-problem-688.json  \n",
            "  inflating: dataset3/validation/truth-problem-689.json  \n",
            "  inflating: dataset3/validation/truth-problem-69.json  \n",
            "  inflating: dataset3/validation/truth-problem-690.json  \n",
            "  inflating: dataset3/validation/truth-problem-691.json  \n",
            "  inflating: dataset3/validation/truth-problem-692.json  \n",
            "  inflating: dataset3/validation/truth-problem-693.json  \n",
            "  inflating: dataset3/validation/truth-problem-694.json  \n",
            "  inflating: dataset3/validation/truth-problem-695.json  \n",
            "  inflating: dataset3/validation/truth-problem-696.json  \n",
            "  inflating: dataset3/validation/truth-problem-697.json  \n",
            "  inflating: dataset3/validation/truth-problem-698.json  \n",
            "  inflating: dataset3/validation/truth-problem-699.json  \n",
            "  inflating: dataset3/validation/truth-problem-7.json  \n",
            "  inflating: dataset3/validation/truth-problem-70.json  \n",
            "  inflating: dataset3/validation/truth-problem-700.json  \n",
            "  inflating: dataset3/validation/truth-problem-701.json  \n",
            "  inflating: dataset3/validation/truth-problem-702.json  \n",
            "  inflating: dataset3/validation/truth-problem-703.json  \n",
            "  inflating: dataset3/validation/truth-problem-704.json  \n",
            "  inflating: dataset3/validation/truth-problem-705.json  \n",
            "  inflating: dataset3/validation/truth-problem-706.json  \n",
            "  inflating: dataset3/validation/truth-problem-707.json  \n",
            "  inflating: dataset3/validation/truth-problem-708.json  \n",
            "  inflating: dataset3/validation/truth-problem-709.json  \n",
            "  inflating: dataset3/validation/truth-problem-71.json  \n",
            "  inflating: dataset3/validation/truth-problem-710.json  \n",
            "  inflating: dataset3/validation/truth-problem-711.json  \n",
            "  inflating: dataset3/validation/truth-problem-712.json  \n",
            "  inflating: dataset3/validation/truth-problem-713.json  \n",
            "  inflating: dataset3/validation/truth-problem-714.json  \n",
            "  inflating: dataset3/validation/truth-problem-715.json  \n",
            "  inflating: dataset3/validation/truth-problem-716.json  \n",
            "  inflating: dataset3/validation/truth-problem-717.json  \n",
            "  inflating: dataset3/validation/truth-problem-718.json  \n",
            "  inflating: dataset3/validation/truth-problem-719.json  \n",
            "  inflating: dataset3/validation/truth-problem-72.json  \n",
            "  inflating: dataset3/validation/truth-problem-720.json  \n",
            "  inflating: dataset3/validation/truth-problem-721.json  \n",
            "  inflating: dataset3/validation/truth-problem-722.json  \n",
            "  inflating: dataset3/validation/truth-problem-723.json  \n",
            "  inflating: dataset3/validation/truth-problem-724.json  \n",
            "  inflating: dataset3/validation/truth-problem-725.json  \n",
            "  inflating: dataset3/validation/truth-problem-726.json  \n",
            "  inflating: dataset3/validation/truth-problem-727.json  \n",
            "  inflating: dataset3/validation/truth-problem-728.json  \n",
            "  inflating: dataset3/validation/truth-problem-729.json  \n",
            "  inflating: dataset3/validation/truth-problem-73.json  \n",
            "  inflating: dataset3/validation/truth-problem-730.json  \n",
            "  inflating: dataset3/validation/truth-problem-731.json  \n",
            "  inflating: dataset3/validation/truth-problem-732.json  \n",
            "  inflating: dataset3/validation/truth-problem-733.json  \n",
            "  inflating: dataset3/validation/truth-problem-734.json  \n",
            "  inflating: dataset3/validation/truth-problem-735.json  \n",
            "  inflating: dataset3/validation/truth-problem-736.json  \n",
            "  inflating: dataset3/validation/truth-problem-737.json  \n",
            "  inflating: dataset3/validation/truth-problem-738.json  \n",
            "  inflating: dataset3/validation/truth-problem-739.json  \n",
            "  inflating: dataset3/validation/truth-problem-74.json  \n",
            "  inflating: dataset3/validation/truth-problem-740.json  \n",
            "  inflating: dataset3/validation/truth-problem-741.json  \n",
            "  inflating: dataset3/validation/truth-problem-742.json  \n",
            "  inflating: dataset3/validation/truth-problem-743.json  \n",
            "  inflating: dataset3/validation/truth-problem-744.json  \n",
            "  inflating: dataset3/validation/truth-problem-745.json  \n",
            "  inflating: dataset3/validation/truth-problem-746.json  \n",
            "  inflating: dataset3/validation/truth-problem-747.json  \n",
            "  inflating: dataset3/validation/truth-problem-748.json  \n",
            "  inflating: dataset3/validation/truth-problem-749.json  \n",
            "  inflating: dataset3/validation/truth-problem-75.json  \n",
            "  inflating: dataset3/validation/truth-problem-750.json  \n",
            "  inflating: dataset3/validation/truth-problem-751.json  \n",
            "  inflating: dataset3/validation/truth-problem-752.json  \n",
            "  inflating: dataset3/validation/truth-problem-753.json  \n",
            "  inflating: dataset3/validation/truth-problem-754.json  \n",
            "  inflating: dataset3/validation/truth-problem-755.json  \n",
            "  inflating: dataset3/validation/truth-problem-756.json  \n",
            "  inflating: dataset3/validation/truth-problem-757.json  \n",
            "  inflating: dataset3/validation/truth-problem-758.json  \n",
            "  inflating: dataset3/validation/truth-problem-759.json  \n",
            "  inflating: dataset3/validation/truth-problem-76.json  \n",
            "  inflating: dataset3/validation/truth-problem-760.json  \n",
            "  inflating: dataset3/validation/truth-problem-761.json  \n",
            "  inflating: dataset3/validation/truth-problem-762.json  \n",
            "  inflating: dataset3/validation/truth-problem-763.json  \n",
            "  inflating: dataset3/validation/truth-problem-764.json  \n",
            "  inflating: dataset3/validation/truth-problem-765.json  \n",
            "  inflating: dataset3/validation/truth-problem-766.json  \n",
            "  inflating: dataset3/validation/truth-problem-767.json  \n",
            "  inflating: dataset3/validation/truth-problem-768.json  \n",
            "  inflating: dataset3/validation/truth-problem-769.json  \n",
            "  inflating: dataset3/validation/truth-problem-77.json  \n",
            "  inflating: dataset3/validation/truth-problem-770.json  \n",
            "  inflating: dataset3/validation/truth-problem-771.json  \n",
            "  inflating: dataset3/validation/truth-problem-772.json  \n",
            "  inflating: dataset3/validation/truth-problem-773.json  \n",
            "  inflating: dataset3/validation/truth-problem-774.json  \n",
            "  inflating: dataset3/validation/truth-problem-775.json  \n",
            "  inflating: dataset3/validation/truth-problem-776.json  \n",
            "  inflating: dataset3/validation/truth-problem-777.json  \n",
            "  inflating: dataset3/validation/truth-problem-778.json  \n",
            "  inflating: dataset3/validation/truth-problem-779.json  \n",
            "  inflating: dataset3/validation/truth-problem-78.json  \n",
            "  inflating: dataset3/validation/truth-problem-780.json  \n",
            "  inflating: dataset3/validation/truth-problem-781.json  \n",
            "  inflating: dataset3/validation/truth-problem-782.json  \n",
            "  inflating: dataset3/validation/truth-problem-783.json  \n",
            "  inflating: dataset3/validation/truth-problem-784.json  \n",
            "  inflating: dataset3/validation/truth-problem-785.json  \n",
            "  inflating: dataset3/validation/truth-problem-786.json  \n",
            "  inflating: dataset3/validation/truth-problem-787.json  \n",
            "  inflating: dataset3/validation/truth-problem-788.json  \n",
            "  inflating: dataset3/validation/truth-problem-789.json  \n",
            "  inflating: dataset3/validation/truth-problem-79.json  \n",
            "  inflating: dataset3/validation/truth-problem-790.json  \n",
            "  inflating: dataset3/validation/truth-problem-791.json  \n",
            "  inflating: dataset3/validation/truth-problem-792.json  \n",
            "  inflating: dataset3/validation/truth-problem-793.json  \n",
            "  inflating: dataset3/validation/truth-problem-794.json  \n",
            "  inflating: dataset3/validation/truth-problem-795.json  \n",
            "  inflating: dataset3/validation/truth-problem-796.json  \n",
            "  inflating: dataset3/validation/truth-problem-797.json  \n",
            "  inflating: dataset3/validation/truth-problem-798.json  \n",
            "  inflating: dataset3/validation/truth-problem-799.json  \n",
            "  inflating: dataset3/validation/truth-problem-8.json  \n",
            "  inflating: dataset3/validation/truth-problem-80.json  \n",
            "  inflating: dataset3/validation/truth-problem-800.json  \n",
            "  inflating: dataset3/validation/truth-problem-801.json  \n",
            "  inflating: dataset3/validation/truth-problem-802.json  \n",
            "  inflating: dataset3/validation/truth-problem-803.json  \n",
            "  inflating: dataset3/validation/truth-problem-804.json  \n",
            "  inflating: dataset3/validation/truth-problem-805.json  \n",
            "  inflating: dataset3/validation/truth-problem-806.json  \n",
            "  inflating: dataset3/validation/truth-problem-807.json  \n",
            "  inflating: dataset3/validation/truth-problem-808.json  \n",
            "  inflating: dataset3/validation/truth-problem-809.json  \n",
            "  inflating: dataset3/validation/truth-problem-81.json  \n",
            "  inflating: dataset3/validation/truth-problem-810.json  \n",
            "  inflating: dataset3/validation/truth-problem-811.json  \n",
            "  inflating: dataset3/validation/truth-problem-812.json  \n",
            "  inflating: dataset3/validation/truth-problem-813.json  \n",
            "  inflating: dataset3/validation/truth-problem-814.json  \n",
            "  inflating: dataset3/validation/truth-problem-815.json  \n",
            "  inflating: dataset3/validation/truth-problem-816.json  \n",
            "  inflating: dataset3/validation/truth-problem-817.json  \n",
            "  inflating: dataset3/validation/truth-problem-818.json  \n",
            "  inflating: dataset3/validation/truth-problem-819.json  \n",
            "  inflating: dataset3/validation/truth-problem-82.json  \n",
            "  inflating: dataset3/validation/truth-problem-820.json  \n",
            "  inflating: dataset3/validation/truth-problem-821.json  \n",
            "  inflating: dataset3/validation/truth-problem-822.json  \n",
            "  inflating: dataset3/validation/truth-problem-823.json  \n",
            "  inflating: dataset3/validation/truth-problem-824.json  \n",
            "  inflating: dataset3/validation/truth-problem-825.json  \n",
            "  inflating: dataset3/validation/truth-problem-826.json  \n",
            "  inflating: dataset3/validation/truth-problem-827.json  \n",
            "  inflating: dataset3/validation/truth-problem-828.json  \n",
            "  inflating: dataset3/validation/truth-problem-829.json  \n",
            "  inflating: dataset3/validation/truth-problem-83.json  \n",
            "  inflating: dataset3/validation/truth-problem-830.json  \n",
            "  inflating: dataset3/validation/truth-problem-831.json  \n",
            "  inflating: dataset3/validation/truth-problem-832.json  \n",
            "  inflating: dataset3/validation/truth-problem-833.json  \n",
            "  inflating: dataset3/validation/truth-problem-834.json  \n",
            "  inflating: dataset3/validation/truth-problem-835.json  \n",
            "  inflating: dataset3/validation/truth-problem-836.json  \n",
            "  inflating: dataset3/validation/truth-problem-837.json  \n",
            "  inflating: dataset3/validation/truth-problem-838.json  \n",
            "  inflating: dataset3/validation/truth-problem-839.json  \n",
            "  inflating: dataset3/validation/truth-problem-84.json  \n",
            "  inflating: dataset3/validation/truth-problem-840.json  \n",
            "  inflating: dataset3/validation/truth-problem-841.json  \n",
            "  inflating: dataset3/validation/truth-problem-842.json  \n",
            "  inflating: dataset3/validation/truth-problem-843.json  \n",
            "  inflating: dataset3/validation/truth-problem-844.json  \n",
            "  inflating: dataset3/validation/truth-problem-845.json  \n",
            "  inflating: dataset3/validation/truth-problem-846.json  \n",
            "  inflating: dataset3/validation/truth-problem-847.json  \n",
            "  inflating: dataset3/validation/truth-problem-848.json  \n",
            "  inflating: dataset3/validation/truth-problem-849.json  \n",
            "  inflating: dataset3/validation/truth-problem-85.json  \n",
            "  inflating: dataset3/validation/truth-problem-850.json  \n",
            "  inflating: dataset3/validation/truth-problem-851.json  \n",
            "  inflating: dataset3/validation/truth-problem-852.json  \n",
            "  inflating: dataset3/validation/truth-problem-853.json  \n",
            "  inflating: dataset3/validation/truth-problem-854.json  \n",
            "  inflating: dataset3/validation/truth-problem-855.json  \n",
            "  inflating: dataset3/validation/truth-problem-856.json  \n",
            "  inflating: dataset3/validation/truth-problem-857.json  \n",
            "  inflating: dataset3/validation/truth-problem-858.json  \n",
            "  inflating: dataset3/validation/truth-problem-859.json  \n",
            "  inflating: dataset3/validation/truth-problem-86.json  \n",
            "  inflating: dataset3/validation/truth-problem-860.json  \n",
            "  inflating: dataset3/validation/truth-problem-861.json  \n",
            "  inflating: dataset3/validation/truth-problem-862.json  \n",
            "  inflating: dataset3/validation/truth-problem-863.json  \n",
            "  inflating: dataset3/validation/truth-problem-864.json  \n",
            "  inflating: dataset3/validation/truth-problem-865.json  \n",
            "  inflating: dataset3/validation/truth-problem-866.json  \n",
            "  inflating: dataset3/validation/truth-problem-867.json  \n",
            "  inflating: dataset3/validation/truth-problem-868.json  \n",
            "  inflating: dataset3/validation/truth-problem-869.json  \n",
            "  inflating: dataset3/validation/truth-problem-87.json  \n",
            "  inflating: dataset3/validation/truth-problem-870.json  \n",
            "  inflating: dataset3/validation/truth-problem-871.json  \n",
            "  inflating: dataset3/validation/truth-problem-872.json  \n",
            "  inflating: dataset3/validation/truth-problem-873.json  \n",
            "  inflating: dataset3/validation/truth-problem-874.json  \n",
            "  inflating: dataset3/validation/truth-problem-875.json  \n",
            "  inflating: dataset3/validation/truth-problem-876.json  \n",
            "  inflating: dataset3/validation/truth-problem-877.json  \n",
            "  inflating: dataset3/validation/truth-problem-878.json  \n",
            "  inflating: dataset3/validation/truth-problem-879.json  \n",
            "  inflating: dataset3/validation/truth-problem-88.json  \n",
            "  inflating: dataset3/validation/truth-problem-880.json  \n",
            "  inflating: dataset3/validation/truth-problem-881.json  \n",
            "  inflating: dataset3/validation/truth-problem-882.json  \n",
            "  inflating: dataset3/validation/truth-problem-883.json  \n",
            "  inflating: dataset3/validation/truth-problem-884.json  \n",
            "  inflating: dataset3/validation/truth-problem-885.json  \n",
            "  inflating: dataset3/validation/truth-problem-886.json  \n",
            "  inflating: dataset3/validation/truth-problem-887.json  \n",
            "  inflating: dataset3/validation/truth-problem-888.json  \n",
            "  inflating: dataset3/validation/truth-problem-889.json  \n",
            "  inflating: dataset3/validation/truth-problem-89.json  \n",
            "  inflating: dataset3/validation/truth-problem-890.json  \n",
            "  inflating: dataset3/validation/truth-problem-891.json  \n",
            "  inflating: dataset3/validation/truth-problem-892.json  \n",
            "  inflating: dataset3/validation/truth-problem-893.json  \n",
            "  inflating: dataset3/validation/truth-problem-894.json  \n",
            "  inflating: dataset3/validation/truth-problem-895.json  \n",
            "  inflating: dataset3/validation/truth-problem-896.json  \n",
            "  inflating: dataset3/validation/truth-problem-897.json  \n",
            "  inflating: dataset3/validation/truth-problem-898.json  \n",
            "  inflating: dataset3/validation/truth-problem-899.json  \n",
            "  inflating: dataset3/validation/truth-problem-9.json  \n",
            "  inflating: dataset3/validation/truth-problem-90.json  \n",
            "  inflating: dataset3/validation/truth-problem-900.json  \n",
            "  inflating: dataset3/validation/truth-problem-901.json  \n",
            "  inflating: dataset3/validation/truth-problem-902.json  \n",
            "  inflating: dataset3/validation/truth-problem-903.json  \n",
            "  inflating: dataset3/validation/truth-problem-904.json  \n",
            "  inflating: dataset3/validation/truth-problem-905.json  \n",
            "  inflating: dataset3/validation/truth-problem-906.json  \n",
            "  inflating: dataset3/validation/truth-problem-907.json  \n",
            "  inflating: dataset3/validation/truth-problem-908.json  \n",
            "  inflating: dataset3/validation/truth-problem-909.json  \n",
            "  inflating: dataset3/validation/truth-problem-91.json  \n",
            "  inflating: dataset3/validation/truth-problem-910.json  \n",
            "  inflating: dataset3/validation/truth-problem-911.json  \n",
            "  inflating: dataset3/validation/truth-problem-912.json  \n",
            "  inflating: dataset3/validation/truth-problem-913.json  \n",
            "  inflating: dataset3/validation/truth-problem-914.json  \n",
            "  inflating: dataset3/validation/truth-problem-915.json  \n",
            "  inflating: dataset3/validation/truth-problem-916.json  \n",
            "  inflating: dataset3/validation/truth-problem-917.json  \n",
            "  inflating: dataset3/validation/truth-problem-918.json  \n",
            "  inflating: dataset3/validation/truth-problem-919.json  \n",
            "  inflating: dataset3/validation/truth-problem-92.json  \n",
            "  inflating: dataset3/validation/truth-problem-920.json  \n",
            "  inflating: dataset3/validation/truth-problem-921.json  \n",
            "  inflating: dataset3/validation/truth-problem-922.json  \n",
            "  inflating: dataset3/validation/truth-problem-923.json  \n",
            "  inflating: dataset3/validation/truth-problem-924.json  \n",
            "  inflating: dataset3/validation/truth-problem-925.json  \n",
            "  inflating: dataset3/validation/truth-problem-926.json  \n",
            "  inflating: dataset3/validation/truth-problem-927.json  \n",
            "  inflating: dataset3/validation/truth-problem-928.json  \n",
            "  inflating: dataset3/validation/truth-problem-929.json  \n",
            "  inflating: dataset3/validation/truth-problem-93.json  \n",
            "  inflating: dataset3/validation/truth-problem-930.json  \n",
            "  inflating: dataset3/validation/truth-problem-931.json  \n",
            "  inflating: dataset3/validation/truth-problem-932.json  \n",
            "  inflating: dataset3/validation/truth-problem-933.json  \n",
            "  inflating: dataset3/validation/truth-problem-934.json  \n",
            "  inflating: dataset3/validation/truth-problem-935.json  \n",
            "  inflating: dataset3/validation/truth-problem-936.json  \n",
            "  inflating: dataset3/validation/truth-problem-937.json  \n",
            "  inflating: dataset3/validation/truth-problem-938.json  \n",
            "  inflating: dataset3/validation/truth-problem-939.json  \n",
            "  inflating: dataset3/validation/truth-problem-94.json  \n",
            "  inflating: dataset3/validation/truth-problem-940.json  \n",
            "  inflating: dataset3/validation/truth-problem-941.json  \n",
            "  inflating: dataset3/validation/truth-problem-942.json  \n",
            "  inflating: dataset3/validation/truth-problem-943.json  \n",
            "  inflating: dataset3/validation/truth-problem-944.json  \n",
            "  inflating: dataset3/validation/truth-problem-945.json  \n",
            "  inflating: dataset3/validation/truth-problem-946.json  \n",
            "  inflating: dataset3/validation/truth-problem-947.json  \n",
            "  inflating: dataset3/validation/truth-problem-948.json  \n",
            "  inflating: dataset3/validation/truth-problem-949.json  \n",
            "  inflating: dataset3/validation/truth-problem-95.json  \n",
            "  inflating: dataset3/validation/truth-problem-950.json  \n",
            "  inflating: dataset3/validation/truth-problem-951.json  \n",
            "  inflating: dataset3/validation/truth-problem-952.json  \n",
            "  inflating: dataset3/validation/truth-problem-953.json  \n",
            "  inflating: dataset3/validation/truth-problem-954.json  \n",
            "  inflating: dataset3/validation/truth-problem-955.json  \n",
            "  inflating: dataset3/validation/truth-problem-956.json  \n",
            "  inflating: dataset3/validation/truth-problem-957.json  \n",
            "  inflating: dataset3/validation/truth-problem-958.json  \n",
            "  inflating: dataset3/validation/truth-problem-959.json  \n",
            "  inflating: dataset3/validation/truth-problem-96.json  \n",
            "  inflating: dataset3/validation/truth-problem-960.json  \n",
            "  inflating: dataset3/validation/truth-problem-961.json  \n",
            "  inflating: dataset3/validation/truth-problem-962.json  \n",
            "  inflating: dataset3/validation/truth-problem-963.json  \n",
            "  inflating: dataset3/validation/truth-problem-964.json  \n",
            "  inflating: dataset3/validation/truth-problem-965.json  \n",
            "  inflating: dataset3/validation/truth-problem-966.json  \n",
            "  inflating: dataset3/validation/truth-problem-967.json  \n",
            "  inflating: dataset3/validation/truth-problem-968.json  \n",
            "  inflating: dataset3/validation/truth-problem-969.json  \n",
            "  inflating: dataset3/validation/truth-problem-97.json  \n",
            "  inflating: dataset3/validation/truth-problem-970.json  \n",
            "  inflating: dataset3/validation/truth-problem-971.json  \n",
            "  inflating: dataset3/validation/truth-problem-972.json  \n",
            "  inflating: dataset3/validation/truth-problem-973.json  \n",
            "  inflating: dataset3/validation/truth-problem-974.json  \n",
            "  inflating: dataset3/validation/truth-problem-975.json  \n",
            "  inflating: dataset3/validation/truth-problem-976.json  \n",
            "  inflating: dataset3/validation/truth-problem-977.json  \n",
            "  inflating: dataset3/validation/truth-problem-978.json  \n",
            "  inflating: dataset3/validation/truth-problem-979.json  \n",
            "  inflating: dataset3/validation/truth-problem-98.json  \n",
            "  inflating: dataset3/validation/truth-problem-980.json  \n",
            "  inflating: dataset3/validation/truth-problem-981.json  \n",
            "  inflating: dataset3/validation/truth-problem-982.json  \n",
            "  inflating: dataset3/validation/truth-problem-983.json  \n",
            "  inflating: dataset3/validation/truth-problem-984.json  \n",
            "  inflating: dataset3/validation/truth-problem-985.json  \n",
            "  inflating: dataset3/validation/truth-problem-986.json  \n",
            "  inflating: dataset3/validation/truth-problem-987.json  \n",
            "  inflating: dataset3/validation/truth-problem-988.json  \n",
            "  inflating: dataset3/validation/truth-problem-989.json  \n",
            "  inflating: dataset3/validation/truth-problem-99.json  \n",
            "  inflating: dataset3/validation/truth-problem-990.json  \n",
            "  inflating: dataset3/validation/truth-problem-991.json  \n",
            "  inflating: dataset3/validation/truth-problem-992.json  \n",
            "  inflating: dataset3/validation/truth-problem-993.json  \n",
            "  inflating: dataset3/validation/truth-problem-994.json  \n",
            "  inflating: dataset3/validation/truth-problem-995.json  \n",
            "  inflating: dataset3/validation/truth-problem-996.json  \n",
            "  inflating: dataset3/validation/truth-problem-997.json  \n",
            "  inflating: dataset3/validation/truth-problem-998.json  \n",
            "  inflating: dataset3/validation/truth-problem-999.json  \n",
            "  inflating: README.md               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruNebl0F1jk1"
      },
      "source": [
        "#Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sets reproducibility.\n",
        "def set_reproducibility(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  tf.random.set_seed(seed)\n",
        "  tf.config.experimental.enable_op_determinism()\n",
        "  os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "  os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
        "  os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
        "\n",
        "# Setting seed.\n",
        "set_reproducibility(seed = 42)"
      ],
      "metadata": {
        "id": "_K2feMwpgLyH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6JMWvviDvHNe"
      },
      "outputs": [],
      "source": [
        "def create_dataframe(directory):\n",
        "\n",
        "  train_set = []\n",
        "  for filename in os.listdir(directory):\n",
        "      f = os.path.join(directory, filename)\n",
        "      if f.endswith('.json'):\n",
        "            train_set.append(f)\n",
        "\n",
        "  train_set.sort(key=lambda f: int(re.sub('\\D', '', f))) #sorting alphabetically files by name in order to have the correct order\n",
        "\n",
        "  data = []\n",
        "  for name in train_set:\n",
        "    with open(name) as json_data:\n",
        "      data_dict = json.load(json_data)\n",
        "      data.append(data_dict)\n",
        "\n",
        "  df = json_normalize(data)\n",
        "  \n",
        "  train_set_text = []\n",
        "  for filename in os.listdir(directory):\n",
        "      f = os.path.join(directory, filename)\n",
        "      if f.endswith('.txt'):\n",
        "            train_set_text.append(f)\n",
        "\n",
        "  train_set_text.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
        "\n",
        "  text_list = []\n",
        "  for file in train_set_text:\n",
        "    with open(file) as f:\n",
        "      content = f.read()\n",
        "      text_list.append(content)\n",
        "\n",
        "  df['input_text'] = text_list\n",
        "\n",
        "  splitted_text = []\n",
        "  for text in df['input_text']:\n",
        "    split = text.splitlines()\n",
        "    splitted_text.append(split)\n",
        "\n",
        "  df['splitted_text'] = pd.Series(splitted_text)\n",
        "\n",
        "  #Sanity check, checking if we have splitted correctly (according to the datset) the input text \n",
        "  for i in range(len(df.index)):\n",
        "    if len(df['splitted_text'].iloc[i]) != len(df['paragraph-authors'].iloc[i]):\n",
        "      print(\"we have a problem at row: \",i)\n",
        "    \n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Z8ZxCOVkxWhH"
      },
      "outputs": [],
      "source": [
        "def data_inspection(data, wordCloud : bool = False):  \n",
        "  print(f\"Dataset size: {data.shape}\")\n",
        "  print(f\"Dataset columns: {data.columns.values}\")\n",
        "  print(f\"Main sources: {data['site'].unique()}\")\n",
        "  print(f\"Number of questions per source:\\n {data.groupby(['site'])['site'].count()}\")\n",
        "  print(f\"Average length of the text: {data['input_text'].apply(len).mean()}\") \n",
        "  print(f\"Possible number of authors: {data['authors'].unique()}\") \n",
        "  if wordCloud:\n",
        "    wordcloud = WordCloud(width = 3000, height = 2000, collocations=False, stopwords = STOPWORDS).generate(\" \".join(data['input_text'])) \n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(wordcloud) \n",
        "    plt.axis(\"off\");\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Figures folder.\n",
        "figures_path = os.path.join(os.getcwd(), \"figures\")\n",
        "if not os.path.exists(figures_path): \n",
        "  os.makedirs(figures_path)\n",
        "\n",
        "# Plots classes distribution.\n",
        "def plot_classes_distribution(classes, counts, filename, figures_path = figures_path):\n",
        "\n",
        "  # Width of each bar.\n",
        "  bar_w = 0.45\n",
        "\n",
        "  # Plot.\n",
        "  fig, ax = plt.subplots(1, 1, figsize = (4, 4))\n",
        "  bars = ax.bar(classes[0] - bar_w / 2, counts[0], width = bar_w, label = \"Without preprocessing\")\n",
        "  bars = ax.bar(classes[1] + bar_w / 2, counts[1], width = bar_w, label = \"With preprocessing\")\n",
        "\n",
        "  # Setting plot attributes.\n",
        "  ax.set_xlabel(\"Class\")\n",
        "  ax.set_ylabel(\"Percentage (%)\")\n",
        "  ax.set_xticks(np.arange(0, len(classes[0]), 1))\n",
        "  ax.legend()\n",
        "\n",
        "  fig.savefig(f\"{figures_path}/{filename}.pdf\", bbox_inches = \"tight\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "I7vwFJhwL_pg"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "M-dmi2jz2-05"
      },
      "outputs": [],
      "source": [
        "# Splits dataset in all possible couples of paragraphs/sentences.\n",
        "def preprocess_with_data_augmentation(documents, authors, tokenizer, max_length, total_upsampling = False, max_samples = None):\n",
        "\n",
        "  # Tensors to be fed to a model.\n",
        "  token_ids = []\n",
        "  attention_masks = []\n",
        "  token_type_ids = []\n",
        "  labels = []\n",
        "\n",
        "  # Splitting data.\n",
        "  for document, author in zip(documents, authors):\n",
        "    for i in range(len(document)):\n",
        "\n",
        "      # Checking data augmentation type.\n",
        "      if total_upsampling:\n",
        "        start = 0\n",
        "      else:\n",
        "        start = i + 1\n",
        "\n",
        "      for j in range(start, len(document)):\n",
        "        if i != j:\n",
        "          encoding_dict = tokenizer.encode_plus(document[i], \n",
        "                                                document[j], \n",
        "                                                add_special_tokens = True, \n",
        "                                                truncation = True, \n",
        "                                                padding = \"max_length\", \n",
        "                                                max_length = max_length, \n",
        "                                                return_attention_mask = True,\n",
        "                                                return_token_type_ids = True,\n",
        "                                                return_tensors = \"tf\")\n",
        "          \n",
        "          token_ids.append(encoding_dict[\"input_ids\"]) \n",
        "          attention_masks.append(encoding_dict[\"attention_mask\"])\n",
        "          token_type_ids.append(encoding_dict[\"token_type_ids\"])\n",
        "\n",
        "          if author[i] != author[j]:\n",
        "            labels.append(1)\n",
        "          else:\n",
        "            labels.append(0)\n",
        "\n",
        "  # Creating TensorFlow tensors.\n",
        "  token_ids = tf.concat(token_ids, axis = 0)\n",
        "  attention_masks = tf.concat(attention_masks, axis = 0)\n",
        "  token_type_ids = tf.concat(token_type_ids, axis = 0)\n",
        "  labels = tf.concat(labels, axis = 0)\n",
        "\n",
        "  # Sampling from tensors to select max_samples samples.\n",
        "  if max_samples != None:\n",
        "    idx = []\n",
        "    idx.extend(list(np.random.choice(np.where(labels == 0)[0], max_samples, replace = False)))\n",
        "    idx.extend(list(np.random.choice(np.where(labels == 1)[0], max_samples, replace = False)))\n",
        "    token_ids = token_ids.numpy()[idx]\n",
        "    attention_masks = attention_masks.numpy()[idx]\n",
        "    token_type_ids = token_type_ids.numpy()[idx]\n",
        "    labels = labels.numpy()[idx]\n",
        "\n",
        "  # Returning tensors.\n",
        "  return token_ids, labels, attention_masks, token_type_ids\n",
        "\n",
        "# Splits dataset in couples of consecutive paragraphs/sentences.\n",
        "def preprocess_without_data_augmentation(splitted_text, changes, tokenizer, max_length, max_samples = None):\n",
        "\n",
        "  # Tensors to be fed to the model.\n",
        "  token_ids = []\n",
        "  attention_masks = []\n",
        "  token_type_ids = []\n",
        "  labels = tf.convert_to_tensor([item for sublist in changes for item in sublist])\n",
        "\n",
        "  # Splitting data.\n",
        "  for document in splitted_text:\n",
        "    for i in range(len(document)):\n",
        "      if i < len(document) - 1:\n",
        "        encoding_dict = tokenizer.encode_plus(document[i], \n",
        "                                              document[i + 1], \n",
        "                                              add_special_tokens = True, \n",
        "                                              truncation = True, \n",
        "                                              padding = \"max_length\", \n",
        "                                              max_length = max_length, \n",
        "                                              return_attention_mask = True, \n",
        "                                              return_token_type_ids = True,\n",
        "                                              return_tensors = \"tf\")\n",
        "        \n",
        "        token_ids.append(encoding_dict[\"input_ids\"]) \n",
        "        attention_masks.append(encoding_dict[\"attention_mask\"])\n",
        "        token_type_ids.append(encoding_dict[\"token_type_ids\"])\n",
        "\n",
        "  # Creating TensorFlow tensors.\n",
        "  token_ids = tf.concat(token_ids, axis = 0)\n",
        "  attention_masks = tf.concat(attention_masks, axis = 0)\n",
        "  token_type_ids = tf.concat(token_type_ids, axis = 0)\n",
        "\n",
        "  # Sampling from tensors to select max_samples samples.\n",
        "  if max_samples != None:\n",
        "    idx = []\n",
        "    idx.extend(list(np.random.choice(np.where(labels == 0)[0], max_samples, replace = False)))\n",
        "    idx.extend(list(np.random.choice(np.where(labels == 1)[0], max_samples, replace = False)))\n",
        "    token_ids = token_ids.numpy()[idx]\n",
        "    attention_masks = attention_masks.numpy()[idx]\n",
        "    token_type_ids = token_type_ids.numpy()[idx]\n",
        "    labels = labels.numpy()[idx]\n",
        "\n",
        "  # Returning tensors.\n",
        "  return token_ids, labels, attention_masks, token_type_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kMWglOo93AZP"
      },
      "outputs": [],
      "source": [
        "# Creates the BERT model.\n",
        "def create_bert_model(encoder, input_shape, n_classes, layers):\n",
        "\n",
        "  # Input layers.\n",
        "  input_ids = tf.keras.layers.Input(shape = input_shape, name = \"input_ids\", dtype = \"int32\")\n",
        "  masks = tf.keras.layers.Input(shape = input_shape, name = \"attention_masks\", dtype = \"int32\")\n",
        "  token_type_ids = tf.keras.layers.Input(shape = input_shape, name = \"token_type_ids\", dtype = \"int32\")\n",
        "\n",
        "  # Tensor 0 is last_hidden_state.\n",
        "  embeddings = encoder(input_ids, attention_mask = masks, token_type_ids = token_type_ids)[0]\n",
        "\n",
        "  # Adding layers.\n",
        "  for i in range(len(layers)):\n",
        "    if i == 0:\n",
        "      X = layers[0](embeddings)\n",
        "    else:\n",
        "      X = layers[i](X)\n",
        "\n",
        "  # Classification head.\n",
        "  y = tf.keras.layers.Dense(n_classes, activation = \"softmax\", name = \"outputs\")(X)\n",
        "\n",
        "  # Model.\n",
        "  model = tf.keras.Model(inputs = [input_ids, masks, token_type_ids], outputs = y)\n",
        "\n",
        "  # Return model.\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Computes index of the most similar row.\n",
        "def get_row_with_max_similarity(matrix, curr):\n",
        "  def element_wise_similarity(row_1, row_2):\n",
        "    return np.sum(np.array(row_1) == np.array(row_2)) / len(row_1)\n",
        "  return np.argmax([element_wise_similarity(matrix[curr], matrix[i]) for i in range(len(matrix)) if i != curr])\n",
        "\n",
        "# Labeling function.\n",
        "def labeling(authors, matrix):\n",
        "\n",
        "  pred = [0] * len(authors)\n",
        "  to_discard = []\n",
        "  new_label = 1\n",
        "\n",
        "  # Labeling.\n",
        "  for i in range(len(authors)):\n",
        "    if i not in to_discard:\n",
        "      for j in range(len(authors)):\n",
        "        if j not in to_discard:\n",
        "          if matrix[i][j] == 0:\n",
        "            if new_label > 5:\n",
        "              pred[i] = pred[get_row_with_max_similarity(matrix, i)]\n",
        "              pred[j] = pred[get_row_with_max_similarity(matrix, j)]\n",
        "            else:\n",
        "              pred[i] = new_label\n",
        "              pred[j] = new_label\n",
        "            to_discard.append(i)\n",
        "            to_discard.append(j)\n",
        "      if new_label < 5:\n",
        "        new_label = new_label + 1\n",
        "  \n",
        "  # Returning pred.\n",
        "  return pred\n",
        "\n",
        "\n",
        "# Computes \"paragraph-authors\" list from model's output.\n",
        "def compute_authors_pred_list(data, predictions):\n",
        "\n",
        "  y_pred = []\n",
        "\n",
        "  # Labeling.\n",
        "  for authors in data:\n",
        "    \n",
        "    # Extracting changes for current authors list.\n",
        "    solution = predictions[:len(authors) * (len(authors) - 1)]\n",
        "    predictions = predictions[len(authors) * (len(authors) - 1):]\n",
        "\n",
        "    # Adding label 0 to each (paragraph-x, paragraph-x) pair.\n",
        "    for i in range(len(authors)): \n",
        "      solution = np.insert(solution, obj = i + (i * len(authors)), values = 0)\n",
        "\n",
        "    # Reshaping output to be a matrix.\n",
        "    solution = np.reshape(solution, (-1, len(authors)))\n",
        "\n",
        "    # Labeling.\n",
        "    y_pred.extend(labeling(authors, solution))\n",
        "\n",
        "  # Returning y_pred.\n",
        "  return y_pred"
      ],
      "metadata": {
        "id": "CNKqUHcyqGSp"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "i1lHiPZJ3CJI"
      },
      "outputs": [],
      "source": [
        "# Saves solutions.\n",
        "def save_solution_files(task, solution_folder, df, predictions):\n",
        "\n",
        "  # Tasks 1 and 3.\n",
        "  if task == 1 or task == 3:\n",
        "\n",
        "    # Creating lists of solutions.\n",
        "    for id_problem, changes in enumerate(df[\"changes\"].values):\n",
        "      \n",
        "      # Solution.\n",
        "      solution = predictions[:len(changes)]\n",
        "      predictions = predictions[len(changes):]\n",
        "\n",
        "      # Saving solution.\n",
        "      with open(f\"{solution_folder}/solution-problem-{id_problem + 1}.json\", \"w\") as file:\n",
        "        file.write(\"{\" + \"\\n\" + '\\\"changes\\\": {}'.format(solution) + \"\\n\" + \"}\")\n",
        "\n",
        "  # Task 2.\n",
        "  elif task == 2:\n",
        "\n",
        "    # Creating lists of solutions.\n",
        "    for id_problem, authors in enumerate(df[\"paragraph-authors\"].values):\n",
        "      \n",
        "      # Solution.\n",
        "      solution = predictions[:len(authors)]\n",
        "      predictions = predictions[len(authors):]\n",
        "\n",
        "      # Saving solution.\n",
        "      with open(f\"{solution_folder}/solution-problem-{id_problem + 1}.json\", \"w\") as file:\n",
        "        file.write(\"{\" + \"\\n\" + '\\\"paragraph-authors\\\": {}'.format(solution) + \"\\n\" + \"}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning rate schedule.\n",
        "class LearningRateSchedule(tf.keras.callbacks.Callback):\n",
        "\n",
        "  # Constructor.\n",
        "  def __init__(self, model, n, reduction):\n",
        "    self.model = model\n",
        "    self.n = n\n",
        "    self.reduction = reduction\n",
        "    \n",
        "  # Initializes step attribute.\n",
        "  def on_train_begin(self, logs = None):\n",
        "    self.step = 0\n",
        "\n",
        "  # Reducing learning rate after specific number of batches.\n",
        "  def on_train_batch_end(self, batch, logs = None):\n",
        "    self.step += 1\n",
        "    lr = float(tf.keras.backend.get_value(self.model.optimizer.lr))\n",
        "    if self.step % self.n == 0:\n",
        "      new_lr = lr * (1.0 - self.reduction / 100)         \n",
        "      tf.keras.backend.set_value(self.model.optimizer.lr, new_lr)\n",
        "      print(\"\\nThe learning rate was adjusted from {:.4e} to {:.4e}.\".format(lr, new_lr))"
      ],
      "metadata": {
        "id": "KXNKhWAIGPD3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e292GXxYrafS"
      },
      "source": [
        "#Subtask 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19A-lCj8xO9a"
      },
      "source": [
        "##Data Inspection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jeleZTepwW0H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ac512260-eeb2-4641-960a-157fd70433b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   authors                      site  multi-author  \\\n",
              "0        2        serverfault.com.7z             1   \n",
              "1        2          superuser.com.7z             1   \n",
              "2        2  dba.stackexchange.com.7z             1   \n",
              "3        2          superuser.com.7z             1   \n",
              "4        2        serverfault.com.7z             1   \n",
              "\n",
              "                       changes               paragraph-authors  \\\n",
              "0  [0, 0, 0, 0, 0, 0, 0, 1, 0]  [1, 1, 1, 1, 1, 1, 1, 1, 2, 2]   \n",
              "1           [0, 0, 0, 1, 0, 0]           [1, 1, 1, 1, 2, 2, 2]   \n",
              "2              [0, 0, 1, 0, 0]              [1, 1, 1, 2, 2, 2]   \n",
              "3        [0, 0, 0, 1, 0, 0, 0]        [1, 1, 1, 1, 2, 2, 2, 2]   \n",
              "4                 [0, 0, 0, 1]                 [1, 1, 1, 1, 2]   \n",
              "\n",
              "                                          input_text  \\\n",
              "0  I use squid on RHEL6 and I want that authentic...   \n",
              "1  \"This behavior can occur if Windows has detect...   \n",
              "2  Let that thing rollback. There's nothing you c...   \n",
              "3  Is there a way to set up tests/analysis of you...   \n",
              "4  I have a single OEL/RHEL 5.3 server with a 'so...   \n",
              "\n",
              "                                       splitted_text  \n",
              "0  [I use squid on RHEL6 and I want that authenti...  \n",
              "1  [\"This behavior can occur if Windows has detec...  \n",
              "2  [Let that thing rollback. There's nothing you ...  \n",
              "3  [Is there a way to set up tests/analysis of yo...  \n",
              "4  [I have a single OEL/RHEL 5.3 server with a 's...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6125718-9974-4d1f-9678-084989e219ee\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>authors</th>\n",
              "      <th>site</th>\n",
              "      <th>multi-author</th>\n",
              "      <th>changes</th>\n",
              "      <th>paragraph-authors</th>\n",
              "      <th>input_text</th>\n",
              "      <th>splitted_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>serverfault.com.7z</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 2, 2]</td>\n",
              "      <td>I use squid on RHEL6 and I want that authentic...</td>\n",
              "      <td>[I use squid on RHEL6 and I want that authenti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>superuser.com.7z</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 2, 2, 2]</td>\n",
              "      <td>\"This behavior can occur if Windows has detect...</td>\n",
              "      <td>[\"This behavior can occur if Windows has detec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>dba.stackexchange.com.7z</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 1, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 2, 2, 2]</td>\n",
              "      <td>Let that thing rollback. There's nothing you c...</td>\n",
              "      <td>[Let that thing rollback. There's nothing you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>superuser.com.7z</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 0, 1, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 2, 2, 2, 2]</td>\n",
              "      <td>Is there a way to set up tests/analysis of you...</td>\n",
              "      <td>[Is there a way to set up tests/analysis of yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>serverfault.com.7z</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[1, 1, 1, 1, 2]</td>\n",
              "      <td>I have a single OEL/RHEL 5.3 server with a 'so...</td>\n",
              "      <td>[I have a single OEL/RHEL 5.3 server with a 's...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6125718-9974-4d1f-9678-084989e219ee')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a6125718-9974-4d1f-9678-084989e219ee button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a6125718-9974-4d1f-9678-084989e219ee');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "train_directory = '/content/dataset1/train'\n",
        "df_train = create_dataframe(train_directory)\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "c5jrS3Qd1zqd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "668ff62c-ac52-46dc-f45c-416e7aa5c882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: (1400, 7)\n",
            "Dataset columns: ['authors' 'site' 'multi-author' 'changes' 'paragraph-authors'\n",
            " 'input_text' 'splitted_text']\n",
            "Main sources: ['serverfault.com.7z' 'superuser.com.7z' 'dba.stackexchange.com.7z'\n",
            " 'gamedev.stackexchange.com.7z' 'datascience.stackexchange.com.7z'\n",
            " 'computergraphics.stackexchange.com.7z'\n",
            " 'raspberrypi.stackexchange.com.7z'\n",
            " 'networkengineering.stackexchange.com.7z'\n",
            " 'codereview.stackexchange.com.7z' 'devops.stackexchange.com.7z'\n",
            " 'cstheory.stackexchange.com.7z' 'cseducators.stackexchange.com.7z']\n",
            "Number of questions per source:\n",
            " site\n",
            "codereview.stackexchange.com.7z             74\n",
            "computergraphics.stackexchange.com.7z        4\n",
            "cseducators.stackexchange.com.7z             3\n",
            "cstheory.stackexchange.com.7z               15\n",
            "datascience.stackexchange.com.7z            32\n",
            "dba.stackexchange.com.7z                   128\n",
            "devops.stackexchange.com.7z                  4\n",
            "gamedev.stackexchange.com.7z               100\n",
            "networkengineering.stackexchange.com.7z     36\n",
            "raspberrypi.stackexchange.com.7z            30\n",
            "serverfault.com.7z                         451\n",
            "superuser.com.7z                           523\n",
            "Name: site, dtype: int64\n",
            "Average length of the text: 1580.9614285714285\n",
            "Possible number of authors: [2]\n"
          ]
        }
      ],
      "source": [
        "data_inspection(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RWg9usZw3Hrt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "9400c5d3-47c0-4dbd-fce9-f0c19b8481be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   authors                                     site  multi-author  \\\n",
              "0        2                       serverfault.com.7z             1   \n",
              "1        2                       serverfault.com.7z             1   \n",
              "2        2  networkengineering.stackexchange.com.7z             1   \n",
              "3        2                       serverfault.com.7z             1   \n",
              "4        2            cstheory.stackexchange.com.7z             1   \n",
              "\n",
              "                       changes               paragraph-authors  \\\n",
              "0              [0, 0, 1, 0, 0]              [1, 1, 1, 2, 2, 2]   \n",
              "1           [0, 1, 0, 0, 0, 0]           [1, 1, 2, 2, 2, 2, 2]   \n",
              "2                 [1, 0, 0, 0]                 [1, 2, 2, 2, 2]   \n",
              "3  [0, 0, 0, 0, 1, 0, 0, 0, 0]  [1, 1, 1, 1, 1, 2, 2, 2, 2, 2]   \n",
              "4                    [1, 0, 0]                    [1, 2, 2, 2]   \n",
              "\n",
              "                                          input_text  \\\n",
              "0  If you can handle a slight delay in the data y...   \n",
              "1  I figured i'd share my method which worked to ...   \n",
              "2  This is not possible the way I want to impleme...   \n",
              "3  We have central HQ building and a lot of small...   \n",
              "4  Moser's proof of the constructive Lovasz Local...   \n",
              "\n",
              "                                       splitted_text  \n",
              "0  [If you can handle a slight delay in the data ...  \n",
              "1  [I figured i'd share my method which worked to...  \n",
              "2  [This is not possible the way I want to implem...  \n",
              "3  [We have central HQ building and a lot of smal...  \n",
              "4  [Moser's proof of the constructive Lovasz Loca...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49cb75a3-6132-4959-8489-9dc4f666cd54\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>authors</th>\n",
              "      <th>site</th>\n",
              "      <th>multi-author</th>\n",
              "      <th>changes</th>\n",
              "      <th>paragraph-authors</th>\n",
              "      <th>input_text</th>\n",
              "      <th>splitted_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>serverfault.com.7z</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 1, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 2, 2, 2]</td>\n",
              "      <td>If you can handle a slight delay in the data y...</td>\n",
              "      <td>[If you can handle a slight delay in the data ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>serverfault.com.7z</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 2, 2, 2, 2, 2]</td>\n",
              "      <td>I figured i'd share my method which worked to ...</td>\n",
              "      <td>[I figured i'd share my method which worked to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>networkengineering.stackexchange.com.7z</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 2, 2, 2, 2]</td>\n",
              "      <td>This is not possible the way I want to impleme...</td>\n",
              "      <td>[This is not possible the way I want to implem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>serverfault.com.7z</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 2, 2, 2, 2, 2]</td>\n",
              "      <td>We have central HQ building and a lot of small...</td>\n",
              "      <td>[We have central HQ building and a lot of smal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>cstheory.stackexchange.com.7z</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 0, 0]</td>\n",
              "      <td>[1, 2, 2, 2]</td>\n",
              "      <td>Moser's proof of the constructive Lovasz Local...</td>\n",
              "      <td>[Moser's proof of the constructive Lovasz Loca...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49cb75a3-6132-4959-8489-9dc4f666cd54')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49cb75a3-6132-4959-8489-9dc4f666cd54 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49cb75a3-6132-4959-8489-9dc4f666cd54');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "valid_directory = '/content/dataset1/validation'\n",
        "df_valid = create_dataframe(valid_directory)\n",
        "df_valid.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "QRGTBkey3IB-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aae1f1bb-fe3b-496c-8992-61d2cc0bb70c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: (300, 7)\n",
            "Dataset columns: ['authors' 'site' 'multi-author' 'changes' 'paragraph-authors'\n",
            " 'input_text' 'splitted_text']\n",
            "Main sources: ['serverfault.com.7z' 'networkengineering.stackexchange.com.7z'\n",
            " 'cstheory.stackexchange.com.7z' 'superuser.com.7z'\n",
            " 'gamedev.stackexchange.com.7z' 'raspberrypi.stackexchange.com.7z'\n",
            " 'datascience.stackexchange.com.7z' 'codereview.stackexchange.com.7z'\n",
            " 'dba.stackexchange.com.7z' 'computergraphics.stackexchange.com.7z'\n",
            " 'cseducators.stackexchange.com.7z' 'devops.stackexchange.com.7z']\n",
            "Number of questions per source:\n",
            " site\n",
            "codereview.stackexchange.com.7z             19\n",
            "computergraphics.stackexchange.com.7z        1\n",
            "cseducators.stackexchange.com.7z             1\n",
            "cstheory.stackexchange.com.7z                5\n",
            "datascience.stackexchange.com.7z             8\n",
            "dba.stackexchange.com.7z                    27\n",
            "devops.stackexchange.com.7z                  1\n",
            "gamedev.stackexchange.com.7z                21\n",
            "networkengineering.stackexchange.com.7z      7\n",
            "raspberrypi.stackexchange.com.7z             5\n",
            "serverfault.com.7z                         100\n",
            "superuser.com.7z                           105\n",
            "Name: site, dtype: int64\n",
            "Average length of the text: 1597.41\n",
            "Possible number of authors: [2]\n"
          ]
        }
      ],
      "source": [
        "data_inspection(df_valid)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "P6S9rfakGKC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model checkpoint.\n",
        "checkpoint = \"bert-base-cased\"\n",
        "\n",
        "# Getting tokenizer.\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "c9945af5abf74bb595e3a9e2d862180d",
            "2062484144984f91832a51fe928612a6",
            "5f1163c8ed1b4dee9aa4d389921b310b",
            "63a68d951c8f40dc94bafdc4cf2417bb",
            "56159c9e1e164c1e8c7a50b79b420eff",
            "a7e8eb4d7ace4a998e1f84474c6c5092",
            "f795592f4d3945299193ee7409ec27c9",
            "8474318a1a2f4f18b3550860654ccc09",
            "f105e1e4764e44ce8e2df8cc3e8a0d76",
            "5b4e189c76c94d3ea03d01d9275b5e15",
            "a58cf8faf41b4f9b98a20f6e962b8eee",
            "446e721591ce48f3aaca6a04dcce2ecc",
            "ee486b4fa89f4043bce2e026e6a422ea",
            "5a8e1db6da244451b2d875b8094cb2f6",
            "344719c595b94f2ba82c072423665598",
            "b37073190c8b4c3cb609295727555ec0",
            "81127e8a748c4aaa9c9133985d919802",
            "d9e0da5d117949bc920ed43c6d129945",
            "554cbcd37ca04665a3d0f4484faf6176",
            "1919f79a73db43ed8c76d93210b70dff",
            "fd3aa08b3e904748b7d4e6d059849e07",
            "d2e4aa46cc2f4d67b49d16adad06c687",
            "7f4eecc7a5d34bed9eeaf6944ef73eb0",
            "f64b08d4e34e4bd091b534dfcd689dd3",
            "2a330d92ecd14402bd4088020085bbbd",
            "a8ef8f7bd6094fb3805b8c6ce2f8a3f2",
            "6486d6e2d8f545729ebf3c35717206ff",
            "6953cb032f64446d938b2d04447dde82",
            "73e08b4273bb42499292909cdacbecdc",
            "1eee744fb70a4e2d935ec54f4d9d64a0",
            "27313a45c92f44c4b70b4dc286912d51",
            "48a5e59dbfc5400fa0945a9f373c1a7b",
            "527dee50ddb44b1fa46649c9f194674b",
            "82ec5215d7684e7aa42cd3c6a4d6f622",
            "5f58c19acd7848cdaf41d694d5143c65",
            "f50d7813d6e749d0bb7448e45c337bac",
            "353caa03fe594b61a970d27ac0ff75da",
            "5e57eb2258ec455b92ad5d2c3d406806",
            "58a5e4bd152649b381d43ed55fe72a78",
            "b81446a0de5848768e200eb3f4f2f9fa",
            "08aec46c3873481b986e32738cbff8fd",
            "0161f8a2105e4899b43e98a7cd617a2a",
            "92d6b8b7f88545eab80b1cde8d8ab671",
            "6b5a88b1475a4f069a71ab9c8eb980dd"
          ],
          "height": 145
        },
        "id": "9swlyHyt5-K1",
        "outputId": "b5595f07-8ead-41ce-dbaa-40faf72bbfdc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9945af5abf74bb595e3a9e2d862180d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "446e721591ce48f3aaca6a04dcce2ecc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f4eecc7a5d34bed9eeaf6944ef73eb0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82ec5215d7684e7aa42cd3c6a4d6f622"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qudDXlmG3Lsi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89302fe3-ecdc-4e74-f7f6-0c1e059adca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_ids: (30000, 256), train_labels: (30000,), train_masks: (30000, 256), train_type_ids: (30000, 256).\n",
            "valid_ids: (2141, 256), valid_labels: (2141,), valid_masks: (2141, 256), valid_type_ids: (2141, 256).\n"
          ]
        }
      ],
      "source": [
        "# Max input length.\n",
        "MAX_LENGTH = 256\n",
        "\n",
        "# Number of samples per class.\n",
        "MAX_SAMPLES = 15000\n",
        "\n",
        "# Splitting data.\n",
        "train_ids, train_labels, train_masks, train_type_ids = preprocess_with_data_augmentation(df_train[\"splitted_text\"].values, df_train[\"paragraph-authors\"].values, tokenizer, MAX_LENGTH, max_samples = MAX_SAMPLES)\n",
        "valid_ids, valid_labels, valid_masks, valid_type_ids = preprocess_without_data_augmentation(df_valid[\"splitted_text\"].values, df_valid[\"changes\"].values, tokenizer, MAX_LENGTH)\n",
        "\n",
        "# Printing shapes.\n",
        "print(f\"train_ids: {train_ids.shape}, train_labels: {train_labels.shape}, train_masks: {train_masks.shape}, train_type_ids: {train_type_ids.shape}.\")\n",
        "print(f\"valid_ids: {valid_ids.shape}, valid_labels: {valid_labels.shape}, valid_masks: {valid_masks.shape}, valid_type_ids: {valid_type_ids.shape}.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing classes distributions.\n",
        "classes_without_upsampling, counts_without_upsampling = np.unique([item for sublist in df_train[\"changes\"] for item in sublist], return_counts = True)\n",
        "classes_with_upsampling, counts_with_upsampling = np.unique(train_labels, return_counts = True)\n",
        "\n",
        "# Normalizing.\n",
        "counts_without_upsampling = counts_without_upsampling / np.sum(counts_without_upsampling) * 100\n",
        "counts_with_upsampling = counts_with_upsampling / np.sum(counts_with_upsampling) * 100\n",
        "\n",
        "# Plot classes distribution.\n",
        "plot_classes_distribution([classes_without_upsampling, classes_with_upsampling], [counts_without_upsampling, counts_with_upsampling], \"subtask1_m1_distribution\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "amJEsl3lRvBo",
        "outputId": "2dc81ba5-3321-44fe-b39d-ecbbaf896919"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models Definition and Training"
      ],
      "metadata": {
        "id": "kKVeReaTA72d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training hyperparameters.\n",
        "LR = 5e-5\n",
        "BATCH_SIZE = 16\n",
        "N_EPOCHS = 2\n",
        "\n",
        "# Learning rate schedule hyperparameters.\n",
        "N_DECREASE_LR = 5\n",
        "LR_REDUCTION = 20"
      ],
      "metadata": {
        "id": "VvUJWFV6F2li"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $m_1^1$"
      ],
      "metadata": {
        "id": "P_CjAhHbGmgN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "2VcF0wC43O4G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "61c7f62eacff434698e2ad7bfb28426c",
            "5a05817b85b84c94ab0ac935d766e3ff",
            "c3b83a805b5d42ea9488503256263baf",
            "4d8cb3b4b9db4ae5b7bd41cd7d1db3ce",
            "6e9e0f5a090d47248ea81cd3de0eda28",
            "fdac71633e3d4a458db98785e20eadf1",
            "7d4189398acd4ac3a9b7fc80067953fa",
            "a0b59a0dbd994e3e80ef647a5a5c4270",
            "5b7eb794191845b0b89fca3068fbbd5d",
            "d34418188eca4e9a86269fac0ebb4aed",
            "b7e38b6b94044f979a20a8d225fa6ef8"
          ]
        },
        "outputId": "826a4b90-c5c6-45d3-affe-82c74cde722e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/527M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61c7f62eacff434698e2ad7bfb28426c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "# List of layers.\n",
        "layers = [tf.keras.layers.GlobalMaxPool1D()]\n",
        "\n",
        "# Creating the model.\n",
        "m1 = create_bert_model(TFAutoModel.from_pretrained(checkpoint), (MAX_LENGTH,), n_classes = 2, layers = layers)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary.\n",
        "m1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-Xa2bHJJHM5",
        "outputId": "c9e93994-b629-424f-d365-880f42a5f22b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " token_type_ids (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_masks[0][0]',        \n",
            "                                tentions(last_hidde               'token_type_ids[0][0]']         \n",
            "                                n_state=(None, 256,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d (GlobalMa  (None, 768)         0           ['tf_bert_model[0][0]']          \n",
            " xPooling1D)                                                                                      \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 2)            1538        ['global_max_pooling1d[0][0]']   \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,311,810\n",
            "Trainable params: 108,311,810\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "4yeLqPC43Q3M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "381c9913-42e2-4a57-9a09-9506f38f03d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 374/1875 [====>.........................] - ETA: 21:11 - loss: 0.5984 - accuracy: 0.6741\n",
            "The learning rate was adjusted from 5.0000e-05 to 4.0000e-05.\n",
            " 749/1875 [==========>...................] - ETA: 16:07 - loss: 0.5455 - accuracy: 0.7129\n",
            "The learning rate was adjusted from 4.0000e-05 to 3.2000e-05.\n",
            "1124/1875 [================>.............] - ETA: 10:48 - loss: 0.5040 - accuracy: 0.7403\n",
            "The learning rate was adjusted from 3.2000e-05 to 2.5600e-05.\n",
            "1499/1875 [======================>.......] - ETA: 5:25 - loss: 0.4724 - accuracy: 0.7619\n",
            "The learning rate was adjusted from 2.5600e-05 to 2.0480e-05.\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.4429 - accuracy: 0.7796\n",
            "The learning rate was adjusted from 2.0480e-05 to 1.6384e-05.\n",
            "1875/1875 [==============================] - 1635s 867ms/step - loss: 0.4429 - accuracy: 0.7796\n",
            "Epoch 2/2\n",
            " 374/1875 [====>.........................] - ETA: 21:47 - loss: 0.1789 - accuracy: 0.9347\n",
            "The learning rate was adjusted from 1.6384e-05 to 1.3107e-05.\n",
            " 749/1875 [==========>...................] - ETA: 16:22 - loss: 0.1699 - accuracy: 0.9359\n",
            "The learning rate was adjusted from 1.3107e-05 to 1.0486e-05.\n",
            "1124/1875 [================>.............] - ETA: 10:55 - loss: 0.1641 - accuracy: 0.9377\n",
            "The learning rate was adjusted from 1.0486e-05 to 8.3886e-06.\n",
            "1499/1875 [======================>.......] - ETA: 5:27 - loss: 0.1574 - accuracy: 0.9401\n",
            "The learning rate was adjusted from 8.3886e-06 to 6.7109e-06.\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.1518 - accuracy: 0.9425\n",
            "The learning rate was adjusted from 6.7109e-06 to 5.3687e-06.\n",
            "1875/1875 [==============================] - 1632s 870ms/step - loss: 0.1517 - accuracy: 0.9425\n"
          ]
        }
      ],
      "source": [
        "# Compiling.\n",
        "m1.compile(optimizer = Adam(LR), loss = SparseCategoricalCrossentropy(from_logits = False), metrics = [\"accuracy\"])\n",
        "\n",
        "# Callbacks.\n",
        "callbacks = [LearningRateSchedule(m1, n = int(np.round(len(train_ids) / BATCH_SIZE / N_DECREASE_LR)), reduction = 20)]\n",
        "\n",
        "# Fitting.\n",
        "m1.fit({\"input_ids\": train_ids, \"attention_masks\": train_masks, \"token_type_ids\": train_type_ids}, train_labels, epochs = N_EPOCHS, batch_size = BATCH_SIZE, callbacks = callbacks)\n",
        "\n",
        "# Saving weights.\n",
        "m1.save_weights(\"subtask_1_m1.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $m_2^1$"
      ],
      "metadata": {
        "id": "psgcLmEORWD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of layers.\n",
        "layers = [tf.keras.layers.GlobalAveragePooling1D()]\n",
        "\n",
        "# Creating the model.\n",
        "m2 = create_bert_model(TFAutoModel.from_pretrained(checkpoint), (MAX_LENGTH,), n_classes = 2, layers = layers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfywSmz4S05b",
        "outputId": "22519a9f-dec3-4c95-ea4c-80ef401a7679"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary.\n",
        "m2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1PjXFLhJUtJ",
        "outputId": "9d1da344-69ac-4664-b092-f4235a4737ca"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " token_type_ids (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model_1 (TFBertModel)  TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_masks[0][0]',        \n",
            "                                tentions(last_hidde               'token_type_ids[0][0]']         \n",
            "                                n_state=(None, 256,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " global_average_pooling1d (Glob  (None, 768)         0           ['tf_bert_model_1[0][0]']        \n",
            " alAveragePooling1D)                                                                              \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 2)            1538        ['global_average_pooling1d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,311,810\n",
            "Trainable params: 108,311,810\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling.\n",
        "m2.compile(optimizer = Adam(LR), loss = SparseCategoricalCrossentropy(from_logits = False), metrics = [\"accuracy\"])\n",
        "\n",
        "# Callbacks.\n",
        "callbacks = [LearningRateSchedule(m2, n = int(np.round(len(train_ids) / BATCH_SIZE / N_DECREASE_LR)), reduction = 20)]\n",
        "\n",
        "# Fitting.\n",
        "m2.fit({\"input_ids\": train_ids, \"attention_masks\": train_masks, \"token_type_ids\": train_type_ids}, train_labels, epochs = N_EPOCHS, batch_size = BATCH_SIZE, callbacks = callbacks)\n",
        "\n",
        "# Saving weights.\n",
        "m2.save_weights(\"subtask_1_m2.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsro-EEmTdWJ",
        "outputId": "416088f8-8da2-4b71-b26b-f763901dc378"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 374/1875 [====>.........................] - ETA: 22:13 - loss: 0.5903 - accuracy: 0.6678\n",
            "The learning rate was adjusted from 5.0000e-05 to 4.0000e-05.\n",
            " 749/1875 [==========>...................] - ETA: 16:43 - loss: 0.5314 - accuracy: 0.7145\n",
            "The learning rate was adjusted from 4.0000e-05 to 3.2000e-05.\n",
            "1124/1875 [================>.............] - ETA: 11:09 - loss: 0.4839 - accuracy: 0.7503\n",
            "The learning rate was adjusted from 3.2000e-05 to 2.5600e-05.\n",
            "1499/1875 [======================>.......] - ETA: 5:35 - loss: 0.4451 - accuracy: 0.7752\n",
            "The learning rate was adjusted from 2.5600e-05 to 2.0480e-05.\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.4107 - accuracy: 0.7965\n",
            "The learning rate was adjusted from 2.0480e-05 to 1.6384e-05.\n",
            "1875/1875 [==============================] - 1682s 892ms/step - loss: 0.4107 - accuracy: 0.7965\n",
            "Epoch 2/2\n",
            " 374/1875 [====>.........................] - ETA: 22:21 - loss: 0.1201 - accuracy: 0.9547\n",
            "The learning rate was adjusted from 1.6384e-05 to 1.3107e-05.\n",
            " 749/1875 [==========>...................] - ETA: 16:46 - loss: 0.1114 - accuracy: 0.9583\n",
            "The learning rate was adjusted from 1.3107e-05 to 1.0486e-05.\n",
            "1124/1875 [================>.............] - ETA: 11:11 - loss: 0.1097 - accuracy: 0.9594\n",
            "The learning rate was adjusted from 1.0486e-05 to 8.3886e-06.\n",
            "1499/1875 [======================>.......] - ETA: 5:35 - loss: 0.1045 - accuracy: 0.9612\n",
            "The learning rate was adjusted from 8.3886e-06 to 6.7109e-06.\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.1008 - accuracy: 0.9622\n",
            "The learning rate was adjusted from 6.7109e-06 to 5.3687e-06.\n",
            "1875/1875 [==============================] - 1675s 894ms/step - loss: 0.1008 - accuracy: 0.9622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $m_3^1$"
      ],
      "metadata": {
        "id": "k1z3cTMPTgq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of layers.\n",
        "layers = [tf.keras.layers.GlobalMaxPool1D(),\n",
        "          tf.keras.layers.Dense(128, activation = \"relu\")]\n",
        "\n",
        "# Creating the model.\n",
        "m3 = create_bert_model(TFAutoModel.from_pretrained(checkpoint), (MAX_LENGTH,), n_classes = 2, layers = layers)"
      ],
      "metadata": {
        "id": "JnTxwD6vTfyG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af0a642c-65a3-4ecc-aa5b-ce45e1d58a5d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary.\n",
        "m3.summary()"
      ],
      "metadata": {
        "id": "dbg6nFhfJeot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f77ff4c-af1f-41d1-eb7b-4f89a7c4a4ab"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " token_type_ids (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model_2 (TFBertModel)  TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_masks[0][0]',        \n",
            "                                tentions(last_hidde               'token_type_ids[0][0]']         \n",
            "                                n_state=(None, 256,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_1 (Global  (None, 768)         0           ['tf_bert_model_2[0][0]']        \n",
            " MaxPooling1D)                                                                                    \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          98432       ['global_max_pooling1d_1[0][0]'] \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 2)            258         ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,408,962\n",
            "Trainable params: 108,408,962\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling.\n",
        "m3.compile(optimizer = Adam(LR), loss = SparseCategoricalCrossentropy(from_logits = False), metrics = [\"accuracy\"])\n",
        "\n",
        "# Callbacks.\n",
        "callbacks = [LearningRateSchedule(m3, n = int(np.round(len(train_ids) / BATCH_SIZE / N_DECREASE_LR)), reduction = 20)]\n",
        "\n",
        "# Fitting.\n",
        "m3.fit({\"input_ids\": train_ids, \"attention_masks\": train_masks, \"token_type_ids\": train_type_ids}, train_labels, epochs = N_EPOCHS, batch_size = BATCH_SIZE, callbacks = callbacks)\n",
        "\n",
        "# Saving weights.\n",
        "m3.save_weights(\"subtask_1_m3.h5\")"
      ],
      "metadata": {
        "id": "t2khGISPTurI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f735ceb-146a-4fdb-c013-2097a4a39ce0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 374/1875 [====>.........................] - ETA: 21:28 - loss: 0.5914 - accuracy: 0.6758\n",
            "The learning rate was adjusted from 5.0000e-05 to 4.0000e-05.\n",
            " 749/1875 [==========>...................] - ETA: 16:10 - loss: 0.5393 - accuracy: 0.7134\n",
            "The learning rate was adjusted from 4.0000e-05 to 3.2000e-05.\n",
            "1124/1875 [================>.............] - ETA: 10:48 - loss: 0.4990 - accuracy: 0.7403\n",
            "The learning rate was adjusted from 3.2000e-05 to 2.5600e-05.\n",
            "1499/1875 [======================>.......] - ETA: 5:25 - loss: 0.4655 - accuracy: 0.7636\n",
            "The learning rate was adjusted from 2.5600e-05 to 2.0480e-05.\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.4343 - accuracy: 0.7831\n",
            "The learning rate was adjusted from 2.0480e-05 to 1.6384e-05.\n",
            "1875/1875 [==============================] - 1631s 865ms/step - loss: 0.4342 - accuracy: 0.7831\n",
            "Epoch 2/2\n",
            " 374/1875 [====>.........................] - ETA: 21:47 - loss: 0.1687 - accuracy: 0.9358\n",
            "The learning rate was adjusted from 1.6384e-05 to 1.3107e-05.\n",
            " 749/1875 [==========>...................] - ETA: 16:20 - loss: 0.1574 - accuracy: 0.9389\n",
            "The learning rate was adjusted from 1.3107e-05 to 1.0486e-05.\n",
            "1124/1875 [================>.............] - ETA: 10:53 - loss: 0.1532 - accuracy: 0.9409\n",
            "The learning rate was adjusted from 1.0486e-05 to 8.3886e-06.\n",
            "1499/1875 [======================>.......] - ETA: 5:26 - loss: 0.1456 - accuracy: 0.9441\n",
            "The learning rate was adjusted from 8.3886e-06 to 6.7109e-06.\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.1399 - accuracy: 0.9463\n",
            "The learning rate was adjusted from 6.7109e-06 to 5.3687e-06.\n",
            "1875/1875 [==============================] - 1628s 868ms/step - loss: 0.1398 - accuracy: 0.9463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $m_4^1$"
      ],
      "metadata": {
        "id": "uVjK7TlET2cM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of layers.\n",
        "layers = [tf.keras.layers.Conv1D(filters = 128, kernel_size = 3, activation = \"relu\"),\n",
        "          tf.keras.layers.MaxPooling1D(pool_size = 2),\n",
        "          tf.keras.layers.Conv1D(filters = 128, kernel_size = 3, activation = \"relu\"),\n",
        "          tf.keras.layers.MaxPooling1D(pool_size = 2),\n",
        "          tf.keras.layers.Conv1D(filters = 128, kernel_size = 3, activation = \"relu\"),\n",
        "          tf.keras.layers.MaxPooling1D(pool_size = 2),\n",
        "          tf.keras.layers.Flatten()]\n",
        "\n",
        "# Creating the model.\n",
        "m4 = create_bert_model(TFAutoModel.from_pretrained(checkpoint), (MAX_LENGTH,), n_classes = 2, layers = layers)"
      ],
      "metadata": {
        "id": "F1A78BU_T4tv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67a2693f-c066-4b88-ff6b-ecdaced7b987"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary.\n",
        "m4.summary()"
      ],
      "metadata": {
        "id": "vts4MedrJk3m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccbbb4a2-0f23-4ed1-9c33-9903240ec916"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " attention_masks (InputLayer)   [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " token_type_ids (InputLayer)    [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " tf_bert_model_3 (TFBertModel)  TFBaseModelOutputWi  108310272   ['input_ids[0][0]',              \n",
            "                                thPoolingAndCrossAt               'attention_masks[0][0]',        \n",
            "                                tentions(last_hidde               'token_type_ids[0][0]']         \n",
            "                                n_state=(None, 256,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 254, 128)     295040      ['tf_bert_model_3[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1D)   (None, 127, 128)     0           ['conv1d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 125, 128)     49280       ['max_pooling1d[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPooling1D)  (None, 62, 128)     0           ['conv1d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 60, 128)      49280       ['max_pooling1d_1[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling1d_2 (MaxPooling1D)  (None, 30, 128)     0           ['conv1d_2[0][0]']               \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 3840)         0           ['max_pooling1d_2[0][0]']        \n",
            "                                                                                                  \n",
            " outputs (Dense)                (None, 2)            7682        ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,711,554\n",
            "Trainable params: 108,711,554\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling.\n",
        "m4.compile(optimizer = Adam(LR), loss = SparseCategoricalCrossentropy(from_logits = False), metrics = [\"accuracy\"])\n",
        "\n",
        "# Callbacks.\n",
        "callbacks = [LearningRateSchedule(m4, n = int(np.round(len(train_ids) / BATCH_SIZE / N_DECREASE_LR)), reduction = 20)]\n",
        "\n",
        "# Fitting.\n",
        "m4.fit({\"input_ids\": train_ids, \"attention_masks\": train_masks, \"token_type_ids\": train_type_ids}, train_labels, epochs = N_EPOCHS, batch_size = BATCH_SIZE, callbacks = callbacks)\n",
        "\n",
        "# Saving weights.\n",
        "m4.save_weights(\"subtask_1_m4.h5\")"
      ],
      "metadata": {
        "id": "6BLcZRuoUcvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "376b7928-d73f-472d-dfb3-f1d03a0d9ef9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 374/1875 [====>.........................] - ETA: 22:15 - loss: 0.6173 - accuracy: 0.6347\n",
            "The learning rate was adjusted from 5.0000e-05 to 4.0000e-05.\n",
            " 749/1875 [==========>...................] - ETA: 16:45 - loss: 0.5673 - accuracy: 0.6806\n",
            "The learning rate was adjusted from 4.0000e-05 to 3.2000e-05.\n",
            "1124/1875 [================>.............] - ETA: 11:11 - loss: 0.5268 - accuracy: 0.7142\n",
            "The learning rate was adjusted from 3.2000e-05 to 2.5600e-05.\n",
            "1499/1875 [======================>.......] - ETA: 5:36 - loss: 0.4955 - accuracy: 0.7380\n",
            "The learning rate was adjusted from 2.5600e-05 to 2.0480e-05.\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.4648 - accuracy: 0.7592\n",
            "The learning rate was adjusted from 2.0480e-05 to 1.6384e-05.\n",
            "1875/1875 [==============================] - 1694s 895ms/step - loss: 0.4649 - accuracy: 0.7592\n",
            "Epoch 2/2\n",
            " 374/1875 [====>.........................] - ETA: 22:25 - loss: 0.2050 - accuracy: 0.9168\n",
            "The learning rate was adjusted from 1.6384e-05 to 1.3107e-05.\n",
            " 749/1875 [==========>...................] - ETA: 16:49 - loss: 0.1927 - accuracy: 0.9225\n",
            "The learning rate was adjusted from 1.3107e-05 to 1.0486e-05.\n",
            "1124/1875 [================>.............] - ETA: 11:13 - loss: 0.1858 - accuracy: 0.9270\n",
            "The learning rate was adjusted from 1.0486e-05 to 8.3886e-06.\n",
            "1499/1875 [======================>.......] - ETA: 5:36 - loss: 0.1792 - accuracy: 0.9294\n",
            "The learning rate was adjusted from 8.3886e-06 to 6.7109e-06.\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.1726 - accuracy: 0.9327\n",
            "The learning rate was adjusted from 6.7109e-06 to 5.3687e-06.\n",
            "1875/1875 [==============================] - 1680s 896ms/step - loss: 0.1725 - accuracy: 0.9327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Testing"
      ],
      "metadata": {
        "id": "ynHIOWIFA_hO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $m_1^1$"
      ],
      "metadata": {
        "id": "8Oo2pwnyH3md"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation test.\n",
        "y_pred_m1 = np.argmax(m1.predict({\"input_ids\": valid_ids, \"attention_masks\": valid_masks, \"token_type_ids\": valid_type_ids}), axis = 1)\n",
        "\n",
        "# Saving true and predicted labels.\n",
        "np.save(\"subtask1_m1_pred.npy\", y_pred_m1)\n",
        "np.save(\"subtask1_m1_true.npy\", valid_labels)\n",
        "\n",
        "# Printing score.\n",
        "print(classification_report(valid_labels, y_pred_m1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa-Da_Ei7lcw",
        "outputId": "0ac07fba-629f-4b7d-ed9c-501277ae961b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67/67 [==============================] - 39s 521ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.82      0.88      1841\n",
            "           1       0.42      0.81      0.55       300\n",
            "\n",
            "    accuracy                           0.82      2141\n",
            "   macro avg       0.69      0.81      0.72      2141\n",
            "weighted avg       0.89      0.82      0.84      2141\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $m_2^1$"
      ],
      "metadata": {
        "id": "x483SzfUTKBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation test.\n",
        "y_pred_m2 = np.argmax(m2.predict({\"input_ids\": valid_ids, \"attention_masks\": valid_masks, \"token_type_ids\": valid_type_ids}), axis = 1)\n",
        "\n",
        "# Saving true and predicted labels.\n",
        "np.save(\"subtask1_m2_pred.npy\", y_pred_m2)\n",
        "np.save(\"subtask1_m2_true.npy\", valid_labels)\n",
        "\n",
        "# Printing score.\n",
        "print(classification_report(valid_labels, y_pred_m2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFET_-c67pOc",
        "outputId": "84c7525a-491b-43ec-8532-beb6fa26f51c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67/67 [==============================] - 38s 527ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.81      0.88      1841\n",
            "           1       0.41      0.82      0.55       300\n",
            "\n",
            "    accuracy                           0.81      2141\n",
            "   macro avg       0.69      0.81      0.71      2141\n",
            "weighted avg       0.89      0.81      0.83      2141\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $m_3^1$"
      ],
      "metadata": {
        "id": "IAcR10ZhTQEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation test.\n",
        "y_pred_m3 = np.argmax(m3.predict({\"input_ids\": valid_ids, \"attention_masks\": valid_masks, \"token_type_ids\": valid_type_ids}), axis = 1)\n",
        "\n",
        "# Saving true and predicted labels.\n",
        "np.save(\"subtask1_m3_pred.npy\", y_pred_m3)\n",
        "np.save(\"subtask1_m3_true.npy\", valid_labels)\n",
        "\n",
        "# Printing score.\n",
        "print(classification_report(valid_labels, y_pred_m3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec2UrVus7sDK",
        "outputId": "4484c30a-3851-4883-987f-3cca782e9914"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67/67 [==============================] - 38s 532ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.80      0.88      1841\n",
            "           1       0.40      0.82      0.54       300\n",
            "\n",
            "    accuracy                           0.81      2141\n",
            "   macro avg       0.69      0.81      0.71      2141\n",
            "weighted avg       0.89      0.81      0.83      2141\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $m_4^1$"
      ],
      "metadata": {
        "id": "l0s_GsmPTUGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation test.\n",
        "y_pred_m4 = np.argmax(m4.predict({\"input_ids\": valid_ids, \"attention_masks\": valid_masks, \"token_type_ids\": valid_type_ids}), axis = 1)\n",
        "\n",
        "# Saving true and predicted labels.\n",
        "np.save(\"subtask1_m4_pred.npy\", y_pred_m4)\n",
        "np.save(\"subtask1_m4_true.npy\", valid_labels)\n",
        "\n",
        "# Printing score.\n",
        "print(classification_report(valid_labels, y_pred_m4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnajKpa-7uga",
        "outputId": "d5dfe350-c016-444a-aa62-f39438c2f9f5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67/67 [==============================] - 40s 543ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.77      0.86      1841\n",
            "           1       0.37      0.81      0.51       300\n",
            "\n",
            "    accuracy                           0.78      2141\n",
            "   macro avg       0.66      0.79      0.68      2141\n",
            "weighted avg       0.88      0.78      0.81      2141\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fG4laDkrfu1"
      },
      "source": [
        "#Subtask 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Inspection"
      ],
      "metadata": {
        "id": "um25XokQrUCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_directory = '/content/dataset2/train'\n",
        "df_train = create_dataframe(train_directory)\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "7E5Go-Jmra-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_inspection(df_train)"
      ],
      "metadata": {
        "id": "vyw6y2Ufrdah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_directory = '/content/dataset2/validation'\n",
        "df_valid = create_dataframe(valid_directory)\n",
        "df_valid.head()"
      ],
      "metadata": {
        "id": "CcI7RFebrfjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_inspection(df_valid)"
      ],
      "metadata": {
        "id": "0-nY6AlDrhMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing"
      ],
      "metadata": {
        "id": "lfA9ZqDGIc-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model checkpoint.\n",
        "checkpoint = \"bert-base-cased\"\n",
        "\n",
        "# Getting tokenizer.\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "xG5AX_8TIgOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Max input length.\n",
        "MAX_LENGTH = 256\n",
        "\n",
        "# Number of samples per class.\n",
        "MAX_SAMPLES = 15000\n",
        "\n",
        "# Splitting data.\n",
        "train_ids, train_labels, train_masks, train_type_ids = preprocess_without_data_augmentation(df_train[\"splitted_text\"].values, df_train[\"changes\"].values, tokenizer, MAX_LENGTH, max_samples = MAX_SAMPLES)\n",
        "valid_ids, valid_labels, valid_masks, valid_type_ids = preprocess_with_data_augmentation(df_valid[\"splitted_text\"].values, df_valid[\"paragraph-authors\"].values, tokenizer, MAX_LENGTH, total_upsampling = True)\n",
        "\n",
        "# Printing shapes.\n",
        "print(f\"train_ids: {train_ids.shape}, train_labels: {train_labels.shape}, train_masks: {train_masks.shape}, train_type_ids: {train_type_ids.shape}.\")\n",
        "print(f\"valid_ids: {valid_ids.shape}, valid_labels: {valid_labels.shape}, valid_masks: {valid_masks.shape}, valid_type_ids: {valid_type_ids.shape}.\")"
      ],
      "metadata": {
        "id": "WLpXiBiLImqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing classes distributions.\n",
        "classes_without_upsampling, counts_without_upsampling = np.unique([item for sublist in df_train[\"changes\"] for item in sublist], return_counts = True)\n",
        "classes_with_upsampling, counts_with_upsampling = np.unique(train_labels, return_counts = True)\n",
        "\n",
        "# Normalizing.\n",
        "counts_without_upsampling = counts_without_upsampling / np.sum(counts_without_upsampling) * 100\n",
        "counts_with_upsampling = counts_with_upsampling / np.sum(counts_with_upsampling) * 100\n",
        "\n",
        "# Plot classes distribution.\n",
        "plot_classes_distribution([classes_without_upsampling, classes_with_upsampling], [counts_without_upsampling, counts_with_upsampling], \"subtask2_m1_distribution\")"
      ],
      "metadata": {
        "id": "RlYMao4UJhyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models Definition and Training"
      ],
      "metadata": {
        "id": "V99U_ncGrVcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training hyperparameters.\n",
        "LR = 5e-5\n",
        "BATCH_SIZE = 16\n",
        "N_EPOCHS = 2\n",
        "\n",
        "# Learning rate schedule hyperparameters.\n",
        "N_DECREASE_LR = 5\n",
        "LR_REDUCTION = 20"
      ],
      "metadata": {
        "id": "sHMiBFC2IPHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $m_1^1$"
      ],
      "metadata": {
        "id": "h3VjCVnDImBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of layers.\n",
        "layers = [tf.keras.layers.GlobalMaxPool1D()]\n",
        "\n",
        "# Creating the model.\n",
        "m11 = create_bert_model(TFAutoModel.from_pretrained(checkpoint), (MAX_LENGTH,), n_classes = 2, layers = layers)"
      ],
      "metadata": {
        "id": "IJkH1RDlK3B2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary.\n",
        "m11.summary()"
      ],
      "metadata": {
        "id": "WtvllVZLK4UR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling.\n",
        "m11.compile(optimizer = Adam(LR), loss = SparseCategoricalCrossentropy(from_logits = False), metrics = [\"accuracy\"])\n",
        "\n",
        "# Callbacks.\n",
        "callbacks = [LearningRateSchedule(m11, n = int(np.round(len(train_ids) / BATCH_SIZE / N_DECREASE_LR)), reduction = 20)]\n",
        "\n",
        "# Fitting.\n",
        "m11.fit({\"input_ids\": train_ids, \"attention_masks\": train_masks, \"token_type_ids\": train_type_ids}, train_labels, epochs = N_EPOCHS, batch_size = BATCH_SIZE, callbacks = callbacks)\n",
        "\n",
        "# Saving weights.\n",
        "m11.save_weights(\"subtask_2_m1.h5\")"
      ],
      "metadata": {
        "id": "k7eb4xFrK-7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $m_2^1$"
      ],
      "metadata": {
        "id": "FPj7f5MoLVe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of layers.\n",
        "layers = [tf.keras.layers.GlobalAveragePooling1D()]\n",
        "\n",
        "# Creating the model.\n",
        "m22 = create_bert_model(TFAutoModel.from_pretrained(checkpoint), (MAX_LENGTH,), n_classes = 2, layers = layers)"
      ],
      "metadata": {
        "id": "WXZGXwktLXc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary.\n",
        "m22.summary()"
      ],
      "metadata": {
        "id": "KszbSeRcLe0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling.\n",
        "m22.compile(optimizer = Adam(LR), loss = SparseCategoricalCrossentropy(from_logits = False), metrics = [\"accuracy\"])\n",
        "\n",
        "# Callbacks.\n",
        "callbacks = [LearningRateSchedule(m22, n = int(np.round(len(train_ids) / BATCH_SIZE / N_DECREASE_LR)), reduction = 20)]\n",
        "\n",
        "# Fitting.\n",
        "m22.fit({\"input_ids\": train_ids, \"attention_masks\": train_masks, \"token_type_ids\": train_type_ids}, train_labels, epochs = N_EPOCHS, batch_size = BATCH_SIZE, callbacks = callbacks)\n",
        "\n",
        "# Saving weights.\n",
        "m22.save_weights(\"subtask_2_m2.h5\")"
      ],
      "metadata": {
        "id": "YxHTKpOuLl4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $m_3^1$"
      ],
      "metadata": {
        "id": "SYiWi7s5Lq-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of layers.\n",
        "layers = [tf.keras.layers.GlobalMaxPool1D(),\n",
        "          tf.keras.layers.Dense(128, activation = \"relu\")]\n",
        "\n",
        "# Creating the model.\n",
        "m33 = create_bert_model(TFAutoModel.from_pretrained(checkpoint), (MAX_LENGTH,), n_classes = 2, layers = layers)"
      ],
      "metadata": {
        "id": "o_OGh-u6LxEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary.\n",
        "m33.summary()"
      ],
      "metadata": {
        "id": "IZky3rttL2Og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling.\n",
        "m33.compile(optimizer = Adam(LR), loss = SparseCategoricalCrossentropy(from_logits = False), metrics = [\"accuracy\"])\n",
        "\n",
        "# Callbacks.\n",
        "callbacks = [LearningRateSchedule(m33, n = int(np.round(len(train_ids) / BATCH_SIZE / N_DECREASE_LR)), reduction = 20)]\n",
        "\n",
        "# Fitting.\n",
        "m33.fit({\"input_ids\": train_ids, \"attention_masks\": train_masks, \"token_type_ids\": train_type_ids}, train_labels, epochs = N_EPOCHS, batch_size = BATCH_SIZE, callbacks = callbacks)\n",
        "\n",
        "# Saving weights.\n",
        "m33.save_weights(\"subtask_2_m3.h5\")"
      ],
      "metadata": {
        "id": "IoyB8wTHL5sW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $m_4^1$"
      ],
      "metadata": {
        "id": "5_njneG7L-er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of layers.\n",
        "layers = [tf.keras.layers.Conv1D(filters = 128, kernel_size = 3, activation = \"relu\"),\n",
        "          tf.keras.layers.MaxPooling1D(pool_size = 2),\n",
        "          tf.keras.layers.Conv1D(filters = 128, kernel_size = 3, activation = \"relu\"),\n",
        "          tf.keras.layers.MaxPooling1D(pool_size = 2),\n",
        "          tf.keras.layers.Conv1D(filters = 128, kernel_size = 3, activation = \"relu\"),\n",
        "          tf.keras.layers.MaxPooling1D(pool_size = 2),\n",
        "          tf.keras.layers.Flatten()]\n",
        "\n",
        "# Creating the model.\n",
        "m44 = create_bert_model(TFAutoModel.from_pretrained(checkpoint), (MAX_LENGTH,), n_classes = 2, layers = layers)"
      ],
      "metadata": {
        "id": "cKGbnAY1MGZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary.\n",
        "m44.summary()"
      ],
      "metadata": {
        "id": "CVogZ2xwMJdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling.\n",
        "m44.compile(optimizer = Adam(LR), loss = SparseCategoricalCrossentropy(from_logits = False), metrics = [\"accuracy\"])\n",
        "\n",
        "# Callbacks.\n",
        "callbacks = [LearningRateSchedule(m44, n = int(np.round(len(train_ids) / BATCH_SIZE / N_DECREASE_LR)), reduction = 20)]\n",
        "\n",
        "# Fitting.\n",
        "m44.fit({\"input_ids\": train_ids, \"attention_masks\": train_masks, \"token_type_ids\": train_type_ids}, train_labels, epochs = N_EPOCHS, batch_size = BATCH_SIZE, callbacks = callbacks)\n",
        "\n",
        "# Saving weights.\n",
        "m44.save_weights(\"subtask_2_m4.h5\")"
      ],
      "metadata": {
        "id": "6HHUTPrDMPgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Testing"
      ],
      "metadata": {
        "id": "Yx5Qjm9WrYdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing uni-dimensional list of paragraph authors.\n",
        "valid_labels = [author for authors in df_valid[\"paragraph-authors\"].values for author in authors]"
      ],
      "metadata": {
        "id": "Js4fm8OnI_2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $m_1^1$"
      ],
      "metadata": {
        "id": "THJbo3xhJAN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation test.\n",
        "y_pred_m11 = np.argmax(m11.predict({\"input_ids\": valid_ids, \"attention_masks\": valid_masks, \"token_type_ids\": valid_type_ids}), axis = 1)\n",
        "\n",
        "# Casting y_pred to be list of paragraph-authors instead of list of changes.\n",
        "y_pred_m11 = compute_authors_pred_list(df_valid[\"paragraph-authors\"].values, y_pred_m11)\n",
        "\n",
        "# Saving true and predicted labels.\n",
        "np.save(\"subtask2_m1_pred.npy\", y_pred_m11)\n",
        "np.save(\"subtask2_m1_true.npy\", valid_labels)\n",
        "\n",
        "# Printing score.\n",
        "print(classification_report(valid_labels, y_pred_m11))"
      ],
      "metadata": {
        "id": "iU0JPoTjrr9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $m_2^1$"
      ],
      "metadata": {
        "id": "Rpq0ZgS4M5WF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation test.\n",
        "y_pred_m22 = np.argmax(m22.predict({\"input_ids\": valid_ids, \"attention_masks\": valid_masks, \"token_type_ids\": valid_type_ids}), axis = 1)\n",
        "\n",
        "# Casting y_pred to be list of paragraph-authors instead of list of changes.\n",
        "y_pred_m22 = compute_authors_pred_list(df_valid[\"paragraph-authors\"].values, y_pred_m22)\n",
        "\n",
        "# Saving true and predicted labels.\n",
        "np.save(\"subtask2_m2_pred.npy\", y_pred_m22)\n",
        "np.save(\"subtask2_m2_true.npy\", valid_labels)\n",
        "\n",
        "# Printing score.\n",
        "print(classification_report(valid_labels, y_pred_m22))"
      ],
      "metadata": {
        "id": "Ml9Vv4hiM61n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $m_3^1$"
      ],
      "metadata": {
        "id": "TkoVnlUIM_6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation test.\n",
        "y_pred_m33 = np.argmax(m33.predict({\"input_ids\": valid_ids, \"attention_masks\": valid_masks, \"token_type_ids\": valid_type_ids}), axis = 1)\n",
        "\n",
        "# Casting y_pred to be list of paragraph-authors instead of list of changes.\n",
        "y_pred_m33 = compute_authors_pred_list(df_valid[\"paragraph-authors\"].values, y_pred_m33)\n",
        "\n",
        "# Saving true and predicted labels.\n",
        "np.save(\"subtask2_m3_pred.npy\", y_pred_m33)\n",
        "np.save(\"subtask2_m3_true.npy\", valid_labels)\n",
        "\n",
        "# Printing score.\n",
        "print(classification_report(valid_labels, y_pred_m33))"
      ],
      "metadata": {
        "id": "qPPOvyRnNCDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $m_4^1$"
      ],
      "metadata": {
        "id": "x1ZwhWD2NGQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation test.\n",
        "y_pred_m44 = np.argmax(m44.predict({\"input_ids\": valid_ids, \"attention_masks\": valid_masks, \"token_type_ids\": valid_type_ids}), axis = 1)\n",
        "\n",
        "# Casting y_pred to be list of paragraph-authors instead of list of changes.\n",
        "y_pred_m44 = compute_authors_pred_list(df_valid[\"paragraph-authors\"].values, y_pred_m44)\n",
        "\n",
        "# Saving true and predicted labels.\n",
        "np.save(\"subtask2_m4_pred.npy\", y_pred_m44)\n",
        "np.save(\"subtask2_m4_true.npy\", valid_labels)\n",
        "\n",
        "# Printing score.\n",
        "print(classification_report(valid_labels, y_pred_m44))"
      ],
      "metadata": {
        "id": "k6PYdHVRNH6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKqQqRFyrhkn"
      },
      "source": [
        "#Subtask 3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Inspection"
      ],
      "metadata": {
        "id": "1rrCEiwV_uAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_directory = '/content/dataset3/train'\n",
        "df_train = create_dataframe(train_directory)\n",
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sptr_pAu_xtY",
        "outputId": "d8a7c9ed-c5f5-4653-b084-a49cc3e88b28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "we have a problem at row:  1194\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   authors                                   site  multi-author  \\\n",
              "0        5                     serverfault.com.7z             1   \n",
              "1        1           gamedev.stackexchange.com.7z             0   \n",
              "2        5                       superuser.com.7z             1   \n",
              "3        1  computergraphics.stackexchange.com.7z             0   \n",
              "4        3                       superuser.com.7z             1   \n",
              "\n",
              "                                             changes  \\\n",
              "0                  [1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1]   \n",
              "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "2         [1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1]   \n",
              "3                                 [0, 0, 0, 0, 0, 0]   \n",
              "4  [1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, ...   \n",
              "\n",
              "                                   paragraph-authors  \\\n",
              "0               [1, 2, 1, 1, 3, 2, 2, 3, 4, 5, 5, 2]   \n",
              "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "2      [1, 2, 3, 1, 1, 4, 5, 5, 1, 3, 3, 2, 2, 2, 1]   \n",
              "3                              [1, 1, 1, 1, 1, 1, 1]   \n",
              "4  [1, 2, 1, 3, 2, 2, 3, 3, 2, 2, 1, 2, 2, 2, 3, ...   \n",
              "\n",
              "                                          input_text  \\\n",
              "0  Everything else equals I would say it being mo...   \n",
              "1  I also apologize for the lack of a 'decent' ti...   \n",
              "2  And updates should not need to touch /home/ an...   \n",
              "3  But v1,v2,v4 and v5 would have non-zero normal...   \n",
              "4  Now run this command to stop Windows from inst...   \n",
              "\n",
              "                                       splitted_text  \n",
              "0  [Everything else equals I would say it being m...  \n",
              "1  [I also apologize for the lack of a 'decent' t...  \n",
              "2  [And updates should not need to touch /home/ a...  \n",
              "3  [But v1,v2,v4 and v5 would have non-zero norma...  \n",
              "4  [Now run this command to stop Windows from ins...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2739ea0e-65f4-44b7-8bfa-c7c2fe622c73\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>authors</th>\n",
              "      <th>site</th>\n",
              "      <th>multi-author</th>\n",
              "      <th>changes</th>\n",
              "      <th>paragraph-authors</th>\n",
              "      <th>input_text</th>\n",
              "      <th>splitted_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>serverfault.com.7z</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1]</td>\n",
              "      <td>[1, 2, 1, 1, 3, 2, 2, 3, 4, 5, 5, 2]</td>\n",
              "      <td>Everything else equals I would say it being mo...</td>\n",
              "      <td>[Everything else equals I would say it being m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>gamedev.stackexchange.com.7z</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>I also apologize for the lack of a 'decent' ti...</td>\n",
              "      <td>[I also apologize for the lack of a 'decent' t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>superuser.com.7z</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1]</td>\n",
              "      <td>[1, 2, 3, 1, 1, 4, 5, 5, 1, 3, 3, 2, 2, 2, 1]</td>\n",
              "      <td>And updates should not need to touch /home/ an...</td>\n",
              "      <td>[And updates should not need to touch /home/ a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>computergraphics.stackexchange.com.7z</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
              "      <td>But v1,v2,v4 and v5 would have non-zero normal...</td>\n",
              "      <td>[But v1,v2,v4 and v5 would have non-zero norma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>superuser.com.7z</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, ...</td>\n",
              "      <td>[1, 2, 1, 3, 2, 2, 3, 3, 2, 2, 1, 2, 2, 2, 3, ...</td>\n",
              "      <td>Now run this command to stop Windows from inst...</td>\n",
              "      <td>[Now run this command to stop Windows from ins...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2739ea0e-65f4-44b7-8bfa-c7c2fe622c73')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2739ea0e-65f4-44b7-8bfa-c7c2fe622c73 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2739ea0e-65f4-44b7-8bfa-c7c2fe622c73');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Element at index 4 of df_train[\"splitted_text\"][1194] is empty and needs to be removed.\n",
        "del df_train[\"splitted_text\"][1194][4]"
      ],
      "metadata": {
        "id": "W9NF0xvTIxcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_inspection(df_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDemH8-B_2tJ",
        "outputId": "49274b66-a839-483a-eede-c6b0ef89d8df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: (7000, 7)\n",
            "Dataset columns: ['authors' 'site' 'multi-author' 'changes' 'paragraph-authors'\n",
            " 'input_text' 'splitted_text']\n",
            "Main sources: ['serverfault.com.7z' 'gamedev.stackexchange.com.7z' 'superuser.com.7z'\n",
            " 'computergraphics.stackexchange.com.7z'\n",
            " 'datascience.stackexchange.com.7z' 'codereview.stackexchange.com.7z'\n",
            " 'cseducators.stackexchange.com.7z' 'raspberrypi.stackexchange.com.7z'\n",
            " 'dba.stackexchange.com.7z' 'cstheory.stackexchange.com.7z'\n",
            " 'networkengineering.stackexchange.com.7z' 'devops.stackexchange.com.7z']\n",
            "Number of questions per source:\n",
            " site\n",
            "codereview.stackexchange.com.7z             281\n",
            "computergraphics.stackexchange.com.7z        23\n",
            "cseducators.stackexchange.com.7z             57\n",
            "cstheory.stackexchange.com.7z                97\n",
            "datascience.stackexchange.com.7z            157\n",
            "dba.stackexchange.com.7z                    352\n",
            "devops.stackexchange.com.7z                  28\n",
            "gamedev.stackexchange.com.7z                482\n",
            "networkengineering.stackexchange.com.7z     147\n",
            "raspberrypi.stackexchange.com.7z            148\n",
            "serverfault.com.7z                         2749\n",
            "superuser.com.7z                           2479\n",
            "Name: site, dtype: int64\n",
            "Average length of the text: 1834.346\n",
            "Possible number of authors: [5 1 3 2 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_directory = '/content/dataset3/validation'\n",
        "df_valid = create_dataframe(valid_directory)\n",
        "df_valid.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owTBE6Up_6OG",
        "outputId": "5784c407-fd96-4597-9a0c-7d8748b572ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   authors                site  multi-author  \\\n",
              "0        4  serverfault.com.7z             1   \n",
              "1        2    superuser.com.7z             1   \n",
              "2        3    superuser.com.7z             1   \n",
              "3        2    superuser.com.7z             1   \n",
              "4        4    superuser.com.7z             1   \n",
              "\n",
              "                                             changes  \\\n",
              "0      [1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1]   \n",
              "1                              [1, 1, 1, 0, 0, 1, 0]   \n",
              "2  [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, ...   \n",
              "3                              [1, 0, 0, 0, 1, 1, 0]   \n",
              "4  [0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, ...   \n",
              "\n",
              "                                   paragraph-authors  \\\n",
              "0   [1, 2, 1, 3, 3, 3, 1, 3, 4, 4, 1, 2, 3, 1, 1, 4]   \n",
              "1                           [1, 2, 1, 2, 2, 2, 1, 1]   \n",
              "2  [1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3, ...   \n",
              "3                           [1, 2, 2, 2, 2, 1, 2, 2]   \n",
              "4  [1, 1, 2, 1, 3, 4, 1, 2, 3, 1, 1, 2, 1, 3, 1, ...   \n",
              "\n",
              "                                          input_text  \\\n",
              "0  And here is the question: why do I have to use...   \n",
              "1  Remove the Day column and combine the Date and...   \n",
              "2  (I will use the \"&\" to execute the command in ...   \n",
              "3  In the advanced settings of openvpn i have cho...   \n",
              "4  Every single device does not exceed the limit ...   \n",
              "\n",
              "                                       splitted_text  \n",
              "0  [And here is the question: why do I have to us...  \n",
              "1  [Remove the Day column and combine the Date an...  \n",
              "2  [(I will use the \"&\" to execute the command in...  \n",
              "3  [In the advanced settings of openvpn i have ch...  \n",
              "4  [Every single device does not exceed the limit...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-340ecf78-78bf-47e1-b555-0c4d633b5040\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>authors</th>\n",
              "      <th>site</th>\n",
              "      <th>multi-author</th>\n",
              "      <th>changes</th>\n",
              "      <th>paragraph-authors</th>\n",
              "      <th>input_text</th>\n",
              "      <th>splitted_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>serverfault.com.7z</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1]</td>\n",
              "      <td>[1, 2, 1, 3, 3, 3, 1, 3, 4, 4, 1, 2, 3, 1, 1, 4]</td>\n",
              "      <td>And here is the question: why do I have to use...</td>\n",
              "      <td>[And here is the question: why do I have to us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>superuser.com.7z</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1, 1, 0, 0, 1, 0]</td>\n",
              "      <td>[1, 2, 1, 2, 2, 2, 1, 1]</td>\n",
              "      <td>Remove the Day column and combine the Date and...</td>\n",
              "      <td>[Remove the Day column and combine the Date an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>superuser.com.7z</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, ...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3, ...</td>\n",
              "      <td>(I will use the \"&amp;\" to execute the command in ...</td>\n",
              "      <td>[(I will use the \"&amp;\" to execute the command in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>superuser.com.7z</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 0, 0, 0, 1, 1, 0]</td>\n",
              "      <td>[1, 2, 2, 2, 2, 1, 2, 2]</td>\n",
              "      <td>In the advanced settings of openvpn i have cho...</td>\n",
              "      <td>[In the advanced settings of openvpn i have ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>superuser.com.7z</td>\n",
              "      <td>1</td>\n",
              "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, ...</td>\n",
              "      <td>[1, 1, 2, 1, 3, 4, 1, 2, 3, 1, 1, 2, 1, 3, 1, ...</td>\n",
              "      <td>Every single device does not exceed the limit ...</td>\n",
              "      <td>[Every single device does not exceed the limit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-340ecf78-78bf-47e1-b555-0c4d633b5040')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-340ecf78-78bf-47e1-b555-0c4d633b5040 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-340ecf78-78bf-47e1-b555-0c4d633b5040');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_inspection(df_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-3B9-Ha__0z",
        "outputId": "924984ee-8d8e-4cc9-882e-65a80452b3e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: (1500, 7)\n",
            "Dataset columns: ['authors' 'site' 'multi-author' 'changes' 'paragraph-authors'\n",
            " 'input_text' 'splitted_text']\n",
            "Main sources: ['serverfault.com.7z' 'superuser.com.7z' 'dba.stackexchange.com.7z'\n",
            " 'cstheory.stackexchange.com.7z' 'codereview.stackexchange.com.7z'\n",
            " 'gamedev.stackexchange.com.7z' 'computergraphics.stackexchange.com.7z'\n",
            " 'raspberrypi.stackexchange.com.7z'\n",
            " 'networkengineering.stackexchange.com.7z'\n",
            " 'cseducators.stackexchange.com.7z' 'datascience.stackexchange.com.7z'\n",
            " 'devops.stackexchange.com.7z']\n",
            "Number of questions per source:\n",
            " site\n",
            "codereview.stackexchange.com.7z             50\n",
            "computergraphics.stackexchange.com.7z        4\n",
            "cseducators.stackexchange.com.7z             8\n",
            "cstheory.stackexchange.com.7z               17\n",
            "datascience.stackexchange.com.7z            22\n",
            "dba.stackexchange.com.7z                    86\n",
            "devops.stackexchange.com.7z                  6\n",
            "gamedev.stackexchange.com.7z                92\n",
            "networkengineering.stackexchange.com.7z     34\n",
            "raspberrypi.stackexchange.com.7z            34\n",
            "serverfault.com.7z                         593\n",
            "superuser.com.7z                           554\n",
            "Name: site, dtype: int64\n",
            "Average length of the text: 1805.512\n",
            "Possible number of authors: [4 2 3 1 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "yBGLj0RIN-EP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model checkpoint.\n",
        "checkpoint = \"bert-base-cased\"\n",
        "\n",
        "# Getting tokenizer.\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "LCxjpYq0OaJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Max input length.\n",
        "MAX_LENGTH = 64\n",
        "\n",
        "# Number of samples per class.\n",
        "MAX_SAMPLES = 15000\n",
        "\n",
        "# Splitting data.\n",
        "train_ids, train_labels, train_masks, train_type_ids = preprocess_without_data_augmentation(df_train[\"splitted_text\"].values, df_train[\"changes\"].values, tokenizer, MAX_LENGTH, max_samples = MAX_SAMPLES)\n",
        "valid_ids, valid_labels, valid_masks, valid_type_ids = preprocess_without_data_augmentation(df_valid[\"splitted_text\"].values, df_valid[\"changes\"].values, tokenizer, MAX_LENGTH)\n",
        "\n",
        "# Printing shapes.\n",
        "print(f\"train_ids: {train_ids.shape}, train_labels: {train_labels.shape}, train_masks: {train_masks.shape}, train_type_ids: {train_type_ids.shape}.\")\n",
        "print(f\"valid_ids: {valid_ids.shape}, valid_labels: {valid_labels.shape}, valid_masks: {valid_masks.shape}, valid_type_ids: {valid_type_ids.shape}.\")"
      ],
      "metadata": {
        "id": "PP8iFgHaOdhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing classes distributions.\n",
        "classes_without_upsampling, counts_without_upsampling = np.unique([item for sublist in df_train[\"changes\"] for item in sublist], return_counts = True)\n",
        "classes_with_upsampling, counts_with_upsampling = np.unique(train_labels, return_counts = True)\n",
        "\n",
        "# Normalizing.\n",
        "counts_without_upsampling = counts_without_upsampling / np.sum(counts_without_upsampling) * 100\n",
        "counts_with_upsampling = counts_with_upsampling / np.sum(counts_with_upsampling) * 100\n",
        "\n",
        "# Plot classes distribution.\n",
        "plot_classes_distribution([classes_without_upsampling, classes_with_upsampling], [counts_without_upsampling, counts_with_upsampling], \"subtask3_m1_distribution\")"
      ],
      "metadata": {
        "id": "k3pvz6BnOlXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models Definition and Training"
      ],
      "metadata": {
        "id": "xangPuKsAlYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training hyperparameters.\n",
        "LR = 5e-5\n",
        "BATCH_SIZE = 16\n",
        "N_EPOCHS = 2\n",
        "\n",
        "# Learning rate schedule hyperparameters.\n",
        "N_DECREASE_LR = 5\n",
        "LR_REDUCTION = 20"
      ],
      "metadata": {
        "id": "HjYNGOVIPDVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $m_1^1$"
      ],
      "metadata": {
        "id": "tAbfcPv2OtZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of layers.\n",
        "layers = [tf.keras.layers.GlobalMaxPool1D()]\n",
        "\n",
        "# Creating the model.\n",
        "m111 = create_bert_model(TFAutoModel.from_pretrained(checkpoint), (MAX_LENGTH,), n_classes = 2, layers = layers)"
      ],
      "metadata": {
        "id": "xykBZWaLPIAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary.\n",
        "m111.summary()"
      ],
      "metadata": {
        "id": "55akYEQoPNFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling.\n",
        "m111.compile(optimizer = Adam(LR), loss = SparseCategoricalCrossentropy(from_logits = False), metrics = [\"accuracy\"])\n",
        "\n",
        "# Callbacks.\n",
        "callbacks = [LearningRateSchedule(m111, n = int(np.round(len(train_ids) / BATCH_SIZE / N_DECREASE_LR)), reduction = 20)]\n",
        "\n",
        "# Fitting.\n",
        "m111.fit({\"input_ids\": train_ids, \"attention_masks\": train_masks, \"token_type_ids\": train_type_ids}, train_labels, epochs = N_EPOCHS, batch_size = BATCH_SIZE, callbacks = callbacks)\n",
        "\n",
        "# Saving weights.\n",
        "m111.save_weights(\"subtask_3_m1.h5\")"
      ],
      "metadata": {
        "id": "Wjz4E4WrPQT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $m_2^1$"
      ],
      "metadata": {
        "id": "pygiM0k0OvNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of layers.\n",
        "layers = [tf.keras.layers.GlobalAveragePooling1D()]\n",
        "\n",
        "# Creating the model.\n",
        "m222 = create_bert_model(TFAutoModel.from_pretrained(checkpoint), (MAX_LENGTH,), n_classes = 2, layers = layers)"
      ],
      "metadata": {
        "id": "qJ7NBfJcPUq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary.\n",
        "m222.summary()"
      ],
      "metadata": {
        "id": "Bbt4V9ljPZfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling.\n",
        "m222.compile(optimizer = Adam(LR), loss = SparseCategoricalCrossentropy(from_logits = False), metrics = [\"accuracy\"])\n",
        "\n",
        "# Callbacks.\n",
        "callbacks = [LearningRateSchedule(m222, n = int(np.round(len(train_ids) / BATCH_SIZE / N_DECREASE_LR)), reduction = 20)]\n",
        "\n",
        "# Fitting.\n",
        "m222.fit({\"input_ids\": train_ids, \"attention_masks\": train_masks, \"token_type_ids\": train_type_ids}, train_labels, epochs = N_EPOCHS, batch_size = BATCH_SIZE, callbacks = callbacks)\n",
        "\n",
        "# Saving weights.\n",
        "m222.save_weights(\"subtask_3_m2.h5\")"
      ],
      "metadata": {
        "id": "3ZUTVbVgPbzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $m_3^1$"
      ],
      "metadata": {
        "id": "WkoKgWwIOw1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of layers.\n",
        "layers = [tf.keras.layers.GlobalMaxPool1D(),\n",
        "          tf.keras.layers.Dense(128, activation = \"relu\")]\n",
        "\n",
        "# Creating the model.\n",
        "m333 = create_bert_model(TFAutoModel.from_pretrained(checkpoint), (MAX_LENGTH,), n_classes = 2, layers = layers)"
      ],
      "metadata": {
        "id": "HSJCNYeCQHYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary.\n",
        "m333.summary()"
      ],
      "metadata": {
        "id": "-fgVu_MKQLXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling.\n",
        "m333.compile(optimizer = Adam(LR), loss = SparseCategoricalCrossentropy(from_logits = False), metrics = [\"accuracy\"])\n",
        "\n",
        "# Callbacks.\n",
        "callbacks = [LearningRateSchedule(m333, n = int(np.round(len(train_ids) / BATCH_SIZE / N_DECREASE_LR)), reduction = 20)]\n",
        "\n",
        "# Fitting.\n",
        "m333.fit({\"input_ids\": train_ids, \"attention_masks\": train_masks, \"token_type_ids\": train_type_ids}, train_labels, epochs = N_EPOCHS, batch_size = BATCH_SIZE, callbacks = callbacks)\n",
        "\n",
        "# Saving weights.\n",
        "m333.save_weights(\"subtask_3_m3.h5\")"
      ],
      "metadata": {
        "id": "HL0ztGhHQPQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $m_4^1$"
      ],
      "metadata": {
        "id": "b4SQTNHOOybT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of layers.\n",
        "layers = [tf.keras.layers.Conv1D(filters = 128, kernel_size = 3, activation = \"relu\"),\n",
        "          tf.keras.layers.MaxPooling1D(pool_size = 2),\n",
        "          tf.keras.layers.Conv1D(filters = 128, kernel_size = 3, activation = \"relu\"),\n",
        "          tf.keras.layers.MaxPooling1D(pool_size = 2),\n",
        "          tf.keras.layers.Conv1D(filters = 128, kernel_size = 3, activation = \"relu\"),\n",
        "          tf.keras.layers.MaxPooling1D(pool_size = 2),\n",
        "          tf.keras.layers.Flatten()]\n",
        "\n",
        "# Creating the model.\n",
        "m444 = create_bert_model(TFAutoModel.from_pretrained(checkpoint), (MAX_LENGTH,), n_classes = 2, layers = layers)"
      ],
      "metadata": {
        "id": "JKB_2kIJQXGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary.\n",
        "m444.summary()"
      ],
      "metadata": {
        "id": "if-5202wQY7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling.\n",
        "m444.compile(optimizer = Adam(LR), loss = SparseCategoricalCrossentropy(from_logits = False), metrics = [\"accuracy\"])\n",
        "\n",
        "# Callbacks.\n",
        "callbacks = [LearningRateSchedule(m444, n = int(np.round(len(train_ids) / BATCH_SIZE / N_DECREASE_LR)), reduction = 20)]\n",
        "\n",
        "# Fitting.\n",
        "m444.fit({\"input_ids\": train_ids, \"attention_masks\": train_masks, \"token_type_ids\": train_type_ids}, train_labels, epochs = N_EPOCHS, batch_size = BATCH_SIZE, callbacks = callbacks)\n",
        "\n",
        "# Saving weights.\n",
        "m444.save_weights(\"subtask_3_m4.h5\")"
      ],
      "metadata": {
        "id": "_XGqsKdWQbEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Testing"
      ],
      "metadata": {
        "id": "IGOT0TjwAq78"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $m_1^1$"
      ],
      "metadata": {
        "id": "Ku9Z0lSMO1qS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation test.\n",
        "y_pred_m111 = np.argmax(m111.predict({\"input_ids\": valid_ids, \"attention_masks\": valid_masks, \"token_type_ids\": valid_type_ids}), axis = 1)\n",
        "\n",
        "# Saving true and predicted labels.\n",
        "np.save(\"subtask3_m1_pred.npy\", y_pred_m111)\n",
        "np.save(\"subtask3_m1_true.npy\", valid_labels)\n",
        "\n",
        "# Printing score.\n",
        "print(classification_report(valid_labels, y_pred_m111))"
      ],
      "metadata": {
        "id": "rvU4GFG7QrNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $m_2^1$"
      ],
      "metadata": {
        "id": "6_QKU6dVO5Zl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation test.\n",
        "y_pred_m222 = np.argmax(m222.predict({\"input_ids\": valid_ids, \"attention_masks\": valid_masks, \"token_type_ids\": valid_type_ids}), axis = 1)\n",
        "\n",
        "# Saving true and predicted labels.\n",
        "np.save(\"subtask3_m2_pred.npy\", y_pred_m222)\n",
        "np.save(\"subtask3_m2_true.npy\", valid_labels)\n",
        "\n",
        "# Printing score.\n",
        "print(classification_report(valid_labels, y_pred_m222))"
      ],
      "metadata": {
        "id": "ShXcKjcdQt6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $m_3^1$"
      ],
      "metadata": {
        "id": "5Gqo5c_hO6h9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation test.\n",
        "y_pred_m333 = np.argmax(m333.predict({\"input_ids\": valid_ids, \"attention_masks\": valid_masks, \"token_type_ids\": valid_type_ids}), axis = 1)\n",
        "\n",
        "# Saving true and predicted labels.\n",
        "np.save(\"subtask3_m3_pred.npy\", y_pred_m333)\n",
        "np.save(\"subtask3_m3_true.npy\", valid_labels)\n",
        "\n",
        "# Printing score.\n",
        "print(classification_report(valid_labels, y_pred_m333))"
      ],
      "metadata": {
        "id": "pTD7A0TTQw4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### $m_4^1$"
      ],
      "metadata": {
        "id": "U0JhTXw9O72l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation test.\n",
        "y_pred_m444 = np.argmax(m444.predict({\"input_ids\": valid_ids, \"attention_masks\": valid_masks, \"token_type_ids\": valid_type_ids}), axis = 1)\n",
        "\n",
        "# Saving true and predicted labels.\n",
        "np.save(\"subtask3_m4_pred.npy\", y_pred_m444)\n",
        "np.save(\"subtask3_m4_true.npy\", valid_labels)\n",
        "\n",
        "# Printing score.\n",
        "print(classification_report(valid_labels, y_pred_m444))"
      ],
      "metadata": {
        "id": "PGrnWM1JQz8T"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TacL2tusBXSN",
        "ruNebl0F1jk1",
        "e292GXxYrafS",
        "19A-lCj8xO9a",
        "P6S9rfakGKC-",
        "kKVeReaTA72d",
        "P_CjAhHbGmgN",
        "psgcLmEORWD5",
        "k1z3cTMPTgq3",
        "uVjK7TlET2cM",
        "ynHIOWIFA_hO",
        "8Oo2pwnyH3md",
        "x483SzfUTKBA",
        "IAcR10ZhTQEx",
        "l0s_GsmPTUGB",
        "1fG4laDkrfu1",
        "um25XokQrUCL",
        "lfA9ZqDGIc-5",
        "V99U_ncGrVcJ",
        "h3VjCVnDImBa",
        "FPj7f5MoLVe6",
        "SYiWi7s5Lq-g",
        "5_njneG7L-er",
        "Yx5Qjm9WrYdW",
        "THJbo3xhJAN1",
        "Rpq0ZgS4M5WF",
        "TkoVnlUIM_6V",
        "x1ZwhWD2NGQo",
        "IKqQqRFyrhkn",
        "1rrCEiwV_uAt",
        "yBGLj0RIN-EP",
        "xangPuKsAlYh",
        "tAbfcPv2OtZr",
        "pygiM0k0OvNj",
        "WkoKgWwIOw1u",
        "b4SQTNHOOybT",
        "IGOT0TjwAq78",
        "Ku9Z0lSMO1qS",
        "6_QKU6dVO5Zl",
        "5Gqo5c_hO6h9",
        "U0JhTXw9O72l"
      ]
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c9945af5abf74bb595e3a9e2d862180d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2062484144984f91832a51fe928612a6",
              "IPY_MODEL_5f1163c8ed1b4dee9aa4d389921b310b",
              "IPY_MODEL_63a68d951c8f40dc94bafdc4cf2417bb"
            ],
            "layout": "IPY_MODEL_56159c9e1e164c1e8c7a50b79b420eff"
          }
        },
        "2062484144984f91832a51fe928612a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7e8eb4d7ace4a998e1f84474c6c5092",
            "placeholder": "​",
            "style": "IPY_MODEL_f795592f4d3945299193ee7409ec27c9",
            "value": "Downloading: 100%"
          }
        },
        "5f1163c8ed1b4dee9aa4d389921b310b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8474318a1a2f4f18b3550860654ccc09",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f105e1e4764e44ce8e2df8cc3e8a0d76",
            "value": 29
          }
        },
        "63a68d951c8f40dc94bafdc4cf2417bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b4e189c76c94d3ea03d01d9275b5e15",
            "placeholder": "​",
            "style": "IPY_MODEL_a58cf8faf41b4f9b98a20f6e962b8eee",
            "value": " 29.0/29.0 [00:00&lt;00:00, 1.87kB/s]"
          }
        },
        "56159c9e1e164c1e8c7a50b79b420eff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7e8eb4d7ace4a998e1f84474c6c5092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f795592f4d3945299193ee7409ec27c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8474318a1a2f4f18b3550860654ccc09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f105e1e4764e44ce8e2df8cc3e8a0d76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b4e189c76c94d3ea03d01d9275b5e15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a58cf8faf41b4f9b98a20f6e962b8eee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "446e721591ce48f3aaca6a04dcce2ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee486b4fa89f4043bce2e026e6a422ea",
              "IPY_MODEL_5a8e1db6da244451b2d875b8094cb2f6",
              "IPY_MODEL_344719c595b94f2ba82c072423665598"
            ],
            "layout": "IPY_MODEL_b37073190c8b4c3cb609295727555ec0"
          }
        },
        "ee486b4fa89f4043bce2e026e6a422ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81127e8a748c4aaa9c9133985d919802",
            "placeholder": "​",
            "style": "IPY_MODEL_d9e0da5d117949bc920ed43c6d129945",
            "value": "Downloading: 100%"
          }
        },
        "5a8e1db6da244451b2d875b8094cb2f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_554cbcd37ca04665a3d0f4484faf6176",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1919f79a73db43ed8c76d93210b70dff",
            "value": 570
          }
        },
        "344719c595b94f2ba82c072423665598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd3aa08b3e904748b7d4e6d059849e07",
            "placeholder": "​",
            "style": "IPY_MODEL_d2e4aa46cc2f4d67b49d16adad06c687",
            "value": " 570/570 [00:00&lt;00:00, 36.8kB/s]"
          }
        },
        "b37073190c8b4c3cb609295727555ec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81127e8a748c4aaa9c9133985d919802": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9e0da5d117949bc920ed43c6d129945": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "554cbcd37ca04665a3d0f4484faf6176": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1919f79a73db43ed8c76d93210b70dff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd3aa08b3e904748b7d4e6d059849e07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2e4aa46cc2f4d67b49d16adad06c687": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f4eecc7a5d34bed9eeaf6944ef73eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f64b08d4e34e4bd091b534dfcd689dd3",
              "IPY_MODEL_2a330d92ecd14402bd4088020085bbbd",
              "IPY_MODEL_a8ef8f7bd6094fb3805b8c6ce2f8a3f2"
            ],
            "layout": "IPY_MODEL_6486d6e2d8f545729ebf3c35717206ff"
          }
        },
        "f64b08d4e34e4bd091b534dfcd689dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6953cb032f64446d938b2d04447dde82",
            "placeholder": "​",
            "style": "IPY_MODEL_73e08b4273bb42499292909cdacbecdc",
            "value": "Downloading: 100%"
          }
        },
        "2a330d92ecd14402bd4088020085bbbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1eee744fb70a4e2d935ec54f4d9d64a0",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27313a45c92f44c4b70b4dc286912d51",
            "value": 213450
          }
        },
        "a8ef8f7bd6094fb3805b8c6ce2f8a3f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48a5e59dbfc5400fa0945a9f373c1a7b",
            "placeholder": "​",
            "style": "IPY_MODEL_527dee50ddb44b1fa46649c9f194674b",
            "value": " 213k/213k [00:00&lt;00:00, 653kB/s]"
          }
        },
        "6486d6e2d8f545729ebf3c35717206ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6953cb032f64446d938b2d04447dde82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73e08b4273bb42499292909cdacbecdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1eee744fb70a4e2d935ec54f4d9d64a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27313a45c92f44c4b70b4dc286912d51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48a5e59dbfc5400fa0945a9f373c1a7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "527dee50ddb44b1fa46649c9f194674b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82ec5215d7684e7aa42cd3c6a4d6f622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f58c19acd7848cdaf41d694d5143c65",
              "IPY_MODEL_f50d7813d6e749d0bb7448e45c337bac",
              "IPY_MODEL_353caa03fe594b61a970d27ac0ff75da"
            ],
            "layout": "IPY_MODEL_5e57eb2258ec455b92ad5d2c3d406806"
          }
        },
        "5f58c19acd7848cdaf41d694d5143c65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58a5e4bd152649b381d43ed55fe72a78",
            "placeholder": "​",
            "style": "IPY_MODEL_b81446a0de5848768e200eb3f4f2f9fa",
            "value": "Downloading: 100%"
          }
        },
        "f50d7813d6e749d0bb7448e45c337bac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08aec46c3873481b986e32738cbff8fd",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0161f8a2105e4899b43e98a7cd617a2a",
            "value": 435797
          }
        },
        "353caa03fe594b61a970d27ac0ff75da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92d6b8b7f88545eab80b1cde8d8ab671",
            "placeholder": "​",
            "style": "IPY_MODEL_6b5a88b1475a4f069a71ab9c8eb980dd",
            "value": " 436k/436k [00:00&lt;00:00, 605kB/s]"
          }
        },
        "5e57eb2258ec455b92ad5d2c3d406806": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58a5e4bd152649b381d43ed55fe72a78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b81446a0de5848768e200eb3f4f2f9fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08aec46c3873481b986e32738cbff8fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0161f8a2105e4899b43e98a7cd617a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "92d6b8b7f88545eab80b1cde8d8ab671": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b5a88b1475a4f069a71ab9c8eb980dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61c7f62eacff434698e2ad7bfb28426c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a05817b85b84c94ab0ac935d766e3ff",
              "IPY_MODEL_c3b83a805b5d42ea9488503256263baf",
              "IPY_MODEL_4d8cb3b4b9db4ae5b7bd41cd7d1db3ce"
            ],
            "layout": "IPY_MODEL_6e9e0f5a090d47248ea81cd3de0eda28"
          }
        },
        "5a05817b85b84c94ab0ac935d766e3ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdac71633e3d4a458db98785e20eadf1",
            "placeholder": "​",
            "style": "IPY_MODEL_7d4189398acd4ac3a9b7fc80067953fa",
            "value": "Downloading: 100%"
          }
        },
        "c3b83a805b5d42ea9488503256263baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0b59a0dbd994e3e80ef647a5a5c4270",
            "max": 526681800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b7eb794191845b0b89fca3068fbbd5d",
            "value": 526681800
          }
        },
        "4d8cb3b4b9db4ae5b7bd41cd7d1db3ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d34418188eca4e9a86269fac0ebb4aed",
            "placeholder": "​",
            "style": "IPY_MODEL_b7e38b6b94044f979a20a8d225fa6ef8",
            "value": " 527M/527M [00:07&lt;00:00, 74.9MB/s]"
          }
        },
        "6e9e0f5a090d47248ea81cd3de0eda28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdac71633e3d4a458db98785e20eadf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d4189398acd4ac3a9b7fc80067953fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0b59a0dbd994e3e80ef647a5a5c4270": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b7eb794191845b0b89fca3068fbbd5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d34418188eca4e9a86269fac0ebb4aed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7e38b6b94044f979a20a8d225fa6ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}